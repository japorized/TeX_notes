% Document Head
\documentclass[11pt, oneside]{book}

\input{latex-classnotes-preamble.tex}

% Main Body
\title{PMATH352W18 Complex Analysis - Class Notes}
\author{Johnson Ng}

\begin{document}
\hypersetup{pageanchor=false}
\maketitle
\hypersetup{pageanchor=true}
\tableofcontents

\chapter*{List of Definitions}
\theoremlisttype{all}
\listtheorems{defn}

\chapter*{List of Theorems}
\theoremlisttype{allname}
\listtheorems{axiom,lemma,thm,crly,propo}

\chapter{Lecture 1 Jan 3 2018}
	\label{chapter:lecture_1_jan_3_2018}

\section{Complex Numbers and Their Properties} % (fold)
\label{sec:complex_numbers_and_their_properties}

\begin{defn}[Complex Number, Complex Plane]\label{defn:Complex Number, Complex Plane}
	A \hldefn{complex number} is a vector in $\mathbb{R}^2$. The \hldefn{complex plane}, denoted by $\mathbb{C}$, is a set of complex numbers,
	\begin{equation*}
		\mathbb{C} = \mathbb{R}^2 = \left\{ \begin{pmatrix} x \\ y \end{pmatrix} : x , y \in \mathbb{R} \right\}
	\end{equation*}
	In $\mathbb{C}$, we usually write \\
	\begin{center}
		\begin{tabular}{c c}
			$0 = \begin{pmatrix} 0 \\ 0 \end{pmatrix}$ & $1 = \begin{pmatrix} 1 \\ 0 \end{pmatrix}$ \\
			$i = \begin{pmatrix} 0 \\ 1 \end{pmatrix}$ & $x = \begin{pmatrix} x \\ 0 \end{pmatrix}$ \\
			$iy = \begin{pmatrix} 0 \\ y \end{pmatrix}$
		\end{tabular}
	\end{center}
	where $x, y \in \mathbb{R}$. Consequently, we have that
	\begin{equation*}
		x + iy = x + yi = \begin{pmatrix} x \\ y \end{pmatrix}
	\end{equation*}
	If for $x, y \in \mathbb{R}, \; z = x + iy$, then $x$ is called the \hldefn{real part} of $z$ and $y$ is called the \hldefn{imaginary part} of $z$, and we write
	\begin{equation*}
		\re(z) = x \quad \im(z) = y.
	\end{equation*}
\end{defn}

\begin{note}
	\begin{itemize}
		\item It is easy to see how $\mathbb{R}$ is a subset of $\mathbb{C}$.
		\item Complex Numbers of the form $\left(\begin{smallmatrix} 0 \\ y \end{smallmatrix}\right)$ where $y \in \mathbb{R}$ are called \hlnotea{purely imaginary numbers}.
		\item Certain authors may prefer to denote $i = \left(\begin{smallmatrix} 0 \\ 1 \end{smallmatrix}\right)$.
	\end{itemize}
\end{note}

\begin{defn}[Sum and Product]\label{defn:Sum and Product}
	We define the sum of two complex numbers to be the usual vector sum, i.e.
	\begin{align*}
		(a + ib) + (c + id) &= \begin{pmatrix} a \\ b \end{pmatrix} + \begin{pmatrix} c \\ d \end{pmatrix} \\
											&= \begin{pmatrix} a + c \\ b + d \end{pmatrix} \\
											&= (a + c) + i (b + d)
	\end{align*}
	where $a, b, c, d \in \mathbb{R}$.

	We define the product of two complex numbers by setting $i^2 = -1$, and by requiring the product to be \hlimpo{commutative, associative, and distributive} over the sum. In this setup, we have that
	\begin{align}
		(a + ib)(c + id) &= ac + iad + ibc + i^2 bd \nonumber \\
						 &= (ac - bd) + i (ad + bc) \label{eq:complex multiplication}
	\end{align}
\end{defn}

\begin{note}
 It is interesting to note that \hlwarn{any complex number times zero is zero}, just like what we have with real numbers.
 \begin{gather*}
 	\forall z = x + iy \in \mathbb{C} \; x, y \in \mathbb{R} \enspace 0 \in \mathbb{C} \\
 	z \cdot 0 = (x + iy)(0 + i0) = 0 + i0 = 0
 \end{gather*}
\end{note}

\begin{eg}\label{eg:1}
	Let $z = 2 + i, w = 1 + 3i$. Find $z + w$ and $zw$.
	\begin{align*}
		z + w &= (2 + i) + (1 + 3i) \\
			  	&= 3 + 4i \\
			  	\\
		zw 		&= (2 + i)(1 + 3i) \\
					&= (2 - 3) + i (6 + 1) \quad \text{By } \cref{eq:complex multiplication}\\
					&= -1 + 7i
	\end{align*}
\end{eg}

\begin{eg}\label{eg:multiplicative inverse of a complex number}
	Show that every non-zero complex number has a \hldefn{multiplicative inverse}, $z^{-1}$, and find a formula for this inverse.

	Let $z = a + ib$ where $a, b \in \mathbb{R}$ with $a^2 + b^2 \neq 0$. Then
	\begin{align*}
				 & z(x + iy) = 1 \\
		\iff & (ax - by) + i(ay + bx) = 1 \\
		\iff & \begin{pmatrix} ax - by \\ ay + bx	\end{pmatrix} = \begin{pmatrix} 1 \\ 0 \end{pmatrix} \\
		\iff & \begin{pmatrix} a & -b \\ b & a \end{pmatrix}\begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} 1 \\ 0 \end{pmatrix} \\
		\iff & \begin{pmatrix} x \\ y \end{pmatrix} = \frac{1}{a^2 + b^2} \begin{pmatrix} a & b \\ -b & a \end{pmatrix}	\begin{pmatrix} 1 \\ 0 \end{pmatrix} \\
		\iff & \begin{pmatrix} x \\ y \end{pmatrix} = \frac{1}{a^2 + b^2}\begin{pmatrix} a \\ -b \end{pmatrix} \\
		\iff & x + iy = \frac{a}{a^2 + b^2} - i \frac{b}{a^2 + b^2} 
	\end{align*}
	Therefore, we have that the formula for the inverse is
	\begin{equation}\label{eq:complex inverse}
		(a + ib)^{-1} = \frac{a}{a^2 +b^2} - i \frac{b}{a^2 + b^2} 
	\end{equation}
\end{eg}

\begin{notation}
	For $z, w \in \mathbb{C}$, we write
	\begin{center}
		\begin{tabular}{c c}
			$-z = -1z$ & $w - z = w + (-z)$ \\
			$\frac{1}{z} = z^{-1}$ & $\frac{w}{z} = wz^{-1}$
		\end{tabular}
	\end{center}
\end{notation}

\begin{eg}\label{eg:3}
	Find $\frac{(4 - i) - (1 - 2i)}{1 + 2i}$.
	\begin{align*}
		\frac{(4 - i) - (1 - 2i)}{1 + 2i} &= \frac{3 + i}{1 + 2i} \\
					&= (3 + i)(\frac{1}{5} - i \frac{2}{5} ) \\
					&= 1 - i
	\end{align*}
\end{eg}

\begin{note}
	The set of complex numbers is a \hlnotea{field} under the operations of addition and multiplication. This means that $\forall u, v, w \in \mathbb{C}$,
	\begin{center}
		\begin{tabular}{r@{\;{=}\;}l r@{\;{=}\;}l}
			u + v 			& v + u 			& uv 			& vu \\
			(u + v) + w & u + (v + w) & (uv)w 	& u(vw) \\
			0 + u 			& u 					& 1u			& u \\
			u + (-u)		& 0						& $uu^{-1}$	& 1, $\; u \neq 0$ \\
			u(v + w)		& uv + uw
		\end{tabular}
	\end{center}

	Since the distributive law holds for complex numbers, note that the \hlwarn{binomial expansion works} for $(w + z)^n$ where $w, z \in \mathbb{C}$ and $n \in \mathbb{N}$. (I did not verify if this is still true for when $n \in \mathbb{R}$.)
\end{note}

\begin{defn}[Conjugate]\label{defn:Conjugate}
	If $z = x + iy$ where $x, y \in \mathbb{R}$, then the \hldefn{conjugate of z} is given by $\bar{z} = x - iy$
\end{defn}

\begin{eg}\label{eg:4}
	Let $z = 3 + 4i$. Then the $\bar{z} = 3 - 4i$. Represented in the complex plane, we have the following:
	\begin{center}
		\begin{tikzpicture}
			\begin{axis}[four quad complex, xtick={-4,-3,...,4}, ytick={-5,-4,...,5}, xmin=-4, xmax=4, ymin=-5, ymax=5]
				\node[label={0:{$z$}},circle,fill,inner sep=2pt] at (axis cs:3,4) {};
				\node[label={0:{$\bar{z}$}},circle,fill,inner sep=2pt] at (axis cs:3,-4) {};
			\end{axis}
		\end{tikzpicture}
	\end{center}

	We observe that on the complex plane, the conjugate of a complex number is simply its reflection on the real axis.
\end{eg}

\begin{defn}[Modulus]\label{defn:Modulus}
	We define the \hldefn{modulus} (length, magnitude) of $z = x + iy \in \mathbb{C}, x, y \in \mathbb{R}$, to be
	\begin{equation}
		\abs{z} = \sqrt{x^2 + y^2} \in \mathbb{R}.
	\end{equation}
\end{defn}

\begin{note}
 Note that this definition is consistent with the notion of the absolute value in real numbers when $z$ is a real number, since if $y = 0$, $\abs{z} = \abs{x + i0} = \sqrt{x^2} = \pm x$.
\end{note}

\begin{note}
 For $z, w \in \mathbb{C}$ and $n \in \mathbb{N}$, we have
 \begin{center}
 	\begin{tabular}{r@{\;{=}\;}l r@{\;{=}\;}l r@{\;{=}\;}l}
 		$\bar{\bar{z}}$ 	& z 									& $z + \bar{z}$ 	& $2 \re(z)$ 			& $z - \bar{z}$ 	& $2i \im(z)$ \\
 		$z\bar{z}$				& $\abs{z}^2$					& $\abs{z}$				& $\abs{\bar{z}}$	& $\bar{z \pm w}$	& $\bar{z} \pm \bar{w}$ \\
 		\color{base16-eighties-lightblue}$\bar{zw}$		& \color{base16-eighties-lightblue}$\bar{z}\bar{w}$
 		& $\abs{zw}$			&	$\abs{z}\abs{w}$
 		& $\bar{z}^n$ & $\bar{z^n}$
 	\end{tabular}
 \end{center}
 but note that $\abs{z + w} \neq \abs{z} + \abs{w}$.

 Also, note that the last equation is a generalization of the \hlnoteb{highlighted equation}.
\end{note}

\begin{note}
 While inequalities such as $z_1 < z_2$, where $z_1, z_2 \in \mathbb{C}$, are meaningless unless if both of them are real, $\abs{z_1} < \abs{z_2}$ means that the point $z_1$ in the complex plane is closer to the origin than the point $z_2$.
\end{note}

\begin{propo}[Basic Inequalities]\label{propo:Basic Inequalities}
	\begin{enumerate}
		\item $\abs{\re(z)} \leq \abs{z}$ \\
		\item $\abs{\im(z)} \leq \abs{z}$ \\
		\item $\abs{z + w} \leq \abs{z} + \abs{w} \quad$ Triangle Inequality \label{eq:triangle inequality}\\
		\item $\abs{z + w} \geq \abs{\;\abs{z} - \abs{w}\;} \quad$ Inverse Triangle Inequality
	\end{enumerate}
\end{propo}

\begin{proof}
	Note that $\abs{z}^2 = \re(z)^2 + \im(z)^2$ and that we can express $\abs{x} = \sqrt{x^2}$ for any $x \in \mathbb{R} $. 1 and 2 immediately follows from that.

	To prove 3, we have that
	\begin{align*}
		\abs{z + w}^2 &= (z + w)(\bar{z} + \bar{w}) \\
				&= \abs{z}^2 + \abs{w}^2 + (w\bar{z} + \bar{w}z) \\
				&= \abs{z}^2 + \abs{w}^2 + 2\re(w\bar{z}) \\
				&\leq \abs{z}^2 + \abs{w}^2 + 2\abs{w\bar{z}} \quad \text{by 1} \\
				&= \abs{z}^2 + \abs{w}^2 + 2\abs{wz} \quad \text{since } \abs{w\bar{z}} = \abs{w}\abs{\bar{z}} \text{ and } \abs{z} = \abs{\bar{z}} \\
				&= (\abs{z} + \abs{w})^2
	\end{align*}
	
	To prove 4, note that
	\begin{alignat}{3}
		&\abs{z} &&= \abs{z + w - w} &&\leq \abs{z + w} + \abs{w} \label{basicinequal1} \\
		&\abs{w} &&= \abs{w + z - z} &&\leq \abs{z + w} + \abs{z} \label{basicinequal2}
	\end{alignat}

	Observe that
	\begin{align*}
		\cref{basicinequal1} \implies \abs{z} - \abs{w} \leq \abs{z + w} \\
		\cref{basicinequal2} \implies \abs{w} - \abs{z} \leq \abs{z + w}
	\end{align*}

	Thus, we have that
	\begin{equation*}
		\abs{z + w} \geq \abs{\; \abs{z} - \abs{w} \;}
	\end{equation*}
	as required.\qed
\end{proof}

\cref{eq:triangle inequality} in \cref{propo:Basic Inequalities} can be generalized by the means of mathematical induction to sums involving any finite number of terms, as:
\begin{equation}\label{eq:generalized triangle inequality}
	\abs{z_1 + z_2 + \hdots + z_n} \leq \abs{z_1} + \abs{z_2} + \hdots + \abs{z_n}
\end{equation}
where $n \in \mathbb{N} \setminus \{0, 1\}$.

To note the induction proof, when $n = 2$, \cref{eq:generalized triangle inequality} is just \cref{eq:triangle inequality}. If \cref{eq:generalized triangle inequality} is true for when $n = m$ where $m \in \mathbb{N} \setminus \{0, 1\}$, $n = m + 1$ is also true since by \cref{eq:triangle inequality},
\begin{align*}
	\abs{(z_1 + z_2 + \hdots + z_m) + z_{m+1}} &\leq \abs{z_1 + z_2 + \hdots + z_m} + \abs{z_{m + 1}} \\
			&\leq (\abs{z_1} + \abs{z_2} + \hdots + \abs{z_m}) + \abs{z_{m+1}}.
\end{align*}

The distance between two points $z_1 = x_1 + iy_1, z_2 = x_2 + iy_2 \in \mathbb{C}, x_1, x_2, y_1, y_2 \in \mathbb{R}$ is $\abs{z_1 - z_2}$, since $\abs{z_1 - z_2} = \sqrt{(x_1 - x_2)^2 (y_1 - y_2)^2}$ is our usual notion of the Euclidean distance of two points on a plane.

Also, note that
\begin{equation*}
	z_1 - z_2 = z_1 + (-z_2)
\end{equation*}
and thus if we apply our knowledge of vector representation, $z_1 - z_2$ is the directed line segment from the point $z_2$ to $z_1$.

With the notion of a ``distance'' set on the complex plane, we can now explore upon points lying on a circle with a center $z_0$ and radius $R$, which satisfies the equation
\begin{equation*}
	\abs{z - z_0} = R.
\end{equation*}
We may simply refer to this set of points as the circle $\abs{z - z_0} = R$.

\begin{eg}
	We may describe a set $\left\{z \in \mathbb{C} : \abs{z -i} = 1 \right\}$ as follows:

	\begin{center}
		\begin{tikzpicture}
			\begin{axis}[four quad complex, xtick={-3,-2,...,3}, ytick={-3,-2,...,3}, xmin=-3, xmax=3, ymin=-1, ymax=3]
				\draw (axis cs:0, 1) circle [radius=1];
			\end{axis}
		\end{tikzpicture}
	\end{center}

	Let $a, b \in \mathbb{C}$ describe the set $\left\{z \in \mathbb{C} : \abs{z - a} < \abs{z - b} \right\}$.

	Suppose the following coordinates for $a$ and $b$ are arbitrary,

	\begin{center}
		\begin{tikzpicture}
			\begin{axis}[four quad complex, xmin=-15, xmax=15, ymin=-15, ymax=15]
				\draw[line width=0pt,dashed,fill=black,fill opacity=0.25](-20,20)--(-20,-20)--(20,-20)--(20,-10)--(-5,15);
				\draw (-1,13) node {$f$};
				\draw[line width=2pt,solid](2,2)--(8,8);
				\draw[color=black] (3.5,5) node {$g$};
				\node[label={0:{$a$}},circle,fill,inner sep=2pt] at (axis cs:2,2) {};
				\node[label={0:{$b$}},circle,fill,inner sep=2pt] at (axis cs:8,8) {};
			\end{axis}
		\end{tikzpicture}
	\end{center}

	In the above, $g$ is the line segment that connects the points $a$ and $b$ on the complex plane, while $f$ is the perpendicular bisector of the line segment $g$. The area described by the set $\left\{z \in \mathbb{C} : \abs{z - a} < \abs{z - b} \right\}$ is the shaded area which is below $f$.
\end{eg}

% section complex_numbers_and_their_properties (end)

% chapter lecture_1_jan_3_2018 (end)

\chapter{Lecture 2 Jan 5th 2018}
	\label{chapter:lecture_2_jan_5th_2018}

\section{Complex Numbers and Their Properties (Continued)} % (fold)
\label{sec:complex_numbers_and_their_properties_continued}

\begin{eg}
	Let $a \in \mathbb{C}$. Describe the set $\{z \in \mathbb{C} : 1 < \abs{z-a} < 2\}$.

	\begin{center}
		\begin{tikzpicture}
			\begin{axis}[
				four quad complex,
				xmin=-2, xmax=7,
				ymin=-2, ymax=7
			]
				\draw [fill=black,fill opacity=0.25,even odd rule] (3,3) circle (1.4142135623730951) (3,3) circle (1);
				\node[label={0:{$a$}},circle,fill,inner sep=1pt] at (axis cs:3,3) {};
			\end{axis}
		\end{tikzpicture}
	\end{center}
\end{eg}

\begin{eg}
	\label{eg:complex number has exactly two roots}
	Show that every non-zero complex number has exactly two complex square roots, and find a formula for the square roots.

	Let $z = x + iy \in \mathbb{C}, x, y \in \mathbb{R}$, and let $w = u + iv, u, v \in \mathbb{R}$. Then

	\begin{alignat}{3}
		&w^2 = z &&\iff && (u + iv)^2 = x + iy \nonumber \\
		&	&&\iff 	&& (u^2 - v^2) + i(2uv) = x + iy \nonumber \\
		&	&&\iff && x = u^2 + v^2 \quad \text{and} \label{tworoots 1} \\
		&	&&	   && y = 2uv \label{tworoots 2}
	\end{alignat}

	Square both sides of \cref{tworoots 2}, and thus we have $y^2 = 4u^2 v^2$.

	Multiply \cref{tworoots 1} by $4u^2$, and we get
	\begin{alignat*}{3}
		& 	  &&4u^2 x &&= 4u^4 - 4u^2 v^2 = 4u^4 - y^2 \\
		&\iff &&0 	&&= 4u^4 - 4u^2 x - y^2 \\
		&\iff &&u^2 &&= \frac{4x \pm \sqrt{16x^2 + 16y^2}}{8} \\
		&	  &&	&&= \frac{x \pm \sqrt{x^2 + y^2}}{2} 
	\end{alignat*}

	Suppose $y \neq 0$. Note that $x < \sqrt{x^2 + y^2}$. Thus $u^2 = \frac{x + \sqrt{x^2 + y^2}}{2} \implies u = \left(\frac{x + \sqrt{x^2 + y^2}}{2} \right)^{\frac{1}{2}}$.

	Similarly, we can get
	\begin{equation*}
		v = \pm \left(\frac{-x + \sqrt{x^2 + y^2}}{2}\right)^{\frac{1}{2}}
	\end{equation*}

	Note that all four choices of signs satisfy \cref{tworoots 1}. If $y > 0$, then $u$ and $v$ are either both positive or both negative by \cref{tworoots 2}.

	Suppose $y = 0$. Then we have
	\begin{equation*}
		w^2 = z = x
	\end{equation*}

	Therefore, we get
	\begin{equation*}
		w = \begin{cases}
			\pm \left[ \left(\frac{x + \sqrt{x^2 + y^2}}{2} \right)^{\frac{1}{2}} + i \left( \frac{-x + \sqrt{x^2 + y^2}}{2} \right)^{\frac{1}{2}} \right] & y > 0 \\
			\pm \left[ \left(\frac{x + \sqrt{x^2 + y^2}}{2} \right)^{\frac{1}{2}} - i \left(\frac{-x + \sqrt{x^2 + y^2}}{2} \right)^{\frac{1}{2}} \right] & y < 0 \\
			\pm \sqrt{x} & y = 0, x > 0 \\
			\pm i \sqrt{x} & y = 0, x < 0
		\end{cases}
	\end{equation*}
\end{eg}

\begin{remark}
	Let $z \in \mathbb{C}$. The notation $\sqrt{z}$ may represent either one of the square roots of $z$ or both of the square roots, i.e. \hlwarn{it is possible that $\sqrt{z}$ represents a set}.
\end{remark}

\begin{ex}\label{ex:Separation of Multiplication in Square Roots}
	Is it always okay for complex numbers such that $\sqrt{zw} = \sqrt{z} \sqrt{w}$, for $z, w \in \mathbb{C}$?

	No. For example, consider $z = w = -1$. Then we have
	\begin{equation*}
		\sqrt{zw} = \sqrt{1} = \pm 1
	\end{equation*}
	while
	\begin{equation*}
		\sqrt{z} \sqrt{w} = i \cdot i = -1
	\end{equation*}
	and thus
	\begin{equation*}
		\sqrt{zw} \neq \sqrt{z} \sqrt{w}.
	\end{equation*}
\end{ex}

\begin{eg}
	Find the values of $\sqrt{3 - 4i}$.

	By \cref{eg:complex number has exactly two roots},

	\begin{align*}
		\sqrt{3 - 4i} &= \pm \left( \sqrt{\frac{3 + \sqrt{9 + 16}}{2}} - i \sqrt{\frac{-3 + \sqrt{9 + 16}}{2}} \right) \\
			&= \pm (2 - i)
	\end{align*}
\end{eg}

\begin{remark}\label{remark:quadratic formula for complex numbers}
	The quadratic formula holds for complex polynomials, i.e.
	\begin{equation*}
		\forall a, b, c \in \mathbb{C} \quad a \neq 0 \quad \forall z \in \mathbb{C} \; az^2 + bz + c = 0,
	\end{equation*}
	the solution for $z$ is given by
	\begin{equation}\label{eq:quadractic formula for complex numbers}
		z_{1, 2} = \frac{-b + \sqrt{b^2 - 4ac}}{b} 
	\end{equation}

	The following is a short proof.

	\begin{proof}
		\begin{align*}
			az^2 + bz + c = 0 &\iff z^2 + \frac{b}{a} z + \frac{c}{a} = 0 \\
				&\iff z^2 + \frac{b}{a} z + \left(\frac{b}{2a} \right)^2 - \left(\frac{b}{2a}\right)^2 + \frac{c}{a} = 0 \\
				&\iff \left(z + \frac{b}{2a} \right)^2 = \frac{b^2}{4a^2} - \frac{c}{a} = \frac{b^2 - 4ac}{4a^2} \\
				&\iff z = \frac{-b + \sqrt{b^2 - 4ac}}{2a}  
		\end{align*}
	\end{proof}

	(Personal Note: where did the $-$ for the supposed $\pm$ go? Or should it really be $\pm$?)
\end{remark}

\begin{eg}
	Solve $iz^2 - (2 + 3i)z + 5(1 + i) = 0$.
	\begin{align*}
		z &= \frac{2 + 3i + \sqrt{(2 + 3i)^2 - 4i[5(1 + i)]}}{2i} \\
			&= \frac{2 + 3i + \sqrt{-5 + 12i -20i + 20}}{2i} \\
			&= \frac{2 + 3i + \sqrt{15 + 8i}}{2i} 
	\end{align*}
	Note that by \cref{eg:complex number has exactly two roots},
	\begin{align*}
		\sqrt{15 - 8i} &= \pm \left[ \sqrt{\frac{15 + \sqrt{225 + 64}}{2} } - i \sqrt{\frac{-15 + \sqrt{225 + 64}}{2} } \; \right] \\
			&= \pm \left[ \sqrt{\frac{15 + 17}{2} } - i \sqrt{\frac{-15 + 17}{2} } \; \right] \\
			&= \pm (4 - i)
	\end{align*}
	Thus we have
	\begin{align*}
		z &= \frac{2 + 3i + \sqrt{15 + 8i}}{2i} \\
			&= \frac{2 + 3i \pm (4 - i)}{2i} \\
			&= (6 + 2i) \left( -\frac{1}{2}i \right) \text{ or } (-2 + 4i) \left( -\frac{1}{2} i \right) \quad \text{by } \cref{eg:multiplicative inverse of a complex number} \\
			&= (1 - 3i) \text{ or } (2 + i)
	\end{align*}
\end{eg}

% section complex_numbers_and_their_properties_continued (end)

% chapter lecture_2_jan_5th_2018 (end)

\chapter{Lecture 3 Jan 8th 2018}
	\label{chapter:lecture_3_jan_8th_2018}

\section{Complex Numbers and Their Properties (Continued 2)} % (fold)
\label{sec:complex_numbers_and_their_properties_continued_2}

\begin{defn}[Argument of a Complex Number]\label{defn:Argument of a Complex Number}
	Let $z \in \mathbb{C} \setminus \{0\}$. The \hldefn{argument} (or the angle) of $z$, denoted by $\arg{z}$, $\Arg{z}$, or simply $\theta = \theta(z)$, is the angle modulo $2 \pi$ (i.e. $0 \leq \theta < 2 \pi$) between the vector defining $z$ and the positive real axis (in the counterclockwise direction).

	\begin{center}
		\begin{tikzpicture}
			\tikzset{>=stealth}
			\draw[->] (-2, 0) -- ++(4, 0) coordinate (X) node[below] {$\re$};
			\draw[->] (0, -1) -- ++(0, 3) node[left] {$\im$};
			\coordinate (O) at (0, 0);

			\draw[->] (O) -- (1,1) coordinate (z) node[above] {$z$};
			\path (X) -- (O) -- (z) pic [draw,->,pic text=$\theta$, angle eccentricity=1.3] {angle=X--O--z};

			\draw[->] (O) -- (-1.5, 1.5) coordinate (z1) node[above] {$z_1$};
			\path (X) -- (O) -- (z1) pic [draw,->,angle radius=1cm, pic text=$\theta_1$, angle eccentricity=1.2] {angle=X--O--z1};
		\end{tikzpicture}
	\end{center}
\end{defn}

\begin{notation}
	Let $e^{i \theta} := \cos \theta + i \sin \theta$. Note that this definition, called \hldefn{Euler's formula}, can be derived by the extending the Taylor expansion of $e^x = \sum_{n=0}^{\infty} \frac{x^n}{n!} $ for when $x \in \mathbb{C}$ (the sum of the real parts of the expansion is the Taylor expansion of cosine while the imaginary part for sine).

	Now $e^{i \theta}$ is on the unit circle.
	\begin{center}
		\begin{tikzpicture}
			\tikzset{>=stealth}
			\draw[->] (-2, 0) -- ++(4, 0) coordinate (X) node[below] {$\re$};
			\draw[->] (0, -2) -- ++(0, 4) node[left] {$\im$};
			\coordinate (O) at (0, 0);

			\newcommand \CircleRadius{1.5};
			\draw (0,0) circle (\CircleRadius);
			\coordinate (z) at (45:\CircleRadius);

			\draw[dotted] (O) -- (z) node[above right] {$e^{t \theta}$};
			\draw[dotted] (z) -- (z -| O) node[left] {$\sin \theta$};
			\draw[dotted] (z) -- (z |- O) node[below] {$\cos \theta$};
		\end{tikzpicture}
	\end{center}
\end{notation}

\begin{remark}
	If $z = 0$, the coordinate $\theta$ is undefined, and so it is implied that $z \neq 0$ whenever we use the polar form.
\end{remark}

\begin{eg}
Some examples of $\theta \in [0, 2\pi)$:

	\begin{tabular}{r@{\;{=}\;}l r@{\;{=}\;}l}
		$e^{i \frac{\pi}{4}}$ & $\frac{\sqrt{2}}{2} + i \frac{\sqrt{2}}{2}$ & $e^{i \frac{\pi}{2} }$ & $i$ \\
		$e^{i \frac{3 \pi}{4}}$ & $-\frac{\sqrt{2}}{2} + i \frac{\sqrt{2}}{2}$ & $e^{i \pi} + 1$ & $0$
	\end{tabular}
\end{eg}

\begin{remark}
	\begin{equation*}
		\forall k \in \mathbb{Z} \enspace \forall \theta \in \mathbb{R} \enspace e^{i\theta} = e^{i(\theta + 2\pi k)} 
	\end{equation*}
\end{remark}

\begin{remark}
	The complex number $re^{i \theta}$, where $r > 0, \theta \in [0, 2\pi)$, represents the complex number with modulus $r$ and argument $\theta$.
	\begin{center}
		\begin{tikzpicture}
			\tikzset{>=stealth}
			\draw[->] (-2, 0) -- ++(4, 0) coordinate (X) node[below] {$\re$};
			\draw[->] (0, -2) -- ++(0, 4) node[left] {$\im$};
			\coordinate (O) at (0, 0);

			\newcommand \CircleRadius{1.5};
			\draw[dotted] (0,0) circle (\CircleRadius);
			\coordinate (z) at (135:\CircleRadius);

			\draw[<->] (O) -- (z) node[midway,below] {$r$} node[above left] {$z$};
			\path (X) -- (O) -- (z) pic [draw,->,angle radius=0.5cm,pic text=$\theta$,angle eccentricity=1.3] {angle=X--O--z};
		\end{tikzpicture}
	\end{center}

	Therefore, $\forall z \in \mathbb{C}$, we can express
	\begin{equation}\label{eq:polar representation of a complex number}
		z := \abs{z} e^{i \Arg{z}}.
	\end{equation}
\end{remark}

With that, we now have two representations of a complex number:
\begin{itemize}
	\item \hlnotea{Cartesian representation}: $z = x + iy$ where $x = \re(z)$ and $y = \im(z)$
	\item \hlnotea{Polar representation}: $z = re^{i \theta}$ where $r = \abs{z}$ and $\theta = \Arg{z} \in [0, 2\pi)$
\end{itemize}

To convert between the two representations, we have the following equations:

Polar $\to$ Cartesian:

\begin{equation}\label{eq:polar to cartesian}
	x = r \cos \theta \quad y = r \sin \theta
\end{equation}

Cartesian $\to$ Polar:

\begin{gather}\label{eq:cartesian to polar}
	r = \abs{z} \nonumber \\
	x \neq 0 \implies \tan \theta = \frac{y}{x} \\
	x = 0 \implies \theta = \frac{\pi}{2} \text{ or } \frac{3\pi}{2} \nonumber
\end{gather}

On another note,
\begin{equation*}
	z = re^{i \theta} \implies \bar{z} = re^{-i \theta}
\end{equation*}
and
\begin{equation}\label{eq:inverse of nonzero complex number in polar coords}
	z \neq 0 \implies \frac{1}{z} = \frac{1}{r} e^{-i \theta}
\end{equation}

\begin{remark}
	\begin{gather*}
		\forall r_1, r_2 \in \mathbb{R} \; \forall \theta_1, \theta_2 \in [0, 2\pi) \\
		z_1 := r_1 e^{i \theta_1} \quad z_2 := r_2 e^{i \theta_2}
	\end{gather*}
	Then
	\begin{equation*}
		z_1 z_2 = r_1 r_2 e^{i \theta_1} e^{i \theta_2} = r_1 r_2 e^{i (\theta_1 + \theta_2)}
	\end{equation*}

	Note that $e^{ix} e^{iy} = e^{i(x + y)}$ is true for all $x, y \in \mathbb{R} $ since
	\begin{align*}
		e^{ix} e^{iy}
			&= (\cos x + i \sin x)(\cos y + i \sin y) \\
			&= (\cos x \cos y - \sin x \sin y) + i (\cos x \sin y + \cos y \sin x) \\
			&= \cos (x + y) + i \sin (x + y) \\
			&= e^{i (x + y)}.
	\end{align*}

	Generalizing the above, we get that
	\begin{equation}\label{eq:demoivre's law}
		\forall n \in \mathbb{Z} \enspace z = (re^{in}) = r^n e^{in\theta}
	\end{equation}
	which is commonly known as \hldefn{deMoivre's Law}. Note that by simply generalizing the above, all we have is that $n \in \mathbb{Z^+}$. But by \cref{eq:inverse of nonzero complex number in polar coords}, we can have that for $n \in \mathbb{Z^-}$, let $m = -n$, and thus
	\begin{equation*}
		z^n = \left[ \frac{1}{r} e^{i (-\theta)} \right]^m = \left(\frac{1}{r}\right)^m e^{im (-\theta)} = \left(\frac{1}{r} \right)^{-n} e^{i (-n) (-\theta)} = r^n e^{i\theta}
	\end{equation*}
	This proves that deMoivre's Law also holds for when $n \in \mathbb{Z^-}$.

	Observe that if $r = 1$, \cref{eq:demoivre's law} becomes
	\begin{equation}
		(e^{i\theta})^n = e^{in\theta} \quad \text{for all } n \in \mathbb{Z} \setminus \{0\} 
	\end{equation}
	When written in the form
	\begin{equation}\label{eq:demoivre's formula}
		(\cos \theta + i \sin \theta)^n = \cos n\theta + i \sin n\theta \quad (n \in \mathbb{Z} \setminus \{0\})
	\end{equation}
	this is known as \hldefn{deMoivre's formula}.
\end{remark}

\begin{eg}
	\cref{eq:demoivre's formula} with $n = 2$ tells us that
	\begin{equation*}
		(\cos \theta + i \sin \theta)^n = \cos 2\theta + i \sin 2\theta
	\end{equation*}
	or we can express the equation as
	\begin{equation*}
		\cos^2 \theta - \sin^2 \theta + i2 \sin\theta \cos\theta = \cos 2\theta + i \sin 2\theta
	\end{equation*}
	Equating real and imaginary parts, we have the familiar double angle trigonometric identities
	\begin{equation*}
		\cos 2\theta = \cos^2 \theta - \sin^2 \theta, \quad \sin 2\theta = 2\sin\theta\cos\theta.
	\end{equation*}
\end{eg}

\subsection{Roots of Complex Numbers} % (fold)
\label{sub:roots_of_complex_numbers}

\begin{propo}[nth Roots of a Complex Number]\label{propo:nth Roots of a Complex Number}
	\begin{gather*}
		\forall z = re^{i\theta} \in \mathbb{C} \enspace r = \abs{z} \in \mathbb{R} \enspace \theta \in [0, 2\pi) \\
		\exists w = se^{i\tau} \in \mathbb{C} \enspace s \in \mathbb{R} \enspace \tau \in [0, 2\pi) \\
		\forall n \in \mathbb{Z} \\ 
		w^n = \left( se^{i\tau}\right)^n = z = re^{i\theta}
	\end{gather*}

	The nth roots of $z$ is described by the set
	\begin{equation}\label{eq:nth roots of a complex number}
		\left\{ r^{\frac{1}{n}} e^{i \left(\frac{\theta + 2 \pi k}{n} \right)} : k = 0, 1, ..., n - 1 \right\}
	\end{equation}

	\begin{proof}
		\begin{gather*}
			s^n = r \iff s = r^{\frac{1}{n}} \\
			e^{in\theta} = e^{i \tau} \iff \theta = \frac{\tau + 2 \pi k}{n}
		\end{gather*}

		Therefore, the set that describes the nth roots of $z$ is
		\begin{gather*}
			\left\{ w = r^\frac{1}{n} e^{i \left( \frac{\theta + 2 \pi k}{n} \right)} : k = 0, 1, ..., n - 1 \right\}
		\end{gather*}
	\end{proof}
\end{propo}

\begin{remark}[nth Roots of Unity]\label{remark:nth Roots of Unity}
	The \hlnotea{nth roots of unity} is a direct consequence of \cref{propo:nth Roots of a Complex Number} where we solve for the equation $z^n = 1$ for any $z \in \mathbb{C}, n \in \mathbb{Z}$.

	The set that describes the nth roots of unity is
	\begin{equation}\label{eq:nth roots of unity}
		\left\{ e^{i \theta} : \theta = \frac{2 \pi k}{n}, k = 0, 1, ..., n - 1 \right\}
	\end{equation}
\end{remark}

It is easy to see how the nth roots of unity \hlnoteb{partitions the unit circle into n parts}.

\begin{eg}
	Find the cubic roots of $-2 + 2i$.

	Let $z = -2 + 2i$. Note that $\abs{z} = 2\sqrt{2}$ and $\Arg{z} = \frac{3 \pi }{4}$.

	Therefore, in polar form, $z = 2 \sqrt{2} e^{i \frac{3\pi}{4} }$.

	Let $w = re^{i \theta}$, where $\theta \in [0, 2\pi)$, and $w^3 = z$. Then
	\begin{gather*}
		r = (2 \sqrt{2})^\frac{1}{3} \\
		\theta = \frac{\frac{3\pi}{4} + 2 \pi k}{3}, \enspace k = 0, 1, 2
	\end{gather*}

	The set that describes the cubic root of $-2 + 2i$ is thus
	\begin{equation*}
		\left\{ (2\sqrt{2})^\frac{1}{3} e^{i \theta} : \theta = \frac{\frac{3\pi}{4} + 2 \pi k}{3}, k = 0, 1, 2 \right\}
	\end{equation*}
\end{eg}

\begin{eg}
	Describe the set $\{z \in \mathbb{C} : \abs{\Arg{z} - \frac{\pi}{2}} < \frac{\pi}{2} \}$. (Note: $\Arg{z} \in [0, 2\pi)$)

	\begin{center}
		\begin{tikzpicture}
			\begin{axis}[four quad complex, xmin=-2, xmax=2, ymin=-1, ymax=2]
				\draw[line width=0pt,dashed,fill=black,fill opacity=0.25](-3,0)--(3,0)--(3,3)--(-3,3);
			\end{axis}
		\end{tikzpicture}
	\end{center}
\end{eg}

\begin{ex}
	Solve
	\begin{enumerate}
		\item $z^4 = -1$
			\begin{gather*}
				\text{Let } z = re^{i \theta} \\
				r = \abs{-1} = 1 \quad \theta = \frac{\pi + 2 \pi k}{4} = \frac{(2k + 1) \pi}{4}, \enspace k = 0, 1, 2, 3
			\end{gather*}
		\item $z^4 = -1 + \sqrt{3} i$
			\begin{gather*}
				\text{Let } z = re^{i \theta} \\
				r = \abs{-1 + \sqrt{3} i} = \sqrt{(-1)^2 + 3^2} = \sqrt{10} \\
				\theta = \frac{\frac{2\pi}{3} + 2\pi k}{4} = \frac{(2k + \frac{2}{3}) \pi}{4}, \quad k = 0, 1, 2, 3  
			\end{gather*}
	\end{enumerate}
\end{ex}

% subsection roots_of_complex_numbers (end)

% section complex_numbers_and_their_properties_continued_2 (end)

% chapter lecture_3_jan_8th_2018 (end)

\chapter{Lecture 4 Jan 10th 2018}
	\label{chapter:lecture_4_jan_10th_2018}

\section{Examples for nth Roots of Unity} % (fold)
\label{sec:examples_for_nth_roots_of_unity}

Recall that the $n$th roots of unity are given by $e^{i \frac{2\pi k}{n}}, k = 0, 1, ..., n - 1$.

\begin{ex}\label{ex:sum of root of unity other than one is negative one}
	Let $z$ be any $n$th root of unity other than 1. Show that
	\begin{equation}
		z^{n - 1} + z^{n - 2} + \hdots + z + 1 = 0
	\end{equation}

	\begin{proof}
		By the Sum of Finite Geometric Terms,
		\begin{equation*}
			z^{n - 1} + z^{n - 2} + \hdots + z + 1 = \frac{1 - z^n}{1 - z}.
		\end{equation*}
		Since $z^n = 1$, RHS is thus zero, which in turn completes the proof.
	\end{proof}
\end{ex}

As an aside, if we wish to remove the restriction that $z$ can also be 1, we may consider that
\begin{equation*}
	z^n - 1 = (z - 1)(1 + z + \hdots + z^{n - 1})
\end{equation*}
Since $z^n = 1$, LHS is zero. Then either $z = 1$ or $(1 + z + \hdots + z^{n - 1}) = 0$.

\begin{ex}
	Consider the $n - 1$ diagonals of a regular $n$-gon, inscribed in a circle of radius 1, obtained by connecting one vertex on the $n$-gon to all its other vertices.

	For example, if we are given $n = 6$, we obtain the following diagram.

	\begin{figure}[H]
		\begin{center}
			\begin{tikzpicture}
				\newcommand \CircleRadius {2};
				\draw(0, 0) circle (\CircleRadius);
				\coordinate (a) at (180:\CircleRadius);
				\coordinate (z1) at (120:\CircleRadius);
				\coordinate (z2) at (60:\CircleRadius);
				\coordinate (z3) at (0:\CircleRadius);
				\coordinate (z4) at (300:\CircleRadius);
				\coordinate (z5) at (240:\CircleRadius);
				\node[label={180:{$a$}},circle,fill,inner sep=1pt] at (a) {};
				\foreach \x in {1, ..., 5} {
					\draw (a)--(z\x) node[midway, above] {$z_\x$};
				};
				\draw[dotted] (0:\CircleRadius) \foreach \x in {0, 60, ..., 300} {
					-- (\x:\CircleRadius)
				} -- cycle;
			\end{tikzpicture}
		\end{center}
		\caption[loftitle]{$n = 6$, where $a$ is an arbitrary vertex on the hexagon}
		\label{figure:regular hexagon with one point connected to all other vertices}
	\end{figure}

	Show that the product of the lengths of these diagonals is equal to n.

	\begin{proof}
		Note that \cref{figure:regular hexagon with one point connected to all other vertices} can be translated into \cref{figure:regular n-gon with roots of unity}.

		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}
					\tikzset{>=stealth}
					\draw[->] (-3, 0) -- ++(6, 0) coordinate (X);
					\draw[->] (0, -3) -- ++(0, 6);
					\newcommand \CircleRadius {2};
					\newcommand \Vertices {10};
					\draw(0, 0) circle (\CircleRadius);
					\foreach \i [evaluate=\i as \x using (\i - 1)*(360 / \Vertices)] in {1, ..., 6} {
						\coordinate (z\i) at (\x:\CircleRadius);
						\ifthenelse{\i<5}{
							\node[label={\x:{\ifthenelse{\i=1}{$a=z_\i$}{$z_\i$}}},circle,fill,inner sep=1pt] at (z\i) {};
						}{};
					};
					\foreach \i [evaluate=\i as \j using \i + 1] in {1, ..., 5} {
						\ifthenelse{\i<4}{
							\draw (z\i)--(z\j);
						}{
							\draw[dotted] (z\i)--(z\j);
						}
					}
					\draw (z1)--(z3);
					\draw (z1)--(z4);
					\draw[dotted] (z1)--(z5);
				\end{tikzpicture}
			\end{center}
			\caption[loftitle]{A regular $n$-gon with the roots of unity on its vertices}
			\label{figure:regular n-gon with roots of unity}
		\end{figure}

		Thus the equation that we wish to prove becomes
		\begin{equation}\label{eq:total length from one vertex to all others is n}
			\abs{1 - z_2}\abs{1 - z_3}\hdots\abs{1 - z_n} = n
		\end{equation}
		Note that $z_2, ..., z_n$ are the $n$th roots of unity other than 1.

		Let $z$ be a variable and consider the polynomial
		\begin{equation}\label{eq:roots of unity polynomial}
			P(z) := 1 + z + z^2 + \hdots + z^{n - 1}
		\end{equation}
		Since the roots of $P(z)$ are the $n$th roots of unity other than 1, we can factorize \cref{eq:roots of unity polynomial} into
		\begin{equation*}
			P(z) = (z - z_2)(z - z_3) \hdots (z - z_n)
		\end{equation*}
		Now let $z = 1$ and take the modulus of $P(z)$, and we get \cref{eq:total length from one vertex to all others is n}.
	\end{proof}
\end{ex}

\begin{ex}
	Let $n \in \mathbb{N}$. Show that $\sum_{j=0}^{n} \binom{3n}{3j} = \frac{2^{3n} + 2(-1)^n}{3}$.

	\begin{proof}
		Let $\alpha = e^{i \frac{2\pi}{3}}$. Then $\alpha$ is a cubic root of unity, i.e. $\alpha^3 = 1$, and from \cref{ex:sum of root of unity other than one is negative one}, $1 + \alpha + \alpha^2 = 0$.

		Consider
		\begin{align}
			\begin{split}\label{eq:combinatorial problem solved in complex terminology 1}
			(1 + 1)^{3n}
				=& \binom{3n}{0} + \binom{3n}{1} + \binom{3n}{2} + \binom{3n}{3} + \binom{3n}{4} \\
				&+ \binom{3n}{5} + \binom{3n}{6} + \hdots + \binom{3n}{3n}
			\end{split} \\
			\begin{split}\label{eq:combinatorial problem solved in complex terminology 2}
			(1 + \alpha)^{3n}
				=& \binom{3n}{0} + \binom{3n}{1}\alpha + \binom{3n}{2}\alpha^2 + \binom{3n}{3} + \binom{3n}{4}\alpha \\
				&+ \binom{3n}{5}\alpha^2 + \binom{3n}{6} + \hdots + \binom{3n}{3n}
			\end{split} \\
			\begin{split}\label{eq:combinatorial problem solved in complex terminology 3}
			(1 + \alpha^2)^{3n}
				=&\binom{3n}{0} + \binom{3n}{1}\alpha^2 + \binom{3n}{2}\alpha + \binom{3n}{3} + \binom{3n}{4}\alpha^2 \\
				&+ \binom{3n}{5}\alpha + \binom{3n}{6} + \hdots + \binom{3n}{3n}
			\end{split}
			\phantom{a}
		\end{align}

		Adding \cref{eq:combinatorial problem solved in complex terminology 1}, \cref{eq:combinatorial problem solved in complex terminology 2} and \cref{eq:combinatorial problem solved in complex terminology 3}, we observe that the terms with coefficients $\binom{3n}{k}$ where $k$ is not a multiple of 3 sums to 0 as given by $1 + \alpha + \alpha^2 = 0$, and therefore we obtain
		\begin{align*}
			2^{3n} + (1 + \alpha)^{3n} + (1 + \alpha^2)^{3n} &= 3 \sum_{j=0}^{n} \binom{3n}{3j} \\
			\frac{1}{3} \left[2^{3n} + (1 + \alpha)^{3n} + (1 + \alpha^2)^{3n}\right] &= \sum_{j=0}^{n} \binom{3n}{3j} \\
			\frac{1}{3} \left[2^{3n} + (-\alpha^2)^{3n} + (-\alpha)^{3n} \right] &= \sum_{j=0}^{n} \binom{3n}{3j} \quad \text{since } 1 + \alpha + \alpha^2 = 0 \\
			\frac{1}{3} \left[2^{3n} + (-1)^n + (-1)^n \right] &= \sum_{j=0}^{n} \binom{3n}{3j} \quad \text{since } \alpha^3 = 1 \\
			\frac{2^{3n} + 2(-1)^n}{3} &= \sum_{j=0}^{n} \binom{3n}{3j}
		\end{align*}
		as required.
	\end{proof}
\end{ex}

\begin{ex}
	Note that we can define $\Arg{z}$ in any interval of length $2 \pi$, i.e. it is not necessary that $\Arg{z} \in [0, 2\pi)$.

	For example, if we restrict $\Arg{z} \in [-\pi, \pi]$, then we can write
	\begin{equation*}
		\Arg{\left(-\frac{1}{\sqrt{2}} - \frac{1}{\sqrt{2}} i \right)} = - \frac{3\pi}{4}
	\end{equation*}

	Let $z$ be on the unit circle and $\Arg{z} \in [-\pi, \pi]$. Suppose that $z \notin \mathbb{R}$, i.e. $z \neq 1, z \neq -1$. Show that
	\begin{equation*}
		\Arg{\left( \frac{z-1}{z+1} \right)} = \begin{cases}
			\frac{\pi}{2} & \im{z} > 0 \\
			-\frac{\pi}{2} & \im{z} < 0
		\end{cases}
	\end{equation*}

	\begin{proof}
		Note that $\forall w_1, w_2 \in \mathbb{C}$, where $\Arg{w_1} = \tau_1, \Arg{w_2} = \tau_2$ for $\tau_1, \tau_2$ in the same $2\pi$-interval,
		\begin{equation}\label{eq:angle division modulo 2 pi}
			\Arg{\frac{w_1}{w_2} = \frac{e^{i\tau_1}}{e^{i\tau_2}} \equiv e^{i (\tau_1 - \tau_2)} = \Arg{w_1} - \Arg{w_2}}
		\end{equation}
		in modulo $2\pi$.

		Suppose $\im{z} > 0$. Let $\theta_1 = \Arg{(z - 1)}$ and $\theta_2 = \Arg{(z + 1)}$. Consider \cref{figure:angle division example}. Note that since both $\theta_1, \theta_2 \in [0, \pi]$, we have that $\theta_1 - \theta_2 \in [-\pi, \pi]$, and thus \cref{eq:angle division modulo 2 pi} holds true without the need of the condition of being in modulo $2 \pi$. We observe that
		\begin{align*}
			\frac{\pi}{2} &= \theta_2 + \pi - \theta_1 \\
			\theta_1 - \theta_2 &= \frac{\pi}{2}
		\end{align*}
		as desired.

		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}
					\tikzset{>=stealth}
					\draw[->] (-2, 0) -- ++(4, 0) coordinate (X);
					\draw[->] (0, -2) -- ++(0, 4);
					\coordinate (O) at (0,0);
					\draw (0,0) circle (1);
					\coordinate (z) at (60:1);
					\node[label={90:{$z$}},circle,fill,inner sep=1pt] at (z) {};
					\coordinate (z-1) at ($(z) + (-1,0)$);
					\node[label={90:{$z-1$}},circle,fill,inner sep=1pt] at (z-1) {};
					\coordinate (z+1) at ($(z) + (1,0)$);
					\node[label={90:{$z+1$}},circle,fill,inner sep=1pt] at (z+1) {};
					\draw[dotted] (z+1)--(z-1);
					\draw[dotted] (O)--(z-1);
					\draw[dotted] (O)--(z+1);
					\path (X) -- (O) -- (z-1) pic [draw,->,pic text=$\theta_1$, angle radius=0.3cm,angle eccentricity=1.6] {angle=X--O--z-1};
					\path (X) -- (O) -- (z+1) pic [draw,->,pic text=$\theta_2$, angle radius=1.2cm,angle eccentricity=1.2] {angle=X--O--z+1};
				\end{tikzpicture}
				\hspace{3cm}
				\begin{tikzpicture}
					\tikzset{>=stealth}
					\draw[->] (-2, 0) -- ++(4, 0) coordinate (X);
					\draw[->] (0, -2) -- ++(0, 4);
					\coordinate (O) at (0,0);
					\draw (0,0) circle (1);
					\coordinate (z) at (60:1);
					\node[label={90:{$z$}},circle,fill,inner sep=1pt] at (z) {};
					\coordinate (z-1) at ($(z) + (-1,0)$);
					\node[label={90:{$z-1$}},circle,fill,inner sep=1pt] at (z-1) {};
					\coordinate (z+1) at ($(z) + (1,0)$);
					\node[label={90:{$z+1$}},circle,fill,inner sep=1pt] at (z+1) {};
					\coordinate (-1) at (180:1);
					\coordinate (1) at (0:1);
					\draw[dotted] (z+1)--(z-1);
					\draw[dotted] (O)--(z-1);
					\draw[dotted] (O)--(z+1);
					\draw (-1)--(z);
					\draw (1)--(z);
					\path (X)--(-1)--(z) pic[draw,->,pic text=$\theta_2$,angle eccentricity=1.5] {angle=X---1--z};
					\path (X)--(1)--(z) pic[draw,->,pic text=$\theta_1$,angle radius=0.3cm,angle eccentricity=1.6] {angle=X--1--z};
					\tkzMarkRightAngle[size=0.2,color=black](-1,z,1);
				\end{tikzpicture}
			\end{center}
			\caption[loftitle]{(Right) Depicted question, (Left) Translated Angles}
			\label{figure:angle division example}
		\end{figure}

		Similarly, we can obtain $\theta_1 - \theta_2 = -\frac{\pi}{2}$ for when $\im{z} < 0$. This completes the proof.
	\end{proof}
\end{ex}

\begin{ex}
	Let $f(z) = e^z$ for $z \in \mathbb{C}$. Let $A = \{z = x + iy \in \mathbb{C} : x \leq 1, y \in [0, \pi] \}$. Describe the image of $f(A)$.

	\begin{solution}
		Firstly, note that
		\begin{align*}
			e^z &= e^{x + iy} \\
			e^x &\in (0, e] \\
			y &\in [0, \pi]
		\end{align*}

		\begin{figure}[H]
			\begin{center}
				\begin{tikzpicture}
					\tikzset{>=stealth}
					\draw[->] (-2, 0) -- ++(4, 0) coordinate (X) node[below, right] {$\re$};
					\draw[->] (0, -2) -- ++(0, 4) node[above,right] {$\im$};
					\draw [draw=none,fill=black,fill opacity=0.25] (-2,0) rectangle (1,1.5);
					\draw (1,0)--(1,1.5)--(-2,1.5);
					\node[label={270:{$1$}}] at (1,0) {};
					\node[label={155:{$\pi$}}] at (0,1.5) {};
				\end{tikzpicture}
				\hspace{3cm}
				\begin{tikzpicture}
					\tikzset{>=stealth}
					\draw[->] (-2, 0) -- ++(4, 0) coordinate (X) node[below,right] {$\re$};
					\draw[->] (0, -2) -- ++(0, 4) node[above,right] {$\im$};
					\begin{scope}
					    \clip (-1,0) rectangle (1,1);
					    \draw[fill=black,fill opacity=0.25] (0,0) circle(1);
					    \draw (-1,0) -- (1,0);
					\end{scope}
					\node[label={270:{$e$}}] at (1,0) {};
					\node[label={270:{$-e$}}] at (-1,0) {};
					\node[label={155:{$e$}}] at (0,1) {};
				\end{tikzpicture}
			\end{center}
			\caption[loftitle]{(Right) Domain of $f(A)$, (Left) Image of $f(A)$}
			\label{figure:domain and image of f(A)}
		\end{figure}

		It is clear that the image will be in on the positive side of the imaginary-axis. Also, since $e^x \in (0, e]$, we get the right graph represented in \cref{figure:domain and image of f(A)}. The image of $f(A)$ is described in the left image of \cref{figure:domain and image of f(A)}.
	\end{solution}
\end{ex}

% section examples_for_nth_roots_of_unity (end)

% chapter lecture_4_jan_10th_2018 (end)

\chapter{Lecture 5 Jan 12 2018}
	\label{chapter:lecture_5_jan_12_2018}

\section{Complex Functions} % (fold)
\label{sec:complex_functions}

\subsection{Limits} % (fold)
\label{sub:limits}

\begin{defn}[Convergence]\label{defn:Convergence}
	A sequence of complex numbers $z_1, z_2, z_3, ...$ \hldefn{converges} to $z \in \mathbb{C}$ if
	\begin{equation}
		\lim_{n \to \infty} \abs{z_n - z} = 0
	\end{equation}
	or we may say
	\begin{equation}
		\forall \epsilon > 0 \enspace \exists N \in \mathbb{N} \enspace \forall n > N \enspace \abs{z_n - z} < \epsilon
	\end{equation}
\end{defn}

\begin{note}
 If $\{z_n\}_{n \in \mathbb{N}}$ converges to $z$, we may write $\lim_{n \to \infty} z_n = z$ or $z_n \to z$ (as $n \to \infty$).
\end{note}

\begin{eg}
	For $\abs{z} > 1$, does $\{\frac{1}{z^n}\}^\infty_{n = 1}$ converge? Explain.

	\begin{solution}
		We claim that the limit is 0. Since $\abs{z} > 1$, we have that
		\begin{align*}
			\lim_{n \to \infty} \abs{\frac{1}{z^n} - 0}
				&= \lim_{n \to \infty} \abs{\frac{1}{z}}^n \\
				&= 0
		\end{align*}

		Another way to prove this, since $\abs{z} > 1 \implies 0 < \abs{\frac{1}{z}} < 1$,
		\begin{gather*}
			\forall \epsilon = \abs{\frac{1}{z}} > 0 \\
			\abs{\frac{1}{z^n} - 0} = \abs{\frac{1}{z}}^n < \abs{\frac{1}{z}} = \epsilon
		\end{gather*}
	\end{solution}
\end{eg}

\begin{defn}[Convergence for Complex Functions]\label{defn:Convergence for Complex Functions}
	$\forall \Omega \subseteq \mathbb{C}$, let $f: \Omega \to \mathbb{C}$. We say that
	\begin{equation}
		\lim_{z \to z_0} f(z) = L
	\end{equation}
	for some $L \in \mathbb{C}$ if for every sequence $\{z_n\}_n \subseteq \Omega$ (not including $z_0$ if it is in $\Omega$), we have that
	\begin{equation}
		z_n \to z_0 \implies f(z_n) \to L
	\end{equation}
	Note that $L$ need not be in $\Omega$.
\end{defn}

\begin{eg}\label{eg:limit dne}
	Let $f(z) = \frac{\bar{z}}{z}, z \in \mathbb{C} \setminus \{0\}$. Find $\lim_{z \to 0} f(z)$.

	\begin{solution}
		Suppose $z = x \in \mathbb{R} \setminus \{0\}$. Then $f(z) = f(x) = \frac{x}{x} = 1$.

		Suppose $z = iy, y \in \mathbb{R} \setminus \{0\}$. Then $f(z) = f(iy) = \frac{-iy}{iy} = -1$.

		Therefore, the limit $\lim_{z \to 0} f(z)$ does not exist.
	\end{solution}
\end{eg}

\begin{ex}\label{ex:convergence in complex iff convergence of real and imaginary parts in real}
	Show that $z_n \to z \iff \re(z_n) \to \re(z) \land \im(z_n) \to \im(z)$. \\
	(Hint: $\abs{\re(z)}, \abs{\im(z)} \leq \abs{z} \leq \abs{\re(z)} + \abs{\im(z)}$)

	\begin{solution}
		Suppose $z_n \to z$. Then $\forall \epsilon_0 > 0 \; \exists N \in \mathbb{N} \; \forall n > N \; \abs{z_n - z} < \epsilon$. Note once and for all that
		\begin{gather*}
			\re(z_n - z) = \re(z_n) - \re(z) \\
			\im(z_n - z) = \im(z_n) - \im(z).
		\end{gather*}
		Thus
		\begin{align*}
			\abs{\re(z_n) - \re(z)} &= \abs{\re(z_n - z)} \\
					&\leq \abs{z_n - z} < \epsilon \\
			\abs{\im(z_n) - \im(z)} &= \abs{\im(z_n - z)} \\
					&\leq \abs{z_n - z} < \epsilon
		\end{align*}

		For the other direction,
		\begin{gather*}
			\forall \frac{\epsilon}{2} > 0 \enspace \exists N_0 \in \mathbb{N} \enspace \forall n > N_0 \enspace \abs{\re(z_n) - \re(z)} < \frac{\epsilon}{2} \\
			\forall \frac{\epsilon}{2} > 0 \enspace \exists N_1 \in \mathbb{N} \enspace \forall n > N_1 \enspace \abs{\im(z_n) - \im(z)} < \frac{\epsilon}{2}.
		\end{gather*}
		Therefore,
		\begin{align*}
			\abs{z_n - z} &= \abs{\re(z_n) + \im(z_n) - \re(z) - \im(z)} \\
				&\leq \abs{\re(z_n) - \re(z)} + \abs{\im(z_n) - \im(z)} \\
				&\leq \epsilon
		\end{align*}
		$\qed$
	\end{solution}
\end{ex}

% subsection limits (end)

\subsection{Continuity} % (fold)
\label{sub:continuity}

\begin{defn}[Continuity]\label{defn:Continuity}
	$\forall \Omega \subseteq \mathbb{C}$, let $f: \Omega \to \mathbb{C}$. We say that $f$ is \hldefn{continuous} at $z_0 \in \Omega$ if
	\begin{enumerate}
		\item $\forall \{z_n\}_{n \in \mathbb{N}} \\
				z_n \to z_0 \implies f(z_n) \to f(z_0)$
		\item $\forall \epsilon > 0 \enspace \exists \delta > 0 \\
				\abs{z - z_0} < \delta \implies \abs{f(z) - f(z_0)} < \epsilon$
	\end{enumerate}
\end{defn}

\begin{remark}
	\begin{enumerate}
		\item $f$ is continuous on $\Omega$ if it is continuous on every point in $\Omega$.
		\item We may \hlnotea{split} $f$ into its feal and imaginary parts, i.e.
			\begin{equation}\label{eq:complex function expressed in real-valued functions}
				f(z) = f(x, y) = u(x, y) + iv(x, y)
			\end{equation}
			where $u, v : \mathbb{R}^2 \to \mathbb{R}$.
	\end{enumerate}
\end{remark}

\begin{eg}
	Let $f: \mathbb{C} \to \mathbb{C}$ and for $z \in \mathbb{C}, f(z) = \frac{\bar{z}}{z}$. To split $f$ into real and imaginary parts:
	\begin{align*}
		f(z) &= \frac{\bar{z}}{z} \\
			&= (x + iy)\left(\frac{x}{x^2 + y^2} - i \frac{y}{x^2 + y^2} \right) \\
			&= \frac{x^2 - y^2}{x^2 + y^2} + i \frac{(-2xy)}{x^2 + y^2} 
	\end{align*}
	and we get
	\begin{align*}
		u(x, y) &= \frac{x^2 - y^2}{x^2 + y^2} \\
		v(x, y) &= -\frac{2xy}{x^2 + y^2} 
	\end{align*}
\end{eg}

% subsection continuity (end)

% section complex_functions (end)

% chapter lecture_5_jan_12_2018 (end)

\chapter{Lecture 6 Jan 15th 2018}
	\label{chapter:lecture_6_jan_15th_2018}

\section{Continuity (Continued)} % (fold)
\label{sec:continuity}

\begin{ex}\label{ex:continuity in complex iff continuity in real-valued functions in real}
	Let $f: \Omega \to \mathbb{C}$. Prove that $f(z)$ is continuous at $z_0 = x_0 + iy_0 \in \mathbb{C} \iff$ functions $u, v: \mathbb{R}^2 \to \mathbb{R}$, such that $f(z) = u(x, y) + iv(x,y)$ are both continuous at $(x_0, y_0)$.

	\begin{solution}
		We shall first prove the forward direction. Suppose that $f(z)$ is continuous at $z_0 = x_0 + iy_0 \in \mathbb{C}$. By \cref{defn:Continuity}, $\forall \{z_n\}_{n \in \mathbb{N}} \subseteq \Omega$, $z_n \to z_0 \implies f(z_n) \to f(z_0)$. By \cref{ex:convergence in complex iff convergence of real and imaginary parts in real},
		\begin{align}
			z_n \to z_0 &\iff \re z_n \to \re z_0 \land \im z_n \to \im z_0 \nonumber \\
				&\iff x_n \to x_0 \land y_n \to y_0 \label{eq:continuity in complex iff continuity in real-valued functions in real 1}
		\end{align}
		where $z_n = x_n + iy_n$ for $x_n, y_n \in \mathbb{R}$.

		Similarly so, and by \cref{eq:complex function expressed in real-valued functions},
		\begin{equation}\label{eq:continuity in complex iff continuity in real-valued functions in real 2}
			f(z_n) + f(z_0) \iff u(x_n, y_n) \to u(x_0, y_0) \land v(x_n, y_n) \to v(x_0, y_0)
		\end{equation}

		Putting together \cref{eq:continuity in complex iff continuity in real-valued functions in real 1} and \cref{eq:continuity in complex iff continuity in real-valued functions in real 2}, we get
		\begin{equation*}
			(x_n, y_n) \to (x_0, y_0) \implies u(x_n, y_n) \to u(x_0, y_0) \land v(x_n, y_n) \to v(x_0, y_0)
		\end{equation*}
		as desired.

		The proof of the other direction is simply a reversed process of the above. \qed
	\end{solution}
\end{ex}

% section continuity (end)

\section{Differentiability} % (fold)
\label{sec:differentiability}

\begin{defn}[Neighbourhood]\label{defn:Neighbourhood}
	For $z_0 \in \mathbb{C}, r \in \mathbb{R}$, let
	\begin{equation}\label{eq:neighbourhood_set}
		D(z_0, r) := \{ z \in \mathbb{C} : \abs{z - z_0} < r \}.
	\end{equation}
	On the complex plane, this is seen as a open disk centered around the point $z_0$ with radius $r$, as shown below.
	\begin{figure}[H]
		\begin{center}
			\begin{tikzpicture}
				\tikzset{>=stealth}
				\draw[->] (-1, 0) -- ++(5, 0) coordinate (X) node[below,right] {$\re$};
				\draw[->] (0, -1) -- ++(0, 5) node[above,right] {$\im$};
				\draw[dashed,fill=black,fill opacity=0.25] (2, 2) circle (1);
				\coordinate (a) at (1, 2);
				\coordinate (z0) at (2, 2);
				\node[label={0:{$z_0$}},fill,circle,inner sep=1pt] at (z0) {};
				\draw[<->] (z0)--(a) node[midway, above] {$r$};
			\end{tikzpicture}
		\end{center}
		\caption[loftitle]{Open disk centered around $z_0$ with radius $r$}
		\label{figure:neighbourhood_open_disk}
	\end{figure}
	This open disk is called a \hldefn{neighbourhood} of $z_0$.
\end{defn}

\begin{defn}[Differentiable/Holomorphic]\label{defn:Differentiable/Holomorphic}
	Let $f(z)$ be defined in a neighbourhood of $z_0 \in \mathbb{C}$. We say $f$ is \hldefn{differentiable/holomorphic} at $z_0$ if for some $h \in \mathbb{C}$,
	\begin{equation}\label{eq:holomorphic}
		\lim_{h \to 0} \frac{f(z_0 + h) - f(z_0)}{h} 
	\end{equation}
	exists. If such a limit exists, we denote the limit by $f'(z_0)$.
\end{defn}

\begin{remark}
	$h \in \mathbb{C}: h$ need not necessarily be real. In this sense, $h$ approaches $0$ from \hlwarn{any direction} around $0 \in \mathbb{C}$.
\end{remark}

\begin{eg}
	For $z \in \mathbb{C} \setminus \{0\},$ let $f(z) = \frac{1}{z}$. Let $z_0 \in \mathbb{C} \setminus \{0\}$. Note that
	\begin{equation*}
		\lim_{h \to 0} \frac{\frac{1}{z_0 + h} - \frac{1}{z_0}}{h} = \lim_{h \to 0} \frac{1}{h} \left[ \frac{-h}{(z_0 + h)z_0} \right] = -\frac{1}{z_0^2} 
	\end{equation*}
	Thus $f$ is holomorphic at any $z \in \mathbb{C} \setminus \{0\}$, and hence $f'(z) = -\frac{1}{z}$.
\end{eg}

\begin{eg}
	For $z \in \mathbb{C},$ let $f(z) = \bar{z}$. Let $z_0 \in \mathbb{C}$. Notice that
	\begin{equation*}
		\lim_{h \to 0} \frac{\bar{z_0 + h} - \bar{z}}{h} = \lim_{h \to 0} \frac{\bar{h}}{h}.
	\end{equation*}
	From \cref{eg:limit dne}, we know that such a limit does not exist. Thus $f$ is not holomorphic on any $z \in \mathbb{C}$.
\end{eg}

\begin{ex}[Holomorphic Functions Properties]\label{ex:holomorphic_functions_properties}
	If $f, g$ are holomorphic at $z \in \mathbb{C}$, prove that
	\begin{enumerate}
		\item $f + g$ is holomorphic and $(f + g)' = f' + g'$. \label{item:holomorphic_linearity}
		\item $fg$ is holomorphic and $(fg)' = f'g + fg'$. \label{item:holomorphic_product_rule}
		\item if $g(z) \neq 0, \frac{f}{g}$ is holomorphic and $(\frac{f}{g})' = \frac{f'g - fg'}{g^2}$. \label{item:holomorphic_quotient_rule}
	\end{enumerate}

	\begin{solution}
		\begin{enumerate}
			\item For $f + g$,
			\begin{align*}
					&\lim_{h \to 0} \frac{f(z + h) + g(z + h) - f(z) - g(z)}{h} \\
				= &\lim_{h \to 0} \left[ \frac{f(z + h) - f(z)}{h} + \frac{g(z + h) - g(z)}{g} \right] \\
				= & f'(z) + g'(z) 
			\end{align*}
			Thus $(f + g)' = f' + g'$.

			\item For $fg$,
			\begin{align*}
					&\lim_{h \to 0} \frac{f(z + h)g(z + h) - f(z)g(z)}{h} \\
				= &\lim_{h \to 0} \frac{f(z + h)g(z + h) + f(z)g(z + h) - f(z)g(z + h) - f(z)g(z)}{h} \\
				= &\lim_{h \to 0} \left[ \frac{f(z + h) - f(z)}{h} g(z + h) + f(z) \frac{g(z + h) - g(z)}{h} \right] \\
				= &f'(z)g(z) + f(z)g'(z)
			\end{align*}
			Therefore, $(fg)' = f'g + fg'$.

			\item When $\forall z \in \mathbb{C} \; g(z) \neq 0$, for $\frac{f}{g}$,
			\begin{align*}
					&\lim_{h \to 0} \frac{\frac{f(z + h)}{g(z + h)} - \frac{f(z)}{g(z)}}{h} \\
				= &\lim_{h \to 0} \frac{1}{h} \left[ \frac{f(z + h)g(z) - f(z)g(z + h)}{g(z + h)g(z)} \right] \\
				= &\lim_{h \to 0} \frac{1}{g(z + h)g(z)} \left[ \frac{f(z + h)g(z) + f(z)g(z) - f(z)g(z) - f(z)g(z + h)}{g} \right] \\
				= &\lim_{h \to 0} \frac{1}{g(z + h)g(z)} \left[ \frac{[f(z + h) - f(z)]g(z) - f(z)[g(z + h) - g(z)]}{h} \right] \\
				= &\frac{f'(z)g(z) - f(z)g'(z)}{g^2(z)}  
			\end{align*}
			Hence, $\frac{f}{g} = \frac{f'g - fg'}{g^2} $
		\end{enumerate}
	\end{solution}
\end{ex}

\begin{note}
	If we look at the example above from the perspective of $f$ being treated as a real-valued function, i.e. $f(z) = u(x, y) + iv(x, y)$ where $u, v: \mathbb{R}^2 \to \mathbb{R}$ and $z = x + iy$, observe that $\forall (x, y) \in \mathbb{R}^2, (x, y) \mapsto (x, -y)$, which we see that $u$ and $v$ are partially differentiable in $\mathbb{R}^2$.

	We will now look into this ``discrepancy''.
\end{note}

\subsection{Cauchy-Riemann Equations} % (fold)
\label{sub:cauchy_riemann_equations}

% subsection cauchy_riemann_equations (end)

Consider the following function taken from \cref{eq:holomorphic},
\begin{equation}\label{eq:holomorphic 2}
	f'(z_0) = \lim_{h \to 0} \frac{f(z_0 + h) - f(z_0)}{h}
\end{equation}
While $h$ may approach $0 \in \mathbb{C}$ from infinitely many sides on the complex plane, we will consider 2 cases.

\textit{Case 1: }$\mathit{h \to 0}$\textit{ via the real axis}

In this case, $h = x + i(0)$ and $x \to 0 \in \mathbb{R}$. Then \cref{eq:holomorphic 2} gives
\begin{align}
	f'(z_0) &= \lim_{x \to 0} \frac{u(x_0 + x, y_0) + iv(x_0 + x, y_0) - u(x_0, y_0) - iv(x_0, y_0)}{x} \nonumber \\
		&= \lim_{x \to 0} \left[ \frac{u(x_0 + x, y_0) - u(x_0, y_0)}{x} + i \frac{v(x_0 + x, y_0) - v(x_0, y_0)}{x} \right] \nonumber \\
		&= \frac{\partial u}{\partial x} \Bigr|_{(x_0, y_0)} + i \frac{\partial v}{\partial x} \Bigr|_{(x_0, y_0)} \label{eq:holomorphic approach via real axis}
\end{align}

\textit{Case 2: }$\mathit{h \to 0}$\textit{ via the imaginary axis}

In this case, $h = 0 + iy$ and $y \to 0 \in \mathbb{R}$. In a similar fashion, \cref{eq:holomorphic 2} becomes
\begin{align}
	f'(z_0) &= \lim_{y \to 0} \left[ \frac{u(x_0, y_0 + y) - u(x_0, y_0)}{iy} + \frac{v(x_0, y_0 + y) - v(x_0, y_0)}{y} \right] \nonumber \\
		&= \frac{1}{i} \cdot \frac{\partial u}{\partial y} \Bigr|_{(x_0, y_0)} + \frac{\partial v}{\partial y} \Bigr|_{(x_0, y_0)} \label{eq:holomorphic approach via imaginary axis}
\end{align}

Note that since $f'(z_0)$ exists, the real and imaginary part of \cref{eq:holomorphic approach via real axis} and \cref{eq:holomorphic approach via imaginary axis} must equate. Also note that $\frac{1}{i} = -i$. With that, we obtain the following theorem.

\begin{thm}[Cauchy-Riemann Equations]\label{thm:cauchy_riemann_equations}
	If $f(z)$ is holomorphic at $z_0 = x_0 + iy_0 \in \mathbb{C}$ where $x_0, y_0 \in \mathbb{R}$, then, at $(x_0, y_0)$,
	\begin{equation}\label{eq:cauchy_riemann_equations}
		\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y} \quad \text{ and } \quad \frac{\partial v}{\partial x} = - \frac{\partial u}{\partial y}.
	\end{equation}
\end{thm}

% section differentiability (end)

% chapter lecture_6_jan_15th_2018 (end)

\chapter{Lecture 7 Jan 17 2018}
	\label{chapter:lecture_7_jan_17_2018}

\section{Differentiability (Continued)} % (fold)
\label{sec:differentiability_continued}

\subsection{Cauchy-Riemann Equations (Continued)} % (fold)
\label{sub:cauchy_riemann_equations_continued}

It is natural to wonder if the \hlnotea{converse} of \cref{thm:cauchy_riemann_equations} is true. We present the following example.

\begin{eg}\label{eg:counterexample_for_converse_of_cre}
	Let
	\begin{equation*}
		f(z) = \begin{cases}
			\frac{\bar{z}^2}{z} & \text{if } z \neq 0 \\
			0		& \text{if } z = 0
		\end{cases}
	\end{equation*}
	Check if
	\begin{enumerate}
		\item $f$ is holomorphic at $0$.
		\item \cref{thm:cauchy_riemann_equations} holds at $(0, 0)$.
	\end{enumerate}

	\begin{proof}
		\begin{enumerate}
			\item Observe that by letting $h = x_h + iy_h$ where $x_h, y_h \in \mathbb{R}$,
			\begin{equation*}
				\lim_{h \to 0} \frac{\frac{\bar{0 + h}^2}{0 + h} - 0}{h} = \lim_{h \to 0} \frac{\bar{h}^2}{h} = \lim_{x_h + iy_h \to 0} \left(\frac{x_h - iy_h}{x_h + iy_h} \right)^2
			\end{equation*}
			Consider $y_h = kx_h$, for $k \in \mathbb{R} \setminus \{0\}$. Then
			\begin{equation*}
				\lim_{x_h \to 0} \left( \frac{x_h - ikx_h}{x_h + ikx_h} \right)^2 = \left( \frac{1 - ik}{1 + ik} \right)^2,
			\end{equation*}
			where we see that the limit depends on the value of $k$. Therefore, the limit DNE. Hence $f$ is not holomorphic at $0$.

			\item Let $z = x + iy$ for $x, y \in \mathbb{R}$. Then
			\begin{equation*}
				\frac{\bar{z}^2}{z} = \frac{(x - iy)^2}{x + iy} = \frac{(x - iy)^3}{x^2 + y^2} = \frac{x^3 - 3xy^2}{x^2 + y^2} + i \frac{(-3x^2y + y^3)}{x^2 + y^2}
			\end{equation*}
			Therefore, we obtain
			\begin{align*}
				u(x, y) &= \begin{cases}
					\frac{x^3 - 3xy^2}{x^2 + y^2} & (x, y) \neq (0, 0) \\
					0	& (x, y) = (0, 0)
				\end{cases} \\
				v(x, y) &= \begin{cases}
					\frac{y^3 - 3x^2y}{x^2 + y^2} & (x, y) \neq (0, 0) \\
					0	& (x, y) = (0, 0)
				\end{cases}
			\end{align*}
			Observe that
			\begin{align*}
				\frac{\partial u}{\partial x} \Bigr|_{(0, 0)}
					&= \lim_{x \to 0} \frac{u(x, 0) - u(0, 0)}{x} = 1 \\
				\frac{\partial v}{\partial y} \Bigr|_{(0, 0)}
					&= \lim_{y \to 0} \frac{v(0, y) - v(0, 0)}{y} = 1 \\
					&\text{and} \\
				\frac{\partial u}{\partial y} \Bigr|_{(0, 0)}
					&= \lim_{y \to 0} \frac{u(0, y) - u(0, 0)}{y} = 0 \\
				\frac{\partial v}{\partial x} \Bigr|_{(0, 0)}
					&= \lim_{x \to 0} \frac{v(x, 0) - v(0, 0)}{x} = 0
			\end{align*}
			satisfies \cref{eq:cauchy_riemann_equations}.
		\end{enumerate}
		This illustrates that the converse of \cref{thm:cauchy_riemann_equations} is not true. We will, however, show that the converse will be true given an extra condition.
	\end{proof}
\end{eg}

\begin{thm}[Conditional Converse of CRE]\label{thm:conditional_converse_of_cre}
	Let $z_0 = x_0 + iy_0 \in \Omega \subseteq \mathbb{C}, x_0, y_0 \in \mathbb{R}$, and $u, v : \mathbb{R}^2 \to \mathbb{R}, f = u + iv : \Omega \to \mathbb{C}$. If
	\begin{enumerate}
		\item the partials of $u, v$ exist in a neighbourhood of $(x_0, y_0)$,
		\item the partials of $u, v$ are continuous at $(x_0, y_0)$, and
		\item $\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y} \quad \text{and} \quad \frac{\partial v}{\partial x} = - \frac{\partial u}{\partial y} \quad \text{at } (x_0, y_0)$,
	\end{enumerate}
	then $f$ is holomorphic at $z_0$.
\end{thm}

A proof of the theorem is in page 36 of Newman and Bak (recommended text of PMATH352W18). I may include the proof whenever I am free.

% subsection cauchy_riemann_equations_continued (end)

\subsection{Power Series} % (fold)
\label{sub:power_series}

\begin{defn}[Power Series]\label{defn:power_series}
	A \hldefn{power series} in $\mathbb{C}$ is an infinite series of the form
	\begin{equation}\label{eq:generic_power_series_formula}
		\sum_{n \in \mathbb{N}} c_n z^n,
	\end{equation}
	where each $c_n \in \mathbb{C}$ is the coefficient of $z$ of the $n$-th power.
\end{defn}

In this subsection, we are interested to see if \cref{eq:generic_power_series_formula} converges.

Recall the notion of convergence in series from $\mathbb{R}$. \cref{eq:generic_power_series_formula} converges if the sequence of partial sums $\{S_N\}$ converges as $N \to \infty$, where
\begin{equation*}
	S_N := \sum_{n = 0}^{N} c_n z^n
\end{equation*}

In other words, using the same definition of $S_N$,
\begin{gather*}
	\forall \epsilon > 0 \quad \exists N \in \mathbb{N} \setminus	\{0\} \quad \forall n > N \\
	\abs{S_n - L} < \epsilon
\end{gather*}
where $L \in \mathbb{C}$ is the limit that the sequence converges to.

We also know that \cref{eq:generic_power_series_formula} converges absolutely if $\sum_{n = 0}^{\infty} \abs{c_n} \abs{z}^n$ converges. This is a stronger statement (i.e. absolute convergence $\implies$ convergence)
\begin{equation*}
	\because \abs{\sum_{n = 0}^{N} c_n z^n} \leq \sum_{n = 0}^{N} \abs{c_n} \abs{z}^n \quad \text{for each } N \in \mathbb{N}
\end{equation*}

\begin{eg}
	$\sum_{n = 0}^{\infty} z^n$ converges absolutely for $\abs{z} < 1$.

	Note that the partial sum of a geometric series is
	\begin{equation*}
		\sum_{n = 0}^{N} r^n = \frac{1 - r^{N + 1}}{1 - r}
	\end{equation*}
	and so the limit as $N \to \infty$ exists if $\abs{r} < 1$, and hence we see that
	\begin{equation*}
		\sum_{n = 0}^{N} r^n \to \frac{1}{1 - r} 
	\end{equation*}
	if $\abs{r} < 1$ as $N \to \infty$.

	However, if $\abs{z} = 1$, the power series diverges.
\end{eg}

Another note that we shall point out is that if \cref{eq:generic_power_series_formula} converges absolutely for some $z_0 \in \mathbb{C}$, then it converges absolutely for any $z$ where $\abs{z} < \abs{z_0}$.

These notions, in turn, begs the question of \hlwarn{what is the largest possible $\abs{z_0}$ for the series to converge absolutely}.

% subsection power_series (end)

% section differentiability_continued (end)

% chapter lecture_7_jan_17_2018 (end)

\chapter{Lecture 8 Jan 19 2018}
	\label{chapter:lecture_8_jan_19_2018}

\section{Power Series (Continued)} % (fold)
\label{sec:power_series_continued}

\subsection{Radius of Convergence} % (fold)
\label{sub:radius_of_convergence}

\begin{thm}[Convergence in the Radius of Convergence]\label{thm:convergence_in_the_radius_of_convergence}
	For any power series $\sum_{n \in \mathbb{N}} c_n z^n$, $\exists 0 \leq R < \infty$, such that
	\begin{enumerate}
		\item $\abs{z} < R \implies $ series converges absolutely.
		\item $\abs{z} > R \implies $ series diverges.
	\end{enumerate}
	Moreover, $R$ is given by \hlnotea{Hadamard's Formula}:
	\begin{equation}\label{eq:hadamards_formula}
		\frac{1}{R} := \limsup_{n \to \infty} \abs{c_n}^\frac{1}{n}
	\end{equation}
\end{thm}

\begin{remark}
	\begin{enumerate}
		\item $R$ is called the \hldefn{radius of convergence} of the series. $\{z \in \mathbb{C} : \abs{z} < R\}$ is called the disk of convergence of the series.
		\item Recall the definition of the \hldefn{limit supremum}
		\begin{equation}
			\label{eq:defn_limsup}
			\limsup_{n \to \infty} a_n := \lim_{n \to \infty} (\sup_{m \geq n} a_m)
		\end{equation}
		which we may colloquially say as the ``highest peak `reached' by $a_n$'s as $n \to \infty$''
	\end{enumerate}
\end{remark}

\begin{propo}[A Property of limsup]\label{propo:a_property_of_limsup}\begin{gather*}
		\forall \{a_n\}_{n \in \mathbb{N}} \quad L := \limsup_{n \to \infty} a_n \implies \\
		\forall \epsilon > 0 \quad \exists N > 0 \quad \forall n > N \\
		L - \epsilon < a_n < L + \epsilon
	\end{gather*}
\end{propo}

(Proof to be included)

\begin{proof}[\cref{thm:convergence_in_the_radius_of_convergence}]
	Let $L := \frac{1}{R} = \limsup_{n \to \infty} \abs{c_n}^\frac{1}{n}$. Clearly, $L \geq 0$.
	\begin{enumerate}
		\item Suppose $\abs{z} < R$. $\exists \epsilon > 0, r := \abs{z}(L + \epsilon)$ such that $0 < r < 1$. By \cref{propo:a_property_of_limsup}, $\exists N \in \mathbb{N}, \forall n > N, \abs{c_n}^\frac{1}{n} < L + \epsilon$.

		Now since $L = \frac{1}{R}$,
		\begin{equation*}
			\sum_{n=N}^{\infty} \abs{c_n}\abs{z}^n = \sum_{n=N}^{\infty} (\abs{c_n}^\frac{1}{n} \abs{z})^n < \sum_{n=N}^{\infty} r^n
		\end{equation*}
		and since $0 < r < 1$, the final summation converges (as it is a geometric sum). Thus by comparison test, $\sum_{n=N}^{\infty} \abs{c_n} \abs{z}^n$ converges.

		We may also proceed with noticing that the partial sum of $\sum_{n=N}^{\infty} \abs{c_n}\abs{z}^n$ is \hlnotea{bounded and monotonic}, which shows that the series converges.

		\item Suppose $\abs{z} > R$. $\exists \epsilon > 0, r := \abs{z}(L - \epsilon)$ such that $r > 1$. By \cref{propo:a_property_of_limsup}, $\exists N \in \mathbb{N}, \forall n > N, \abs{c_n}^\frac{1}{n} > L - \epsilon$. Then analogous to the proof above,
		\begin{equation*}
			\sum_{n=N}^{\infty} \abs{c_n}\abs{z}^n = \sum_{n=N}^{\infty} (\abs{c_n}^\frac{1}{n} \abs{z})^n > \sum_{n=N}^{\infty} r^n
		\end{equation*}
		where the final summation diverges, and thus implying that $\sum_{n=N}^{\infty} \abs{c_n}\abs{z}^n$ diverges.
	\end{enumerate}
\end{proof}

\begin{thm}[Power function, holomorphic function, region of convergence]\label{thm:power_function_holomorphic_function_region_of_convergence}
	Suppose $f(z) = \sum_{n\in \mathbb{N}} c_n z^n$ has a radius of convergence $R \in \mathbb{R}$. Then $f'(z)$ exists and equals
	\begin{equation*}
		\sum_{n=1}^{\infty} nc_nz^{n - 1}
	\end{equation*}
	throughout $\abs{z} < R$.

	Moreover, $f'$ has the \hlimpo{same radius of convergence} as $f$.
\end{thm}

\begin{proof}
	Note that $f'$ has the same radius of convergence as $f$ since
	\begin{equation*}
		\limsup_{n \to \infty} \abs{nc_n}^\frac{1}{n} = \limsup_{n \to \infty} \abs{n}^\frac{1}{n} \abs{c_n}^\frac{1}{n} = \limsup_{n \to \infty} \abs{c_n}^\frac{1}{n}
	\end{equation*}
	where note that $\lim_{n \to \infty} \abs{n}^\frac{1}{n} = 1$.

	Let $\abs{z_0} \leq r < R$ and $g(z_0) := \sum_{n=1}^{\infty} nc_n z_0^{n - 1} $.

	\WTS
	\begin{equation*}
		\lim_{h \to 0} \frac{f(z_0 + h) - f(z_0)}{h} = g(z_0)
	\end{equation*}
	OR
	\begin{gather*}\label{eq:power_function_defines_holomorphic_function_epsilondelta}\tag{$\dagger$}
		\forall \epsilon > 0 \enspace \exists \delta > 0 \\
		\abs{h} < \delta \implies \abs{\frac{f(z_0 + h) - f(z_0)}{h} -g(z_0)} < \epsilon
	\end{gather*}
	(Note that we would want $\delta > 0$ such that $\abs{z_0 + h} \leq r < R$)

	\WTP \eqref{eq:power_function_defines_holomorphic_function_epsilondelta}. $\forall \epsilon > 0$, choose $\delta > 0$. Suppose $\abs{z_0 + h} < \abs{z_0 + \delta} \leq r < R$. Write
	\begin{equation*}
		f(z) = \sum_{n=0}^{N} c_n z^n + \sum_{n=N}^{\infty} c_n z^n
	\end{equation*}
	and let $S_N(z)$ and $E_N(z)$ be the first and second terms respectively.
	Then we have that
	\begin{equation*}
		S_N'(z) = \sum_{n=1}^{N} nc_n z^{n - 1}
	\end{equation*}
	Consider
	\begin{align}
			&\abs{\frac{S_N(z_0 + h) - S_N(z_0)}{h} + \frac{E_N(z_0 + h) - E_N(z_0)}{h} - g(z_0) + S_N'(z_0) - S_N'(z_0)} \nonumber \\
		\leq &\abs{\frac{S_N(z_0 + h) - S_N(z_0)}{h} - S_N'(z_0)} + \abs{\frac{E_N(z_0 + h) - E_N(z_0)}{h}} + \abs{S_N'(z_0) - g(z_0)} \label{eq:power_function_defines_holomorphic_function_1}
	\end{align}
	For the second term, since $a^2 - b^2 = (a - b)(a^{n - 1} + a^{n - 2}b + \hdots ab^{n - 2} + b^{n - 1})$ and $\abs{z_0}, \abs{z_0 + h} < r \leq R$, we obtain $(z_0 + h)^n - z_0^n \leq hnr^{n - 1}$. Thus
	\begin{equation*}
		\abs{\frac{E_N(z_0 + h) - E_N(z_0)}{h}} = \abs{\frac{1}{h} \sum_{n=N+1}^{\infty} c_n [(z_0 + h)^n - z_0^n]} \leq \sum_{n=N+1}^{\infty} nc_nr^{n-1}.
	\end{equation*}

	Note that
	\begin{equation}\label{eq:power_function_defines_holomorphic_function_2}
		\sum_{n=1}^{\infty} nc_nr^{n-1} = g(r),
	\end{equation}
	and since $r < R$, \cref{eq:power_function_defines_holomorphic_function_2} converges absolutely by \cref{thm:convergence_in_the_radius_of_convergence}, thus the tail
	$\sum_{n=N+1}^{\infty} nc_n r^{n - 1}$ converges absolutely. Therefore, by comparison, we can pick $\frac{\epsilon}{3} > 0$ so that $\exists N_1 \in \mathbb{N}, \forall n > N_1$
	\begin{equation*}
		\abs{\frac{E_N(z_0 + h) - E_N(z_0)}{h}} < \frac{\epsilon}{3}.
	\end{equation*}
	
	For the third term in \cref{eq:power_function_defines_holomorphic_function_1}, we observe that by definition, $S_N'(z_0) = \sum_{n=1}^{N} nc_n z^{n - 1}$. Since
	\begin{equation*}
		\lim_{N \to \infty} S_N'(z_0) = \lim_{N \to \infty} \sum_{n=1}^{N} nc_n z^{n - 1} = \sum_{n=1}^{\infty} nc_n z^{n - 1} = g(z_0)
	\end{equation*}
	we know that we can pick $\frac{\epsilon}{3} > 0, \exists N_2 \in \mathbb{N}, \forall n > N_2$, we have
	\begin{equation*}
		\abs{S_N'(z_0) - g(z_0)} < \frac{\epsilon}{3}
	\end{equation*}.

	For the first term in \cref{eq:power_function_defines_holomorphic_function_1}, note that $(S_N(z_0))' = S_N'(z_0)$. Let $\frac{\epsilon}{3} > 0, \exists \delta > 0, \exists N > \max\{N_1, N_2\}, \forall n > N$, since $\abs{h} < \delta$, we have that
	\begin{equation*}
		\abs{\frac{S_N(z_0 + h) - S_N(z_0)}{h} - S_N'(z_0)} < \frac{\epsilon}{3}
	\end{equation*}

	This completes the proof. \qed
\end{proof}

% subsection radius_of_convergence (end)

% section power_series_continued (end)

% chapter lecture_8_jan_19_2018 (end)

\chapter{Lecture 9 Jan 22 2018}
	\label{chapter:lecture_9_jan_22_2018}

\section{Power Series (Continued 2)} % (fold)
\label{sec:power_series_continued_2}

\subsection{Radius of Convergence (Continued)} % (fold)
\label{sub:radius_of_convergence_continued}

\begin{eg}
	Let $f(z) = \sum_{n=1}^{\infty} \frac{z^n}{n}$. To find the radius of convergence, we use Hadamard's Formula:
	\begin{equation*}
		\frac{1}{R} = \limsup_{n \to \infty} \left(\frac{1}{n} \right)^\frac{1}{n} = 1 \qquad \because \lim_{n \to \infty} n^\frac{1}{n} = 1
	\end{equation*}
	Therefore $R = 1$. Thus, by \cref{thm:convergence_in_the_radius_of_convergence}, $f$ converges absolutely when $\abs{z} < 1$ and diverges when $\abs{z} > 1$. As for the boundary, i.e. $\abs{z} = 1$, consider the following two cases:
	\begin{enumerate}
		\item If $z = 1$, then $f(1) = \sum_{n=1}^{\infty} \frac{1}{n}$ is a \hlnotea{harmonic series}, and hence $f$ diverges.
		\item If $z = i$, then
		\begin{align*}
			f(i) &= \sum_{n=1}^{\infty} \frac{i^n}{n} \\
				 &= i - \frac{1}{2} + \frac{-i}{3} + \frac{1}{4} + \frac{i}{5} - \frac{1}{6} \\
				 &= \left(-\frac{1}{2} + \frac{1}{4} - \frac{1}{6} + \hdots	\right) + i \left(1 - \frac{1}{3} + \frac{1}{5} + \hdots \right).
		\end{align*}
		Observe that both the real and imaginary parts are alternating series where the absolute values of each term is decreasing, which, by the \hlnotea{alternating series test}, converge. Thus in this case, $f$ converges.
	\end{enumerate}
	Therefore, we observe that \hlnoteb{both convergence and divergence may occur} on the boundary, depending on the value of $z$.
\end{eg}

\begin{note}
	We may not always exchange the position of $\lim$ and $\sum_{a=1}^{b}$ when we consider an infinite sum (i.e. $b = \infty$). Here's an example why this is true. Consider the function $f(x) = \sum_{n=1}^{\infty} (x^n - x^{n - 1})$ for $\abs{x} < 1$. Is
	\begin{equation*}
		\lim_{x \to 1} \sum_{n=1}^{\infty} (x^n - x^{n - 1}) = \sum_{n=1}^{\infty} \lim_{x \to 1} (x^n x^{n - 1})
	\end{equation*}
	true?

	Clearly, RHS is 0. For LHS, note that
	\begin{align*}
		f(x) &= \lim_{N \to \infty} \sum_{n=1}^{N} (x^n - x^{n - 1}) \\
			&= \lim_{N \to \infty} (x - x^2 + x^2 - x^3 + \hdots + x^N x^{N + 1}) \\
			&= \lim_{N \to \infty} (x - x^{N + 1}) = x.
	\end{align*}
	So,
	\begin{equation*}
		\text{LHS} = \lim_{x \to 1} x = 1
	\end{equation*}
	And we see that RHS $\neq$ LHS.
\end{note}

\begin{defn}[Entire Function]
	A function $f$ is said to be \hldefn{entire} if $f$ is holomorphic in \hlnoteb{the entire complex plane}.
\end{defn}

\begin{ex}
	Define $e^z = \sum_{n=0}^{\infty} \frac{z^n}{n!}$. Show that
	\begin{enumerate}
		\item the radius of convergence of this series is $\infty$, and hence that $e^z$ is an entire function. (Hint: Use \hlnotea{Stirling's formula}: $n! \sim (\frac{n}{e})^n \sqrt{2 \pi n}$)
		\item $(e^z)' = e^z$
	\end{enumerate}

	\begin{solution}
		\begin{enumerate}
			\item Using Stirling's formula, note that we have
			\begin{equation*}
				e^z = \sum_{n=0}^{\infty} \frac{1}{\sqrt{2 \pi n}} \left(\frac{ez}{n} \right)^n
			\end{equation*}
			To find $R$, we have
			\begin{align*}
				\frac{1}{R} &= \limsup_{n \to \infty} \abs{\frac{1}{\sqrt{2 \pi n}} \left(\frac{e}{n} \right)}^\frac{1}{n} \\
					&= \limsup_{n \to \infty} \abs{\frac{e}{n}} \limsup_{n \to \infty} \abs{\frac{1}{\sqrt{2 \pi n}}}^\frac{1}{n} \\
					&= 0
			\end{align*}
			since $\limsup_{n \to \infty} \frac{e}{n} = 0$. Thus $R = \infty$. By \cref{thm:convergence_in_the_radius_of_convergence}, $e^z$ is an entire function.

			\item Note that
			\begin{align*}
				\lim_{h \to 0} \frac{e^{z + h} - e^z}{h} &= e^z \lim_{h \to 0} \frac{e^h - 1}{h}  \\
					&= e^z \lim_{h \to 0} \frac{1 + h + \frac{h^2}{2} + \frac{h^3}{3} + \hdots - 1}{h} \\
					&= e^z
			\end{align*}
			Thus $(e^z)' = e^z$ as required.
		\end{enumerate}
	\end{solution}
\end{ex}

% subsection radius_of_convergence_continued (end)

% section power_series_continued_2 (end)

% chapter lecture_9_jan_22_2018 (end)

\chapter{Lecture 10 Jan 24 2018}
	\label{chapter:lecture_10_jan_24_2018}

\section{Power Series (Continued 3)} % (fold)
\label{sec:power_series_continued_3}

\subsection{Radius of Convergence (Continued 2)} % (fold)
\label{sub:radius_of_convergence_continued_2}

A power series is infinitely $\mathbb{C}$-differentiable in its radius of convergence. All its derivatives are also power series, obtained by term-wise differentiation.

E.g.

\begin{equation*}
	f(z) - \sum_{n=0}^{\infty} c_n z^n \enspace \text{ then } \enspace f^{(2)}(z) = \sum_{n=0}^{\infty} n(n-1)c_n z^{n - 2}
\end{equation*}

In general, we may have $\sum_{n=0}^{\infty} c_n (z - z_0)^n$, which is a power series centered at $z_0 \in \mathbb{C}$. Then, as before, the radius of convergence of this power series is given by

\begin{equation*}
	\frac{1}{R} = \limsup_{n \to \infty} \abs{c_n}^\frac{1}{n}
\end{equation*}

So instead of having the disc of convergence centered around $0$, we now have one that is centered around $z_0$.

\begin{crly}[Corollary of \cref{thm:power_function_holomorphic_function_region_of_convergence}]
	From \cref{thm:power_function_holomorphic_function_region_of_convergence}, we have shown that

	\begin{tabular}{L{7cm} C{2cm} R{5cm}}
		$f(z)$ has a power series expansion at $z_0$ (i.e. $f(z) = \sum_{n=0}^\infty c_n (z - z_0)^n$ in some neighbourhood of $z_0$) with radius of convergence $R > 0$ &
		$\implies$ &
		$f$ is holomorphic at $z_0$
	\end{tabular}
\end{crly}

The converse of the statement above is true, i.e.

\begin{tabular}{L{5cm} C{2cm} R{7cm}}
	$f$ is holomorphic at $z_0$ &
	$\implies$ &
	$f(z)$ has a power series expansion at $z_0$ (i.e. $f(z) = \sum_{n=0}^\infty c_n (z - z_0)^n$ in some neighbourhood of $z_0$) with radius of convergence $R > 0$
\end{tabular}

This converse, however, is not possible to be proven given the current tools on our belt. And so we now have to venture into integrals in $\mathbb{C}$.

% subsection radius_of_convergence_continued_2 (end)

% section power_series_continued_3 (end)

\section{Integration in \texorpdfstring{$\mathbb{C}$}{C}} % (fold)
\label{sec:integration_in_c}

\subsection{Curves and Paths} % (fold)
\label{sub:curves_and_paths}

Before we begin with the definition of a curve in $\mathbb{C}$, let us consider how a straight line should be described as a vector-valued function in the complex plane. For instance, if we have two points $\alpha, \beta \in \mathbb{C}$, and we want to describe the straight line connecting the two.

\begin{tabular}{C{5cm} L{10cm}}
	\begin{tikzpicture}
		\coordinate (a) at (-1, -1);
		\coordinate (b) at (1, 1);
		\node[label={225:{$\alpha$}},circle,fill=base16-eighties-light,inner sep=1pt] at (a) {};
		\node[label={45:{$\beta$}},circle,fill=base16-eighties-light,inner sep=1pt] at (b) {};
		\draw[midarrow={>}] (a)--(b);
	\end{tikzpicture} &
	Let $\gamma$ be the function that describes this line. We may then define $\gamma : [0, 1] \to \mathbb{C}$ to be either
	\begin{equation*}
		\gamma(t) = \alpha + (\beta - \alpha) t \enspace \text{ or } \enspace \gamma = \alpha(1 - t) + \beta t.
	\end{equation*}
	We would then have the following mapping:
\end{tabular}

\begin{figure}[H]
	\begin{center}
		\begin{tabular}{c c c}
			\begin{tikzpicture}
				\draw[-] (2, 0) -- (-2, 0) node[left] {$\mathbb{R}$};
				\node at (0, -2.5) {};
				\node at (0, 4) {};
				\node[label={270:{a}}] at (-1, 0) {[};
				\node[label={270:{b}}] at (1, 0) {]};
				\node[label={90:{c}},fill=base16-eighties-light,inner sep=1pt] at (0, 0) {};
			\end{tikzpicture} &
			\begin{tikzpicture}
				\draw[->] (0, 0) arc (135:45:2) node[midway,above] {$\gamma$};
				\node[label={0:{}}] at (0,-3) {};
			\end{tikzpicture} &
			\begin{tikzpicture}
				\draw[->] (-3, 0) -- ++(6, 0) node[right] {$\mathbb{C}$};
				\draw[->] (0, -2.5) -- (0, 2);
				\node[label={270:{a}},fill=base16-eighties-light,inner sep=1pt] at (-2.3, -1.287) {};
    			\node[label={90:{b}},fill=base16-eighties-light,inner sep = 1pt] at (1.2, 1.258) {};
    			\node[label={270:{c}},fill=base16-eighties-light,inner sep=1pt] at (-0.55,-1.011375) {};
				\clip (-2.3,-2.5) rectangle (1.2,1.2);
    			\draw[midarrow={>},domain=-2.5:1.5] plot (\x, {pow(\x,3)+2*pow(\x,2)-\x-2});
			\end{tikzpicture}
		\end{tabular}
	\end{center}
	\caption[loftitle]{Mapping from $\mathbb{R} \to \mathbb{C}$ with $\gamma$, which is called \hlnoteb{the curve $\gamma$}}
	\label{figure:map_from_r_to_c_with_upsilon}
\end{figure}

\begin{defn}[Curves in $\mathbb{C}$]\label{defn:curves_in_c}
	A curve in $\mathbb{C}$ is a continuous function, $\gamma(t): [a, b] \to \mathbb{C}$, where $a, b \in \mathbb{R}$. The image of $\gamma$ in $\mathbb{C}$ is called $\gamma^*$.
\end{defn}

\begin{eg}
	Let $z_0 \in \mathbb{C}, r > 0$. \\
	\begin{tabular}{L{9cm} R{5cm}}
		\begin{enumerate}
			\item Let $\gamma : [0, 2 \pi] \to \mathbb{C}$, such that $\gamma (t) = z_0 + re^{it}$.
			\item Let $\gamma' : [0, 1] \to \mathbb{C}$, such that $\gamma' (t) = z_0 + re^{2 \pi i t}$.
		\end{enumerate}
		The two functions above describe a circle centered at $z_0$ with radius $r$, anticlockwise-oriented. &
		\begin{tikzpicture}
			\draw[->] (-0.5, 0) -- (3, 0);
			\draw[->] (0, -0.5) -- (0, 3);
			\coordinate (z0) at (1.5,1.5);
			\draw (z0) circle (1);
			\node[label={0:{$z_0$}},fill=base16-eighties-light,inner sep=1pt] at (z0) {};
			\draw[<->] (z0)--(0.5,1.5) node[midway,above] {$r$};
			\node[label={0:{$t=0$ or $2 \pi$}},fill=base16-eighties-light,inner sep=1pt] at (2.5,1.5) {};
			\node[label={90:{$t=\frac{\pi}{2}$}},fill=base16-eighties-light,inner sep=1pt] at (1.5,2.5) {};
			\node[label={180:{$t=\pi$}},fill=base16-eighties-light,inner sep=1pt] at (0.5,1.5) {};
			\node[label={270:{$t=\frac{3\pi}{2}$}},fill=base16-eighties-light,inner sep=1pt] at (1.5,0.5) {};
		\end{tikzpicture}
	\end{tabular}
\end{eg}

We say that $\gamma$ and $\gamma'$ are equivalent parameterizations for the same oriented path.

\begin{defn}[Equivalent Parameterization]\label{defn:equivalent_parameterization}
	Let $\gamma_1 : [a, b] \to \mathbb{C}, \gamma_2 : [c, d] \to \mathbb{C}$ where $a, b, c, d \in \mathbb{C}$ describe the path $\gamma^*$. The two \hldefn{paramaterization are said to be equivalent} if $\exists h: [a, b] \to [c, d]$ that is a bijection and a continuous function such that
	\begin{equation*}
		\gamma_1(t) = \gamma_2(h(t))
	\end{equation*}
	where $t \in [a, b]$.
\end{defn}

\begin{note}
 	We will not look at functions like the Weierstrass function in this course.
\end{note}

\begin{defn}[Smooth Curve]\label{defn:smooth_curve}
	Let $\gamma : [a, b] \to \mathbb{C}, a, b, \in \mathbb{C}$. $\gamma$ is said to be smooth if its derivative $\gamma'$ exists and is continuous on $[a, b]$ and $\forall t \in [a, b], \gamma'(t) \neq 0$.
\end{defn}

\begin{defn}[Piecewise Smooth]\label{defn:piecewise_smooth}
	Let $\gamma: [a, b] \to \mathbb{C}$. $\gamma$ is said to be piecewise smooth if it is smooth on $[a, b]$ except on finitely many points in $[a, b]$.
\end{defn}

\begin{remark}
	Piecewise smooth curves shall be called paths.
\end{remark}

% subsection curves_and_paths (end)

\subsection{Integral} % (fold)
\label{sub:integral}

\begin{defn}[Integral of $f$ over a path $\gamma$]\label{defn:integral_of_f_over_a_path_gamma}
	Given a path $\gamma: [a, b] \to \mathbb{C}$ and $f : \mathbb{C} \to \mathbb{C}$, a function continuous on $\gamma$. We define the integral $f$ along $\gamma$ as
	\begin{equation}
		\int_{\gamma} f(z) dz := \int_{a}^{b} f(\gamma(t))\gamma'(t) dt
	\end{equation}
	where we let $z = \gamma(t)$ and hence $dz = \gamma'(t) dt$.
\end{defn}

\begin{remark}
	\begin{enumerate}
		\item Suppose $g$ is a complex-valued function, then
			\begin{equation*}
				\int_{a}^{b} g(t) dt = \int_{a}^{b} \re(g(t)) dt + i \int_{a}^{b} \im(g(t)) dt
			\end{equation*}
		\item The integral of $f$ along $\gamma$ can be shown to be independent of the chosen parameterization for $\gamma^*$.

		\begin{proof}
			Let $a, b, c, d \in \mathbb{R}, \gamma_1 : [a, b] \to \mathbb{C}, \gamma_2 : [c, d] \to \mathbb{C}$ describe the same path $\gamma^*$. By \cref{defn:equivalent_parameterization}, define a bijection $h : [a, b] \to [c, d]$ that is a continuous function such that $t \mapsto \tau$, so that
			\begin{equation*}
				\gamma_1(t) = \gamma_2(h(t)) = \gamma(\tau).
			\end{equation*}
			Note that
			\begin{align*}
				\gamma_1'(t) &= h'(t)\gamma_2'(h(t)) \text{ and } \\
				h(t) &= \tau \implies h'(t) dt = d\tau.
			\end{align*}
			Now since $h$ is a bijection, we claim that $h(a) = c$ while $h(b) = d$.

			We know that $h$ cannot be a constant function. Suppose $h$ is an increasing function, then since $a \leq b$ and $c \leq d$, it is clear that $h(a) = c$ and $h(b) = d$. Similarly, if $h$ is a decreasing function, then $h(a) = d$ and $h(b) = c$. But this is a contradiction to our supposition that $\gamma_1$ and $\gamma_2$ describe the same orientation. Thus $h$ must be an increasing function, and hence we have $h(a) = c$ and $h(b) = d$.

			\hlnotec{(This can be more rigorous but that is an easy proof, and we may use perhaps the Approximation Property of $\mathbb{R}$ to that end, which is a fun exercise that shall not be included within these covers.)}

			Now
			\begin{align*}
				\int_{\gamma_1} f(z) dz
					&= \int_{a}^{b} f\big( \gamma_1(t) \big) \gamma_1'(t) dt \\
					&= \int_{a}^{b} f\Big( \gamma_2 \big( h(t) \big) \Big) h'(t) \gamma_2'(h(t)) dt \\
					&= \int_{c}^{d} f\big( \gamma_2(\tau) \big) \gamma_2'(\tau) d\tau \\
					&= \int_{\gamma_2} f(z) dz
			\end{align*}
			This completes the proof.
		\end{proof}
	\end{enumerate}
\end{remark}

\begin{propo}[Properties of integrals in $\mathbb{C}$]\label{propo:properties_of_integrals_in_c}
	Let $\alpha, \beta \in \mathbb{C}$.
	\begin{enumerate}
		\item $\int_{\gamma} \left(\alpha f(z) + \beta g(z) \right) dz = \alpha \int_{\gamma} f(z) dz + \beta \int_{\gamma} g(z) dz$.
	\end{enumerate}
\end{propo}

% subsection integral (end)

% section integration_in_c (end)

% chapter lecture_10_jan_24_2018 (end)
\end{document}