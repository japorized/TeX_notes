\documentclass[notoc,notitlepage]{tufte-book}
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

\renewcommand{\baselinestretch}{1.1}

\usepackage{tikz-cd}
\input{latex-classnotes-preamble.tex}

\title{PMATH347S18 - Groups \& Rings}
\author{Johnson Ng}

% Header formatting
\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
\renewcommand{\sectionmark}[1]{\markright{#1}}
\makeatletter
\pagestyle{fancy}
\fancyhead{}
\fancyhead[RO]{\textsl{\@title} \enspace \thepage}
\fancyhead[LE]{\thepage \enspace \textsl{\leftmark \enspace - \enspace \rightmark}}
\makeatother

\begin{document}
\hypersetup{pageanchor=false}
\maketitle
\hypersetup{pageanchor=true}
\tableofcontents

\chapter*{List of Definitions}
\theoremlisttype{all}
\listtheorems{defn}

\chapter*{List of Theorems}
\theoremlisttype{allname}
\listtheorems{axiom,lemma,thm,crly,propo}

\chapter{Lecture 1 May 02nd 2018}
  \label{chapter:lecture_1_may_02nd_2018}

\section{Introduction} % (fold)
\label{sec:introduction}

\subsection{Numbers} % (fold)
\label{sub:numbers}

The following are some of the number sets that we are already familiar with:
\begin{gather*}
  \mathbb{N} = \{1, 2, 3, ...\} \qquad \mathbb{Z} = \{.., -2, -1, 0, 1, 2, ...\} \\
  \mathbb{Q} = \left\{\frac{a}{b} : a \in \mathbb{Z}, b \in \mathbb{N} \right\} \qquad \mathbb{R} = \text{ set of real numbers} \\
  \mathbb{C} = \{a + bi : a, b \in \mathbb{R}, i = \sqrt{-1} \} = \text{ set of complex numbers} 
\end{gather*}
For $n \in \mathbb{Z}$, let $\mathbb{Z}_n$ denote the set of integers modulo $n$, i.e.
\begin{equation*}
  \mathbb{Z}_n = \{ [0], [1], ..., [n - 1] \}
\end{equation*}
where the $[r]$, $0 \leq r \leq n - 1$, are the congruence classes, i.e.
\begin{equation*}
  [r] = \{z \in \mathbb{Z} : z \equiv r \mod n\}
\end{equation*}

These sets share some common properties, e.g. $+$ and $\times$. Let's try to break that down to make further observation.

\newthought{Note that} for $R = \mathbb{N}, \, \mathbb{Z}, \, \mathbb{Q}, \, \mathbb{R}, \, \mathbb{C},$ or $\mathbb{Z}_n$, $R$ has 2 operations, i.e. addition and multiplication.

\paragraph{Addition} If $r_1, r_2, r_3 \in R$, then
\begin{itemize}
  \item (\hldefn{closure}) $r_1 + r_2 \in R$
  \item (\hldefn{associativity}) $r_1 + (r_2 + r_3) = (r_1 + r_2) + r_3$
\end{itemize}
Also, if $R \neq \mathbb{N}$, then $\exists 0 \in R$ (the \hldefn{additive identity}) such that
\begin{equation*}
  \forall r \in R \quad r + 0 = r = 0 + r.
\end{equation*}
Also, $\forall r \in R$, $\exists (-r) \in R$ such that
\begin{equation*}
  r + (-r) = 0 = (-r) + r.
\end{equation*}

\paragraph{Multiplication} For $r_1, r_2, r_3 \in R$, we have
\begin{itemize}
  \item (\hlnoteb{closure}) $r_1 r_2 \in R$
  \item (\hlnoteb{associativity}) $r_1 (r_2 r_3) = (r_1 r_2) r_3$
\end{itemize}
Also, $\exists 1 \in R$ (a.k.a the \hldefn{mutiplicative identity}), such that
\begin{equation*}
  \forall r \in R \quad r \cdot 1 = r = 1 \cdot r.
\end{equation*}
Finally, for $R = \mathbb{Q}, \, \mathbb{R},$ or $\mathbb{C}$, $\forall r \in R, \, \exists r^{-1} \in R$ such that
\begin{equation*}
  r \cdot r^{-1} = 1 = r^{-1} \cdot r.
\end{equation*}
Note that for $R = \mathbb{Z}_n$, where $n \in \mathbb{Z}$, not all $[r] \in \mathbb{Z}_n$ have a multiplicative inverse. For example, for $[2] \in \mathbb{Z}_4$, there is no $[x] \in \mathbb{Z}_4$ such that $[2][x] = [1]$.\sidenote{This is best proven using techniques introduced in MATH135/145.}

% subsection numbers (end)

\subsection{Matrices}
  \label{sub:matrices}

For $n \in \mathbb{N} \setminus \{1\}$, an $n \times n$ matrix over $\mathbb{R}$ \sidenote{$\mathbb{R}$ can be replaced by $\mathbb{Q}$ or $\mathbb{C}$.} is an $n \times n$ array that can be expressed as follows:
\begin{equation*}
  A = [a_{ij}] = \begin{bmatrix}
    a_{11} & a_{12} & \hdots & a_{1n} \\
    a_{21} & a_{22} & \hdots & a_{2n} \\
    \vdots & \vdots &        & \vdots \\
    a_{n1} & a_{n2} & \hdots & a_{nn}
  \end{bmatrix}
\end{equation*}
where for $1 \leq i, j \leq n$, $a_{ij} \in \mathbb{R}$. We denote $M_n(\mathbb{R})$ as the set of all $n \times n$ matrices over $\mathbb{R}$.

As in \cref{sub:numbers}, we can perform \hlnotea{addition and multiplication} on $M_n(\mathbb{R})$.

\paragraph{Matrix Addition} Given $A = [a_{ij}], B = [b_{ij}], C = [c_{ij}] \in M_n(\mathbb{R})$, we define matrix addition as
\begin{equation*}
  A + B = [a_{ij} + b_{ij}],
\end{equation*}
which immediately gives the \hlnoteb{closure property}, since $a_{ij} + b_{ij} \in \mathbb{R}$ and hence $A + B \in M_n(\mathbb{R})$. Also, by this definition, we also immediately obtain the \hlnoteb{associativity property}, i.e.
\begin{equation*}
  A + (B + C) = (A + B) + C.
\end{equation*}
We define the zero matrix as
\begin{equation*}
  0 = \begin{bmatrix}
    0      &   0    & \hdots &   0 \\
    0      &   0    & \hdots &   0 \\
    \vdots & \vdots &        & \vdots \\
    0      &   0    & \hdots &   0
  \end{bmatrix}.
\end{equation*}
Then we have that $0$ is the \hlnoteb{additive identity}, i.e.
\begin{equation*}
  A + 0 = A = 0 + A.
\end{equation*}
Finally, $\forall A \in M_n(\mathbb{R})$, $\exists (-A) \in M_n(\mathbb{R})$ (the \hlnoteb{additive inverse}) such that
\begin{equation*}
  A + (-A) = 0 - (-A) + A.
\end{equation*}

Note that in this case, we also have that that the operation is \hlnoteb{commutative}, i.e.
\begin{equation*}
  A + B = B + A.
\end{equation*}

\paragraph{Matrix Multiplication} Given $A = [a_{ij}], B = [b_{ij}], C = [c_{ij}] \in M_n(\mathbb{R})$, we define the matrix multiplication as
\begin{equation*}
  AB = [d_{ij}] \text{ where } c_{ij} = \sum_{k=1}^{n} a_{ik} b_{kj} \in \mathbb{R}.
\end{equation*}
Clearly, $AB \in M_n(\mathbb{R})$, i.e. it is \hlnoteb{closed under matrix multiplication}. Also, we have that, under such a defintion, matrix multiplication is \hlnoteb{associative}, i.e.
\begin{equation*}
  A(BC) = (AB)C.
\end{equation*}
Define the identity matrix, $I \in M_n(\mathbb{R})$, as follows:
\begin{equation*}
  I = \begin{bmatrix}
    1      &   0    & \hdots & 0 \\
    0      &   1    & \hdots & 0 \\
    \vdots & \vdots &        & \vdots \\
    0      &   0    & \hdots & 1
  \end{bmatrix}.
\end{equation*}
Then we have that $I$ is the \hlnoteb{multiplicative identity}, since
\begin{equation*}
  AI = A = IA.
\end{equation*}
However, contrary to matrix addition, $\forall A \in M_n(\mathbb{R})$, it is not always true that $\exists A^{-1} \in M_n(\mathbb{R})$ such that\marginnote{This is especially true if the \hlnotea{determinant} of $A$ is $0$.}
\begin{equation*}
  AA^{-1} = I = A^{-1} A.
\end{equation*}

Also, we can always find some $A, B \in M_n(\mathbb{R})$ such that
\begin{equation*}
  AB \neq BA,
\end{equation*}
i.e. matrix multiplication is not always commutative.

\newthought{The common properties} of the operations from above: \hlimpo{closure, associativity, and existence of an inverse}, are not unique to just addition and multiplication. We shall see in the next lecture that there are other operations where these properties will continue to hold, e.g. \hlnoteb{permutations}.

% subsection matrices (end)

% section introduction (end)

% chapter lecture_1_may_02nd_2018 (end)

\chapter{Lecture 2 May 04th 2018}
  \label{chapter:lecture_2_may_04th_2018}

\section{Introduction (Continued)} % (fold)
\label{sec:introduction_continued}

\subsection{Permutations} % (fold)
\label{sub:permutations}

\begin{defn}[Injectivity]\label{defn:injectivity}
\index{Injectivity}
  Let $f: X \to Y$ be a function. We say that $f$ is \hlnoteb{injective} (or \hldefn{one-to-one}) if $f(x_1) = f(x_2)$ implies $x_1 = x_2$.
\end{defn}

\begin{defn}[Surjectivity]\label{defn:surjectivity}
\index{Surjectivity}
  Let $f: X \to Y$ be a function. We say that $f$ is \hlnoteb{surjective} (or \hldefn{onto}) if $\forall y \in Y \enspace \exists x \in X \enspace f(x) = y$.
\end{defn}

\begin{defn}[Bijectivity]\label{defn:bijectivity}
\index{Bijectivity}
  Let $f: X \to Y$ be a function. We say that $f$ is \hlnoteb{bijective} if it is both \hlnoteb{injective} and \hlnoteb{surjective}.
\end{defn}

\begin{defn}[Permutations]\label{defn:permutations}
\index{Permutations}
  Given a non-empty set $L$, a permutation of $L$ is a bijection from $L$ to $L$. The set of all permutations of $L$ is denoted by $S_L$.
\end{defn}

\begin{eg}
  \label{eg:permutations_first}
  Consider the set $L = \{1, 2, 3\}$, which has the following $6$ different permutations: \marginnote{\begin{note}
    \begin{equation*}
      \begin{pmatrix} 1 & 2 & 3 \\ 1 & 3 & 2 \end{pmatrix}
    \end{equation*}
    indicates the bijection $\sigma: \{1, 2, 3\} \to \{1, 2, 3\}$ with $\sigma(1) = 1$, $\sigma(2) = 3$ and $\sigma(3) = 2$.
  \end{note}}

  \begin{gather*}
     \begin{pmatrix} 1 & 2 & 3 \\ 1 & 2 & 3 \end{pmatrix} \quad \begin{pmatrix} 1 & 2 & 3 \\ 1 & 3 & 2 \end{pmatrix} \quad \begin{pmatrix} 1 & 2 & 3 \\ 2 & 1 & 3 \end{pmatrix} \\
     \begin{pmatrix} 1 & 2 & 3 \\ 2 & 3 & 1 \end{pmatrix} \quad \begin{pmatrix} 1 & 2 & 3 \\ 3 & 1 & 2 \end{pmatrix} \quad \begin{pmatrix} 1 & 2 & 3 \\ 3 & 2 & 1 \end{pmatrix}
   \end{gather*} 
\end{eg}

\newthought{For $n \in \mathbb{N}$}, we denote $S_n := S_{\{1, 2, ..., n\}}$, the set of all permutations of $\{1, 2, ..., n\}$. \cref{eg:permutations_first} shows the elements of the set $S_3$.

\begin{defn}[Order]\label{defn:order}
\index{Order}
  The \hlnoteb{order} of a set $A$, denoted by $\abs{A}$, is the cardinality of the set.
\end{defn}

\begin{eg}
  \label{eg:order_of_prev_eg}
  We have seen that the order of $S_3$, $\abs{S_3}$ is $6 = 3!$.
\end{eg}

\begin{propo}\label{propo:order_of_Sn_is_n}
  $\abs{S_n} = n!$
\end{propo}

\begin{proof}
  $\forall \sigma \in S_n$, there are $n$ choices for $\sigma(1)$, $n - 1$ choices for $\sigma(2)$, ..., $2$ choices for $\sigma(n - 1)$, and finally $1$ choice for $\sigma(n)$. \qed
\end{proof}

\paragraph{Do elements of $S_n$ share the same properties as what we've seen in the numbers?} Given $\sigma, \tau \in S_n$, we can \hlnotea{compose} the 2 together to get a third element in $S_n$, namely $\sigma \tau$ (wlog), where $\sigma \tau : \{1, ..., n\} \to \{1, ..., n\}$ is given by $\forall x \in \{1, ..., n\}$, $x \mapsto \sigma( \tau(x) )$.

It is important to note that $\because \sigma, \tau$ are \hlimpo{both bijective}, $\sigma \tau$ is also bijective. Thus, together with the fact that $\sigma \tau : \{1, ..., n\} \to \{1, ..., n\}$, we have that $\sigma \tau \in S_n$ by definition of $S_n$.

$\therefore \forall \sigma, \tau \in S_n, \; \sigma \tau, \tau \sigma \in S_n$, but $\sigma \tau \neq \tau \sigma$ in general. The following is an example of the stated case:

\begin{eg}
  \label{eg:commutativity_of_Sn}
  Let
  \begin{equation*}
    \sigma &= \begin{pmatrix}
      1 & 2 & 3 & 4 \\
      3 & 4 & 1 & 2
    \end{pmatrix}, \text{ and } 
    \tau &= \begin{pmatrix}
      1 & 2 & 3 & 4 \\
      2 & 4 & 3 & 1
    \end{pmatrix}.
  \end{equation*}
  Compute $\sigma \tau$ and $\tau \sigma$ to show that they are not equal.

  \begin{solution}
    \begin{equation*}
      \sigma \tau &= \begin{pmatrix}
        1 & 2 & 3 & 4 \\
        4 & 2 & 1 & 3
      \end{pmatrix} \text{ but } 
      \tau \sigma &= \begin{pmatrix}
        1 & 2 & 3 & 4 \\
        3 & 1 & 2 & 4
      \end{pmatrix}
    \end{equation*}
  \end{solution}
\end{eg}

Perhaps what is interesting is the question of: \textbf{when does commutativity occur?} One such case is when $\sigma$ and $\tau$ have support sets that are disjoint\sidenote{This is proven in A1}.

On the other hand, the associative property holds\sidenote{
  \begin{ex}
    Prove this as an exercise.
  \end{ex}
}, i.e.
\begin{equation*}
  \forall \sigma, \tau, \mu \in S_n \enspace \sigma (\tau \mu) = (\sigma \tau) \mu
\end{equation*}

The set $S_n$ also has an identity element\sidenote{
  \begin{ex}
    Verify that the given identity element is indeed the identity, i.e.
    \begin{equation*}
      \forall \sigma \in S_n \enspace \sigma \epsilon = \sigma = \epsilon \sigma.
    \end{equation*}
  \end{ex}
}, namely
\begin{equation*}
  \epsilon = \begin{pmatrix}
    1 & 2 & \hdots & n \\
    1 & 2 & \hdots & n
  \end{pmatrix}
\end{equation*}

Finally, $\forall \sigma \in S_n$, since $\sigma$ is a bijection, we have that its inverse function, $\sigma^-1$ is also a bijection, and thus satisfies the requirements to be in $S_n$. We call $\sigma^{-1} \in S_n$ to be the \hldefn{inverse permutation} of $\sigma$, such that
\begin{equation*}
  \forall x, y \in \{1, ..., n\} \quad \sigma^{-1}(x) = y \iff \sigma(y) = x.
\end{equation*}
It follows, immediately, that
\begin{equation*}
  \sigma \big( \sigma^{-1}(x) \big) = x \, \land \, \sigma^{-1} \big( \sigma(y) \big) = y.
\end{equation*}
$\therefore$ We have that 
\begin{equation*}
  \sigma \sigma^{-1} = \epsilon = \sigma^{-1} \sigma.
\end{equation*}

\begin{eg}
  \label{eg:inverse_permutation}
  Find the inverse of
  \begin{equation*}
    \sigma = \begin{pmatrix}
      1 & 2 & 3 & 4 & 5 \\
      4 & 5 & 1 & 2 & 3
    \end{pmatrix}
  \end{equation*}

  \begin{solution}
    By rearranging the image in ascending order, using them now as the object and their respective objects as their image, construct
    \begin{equation*}
      \tau = \begin{pmatrix}
        1 & 2 & 3 & 4 & 5 \\
        3 & 4 & 5 & 1 & 2
      \end{pmatrix}.
    \end{equation*}
    It can easily (although perhaps not so prettily) be shown that
    \begin{equation*}
      \sigma \tau = \epsilon = \tau \sigma.
    \end{equation*}
  \end{solution}
\end{eg}

With all the above, we have for ourselves the following proposition:

\begin{propo}[Properties of $S_n$]\label{propo:properties_of_Sn}
  We have
  \begin{enumerate}
    \item $\forall \sigma, \tau \in S_n \enspace \sigma \tau, \tau \sigma \in S_n$.
    \item $\forall \sigma, \tau, \mu \in S_n \enspace \sigma (\tau \mu) = (\sigma \tau) \mu$.
    \item $\exists \epsilon \in S_n \enspace \forall \sigma \in S_n \enspace \sigma \epsilon = \sigma = \epsilon \sigma$.
    \item $\forall \sigma \in S_n \enspace \exists! \sigma^{-1} \in S_n \enspace \sigma \sigma^{-1} = \epsilon = \sigma^{-1} \sigma$.
  \end{enumerate}
\end{propo}

\newthought{Consider}
\begin{equation*}
  \sigma = \begin{pmatrix}
    1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\
    3 & 1 & 7 & 6 & 9 & 4 & 2 & 5 & 8 & 10
  \end{pmatrix} \in S_{10}
\end{equation*}
If we represent the action of $\sigma$ geometrically, we get

\begin{tabular}{c c c}
  \begin{tikzcd}
   & 1 \arrow[rd] &  \\
  2 \arrow[ru] &  & 3 \arrow[ld] \\
   & 7 \arrow[lu] & 
  \end{tikzcd}
  &
  \begin{tikzcd}
  4 \arrow[dd, bend left] \\
   \\
  6 \arrow[uu, bend left]
  \end{tikzcd}
  &
  \begin{tikzcd}
   & 5 \arrow[rdd] &  \\
   &  &  \\
  8 \arrow[ruu] &  & 9 \arrow[ll]
  \end{tikzcd}
  \\ &
  \begin{tikzcd}
    10 \arrow[loop below]
  \end{tikzcd}
\end{tabular}
We observe that $\sigma$ can be \hlnotea{decomposed} into one $4$-cycle, $\begin{pmatrix} 1 & 3 & 7 & 2 \end{pmatrix}$, one $2$-cycle, $\begin{pmatrix} 4 & 6 \end{pmatrix}$, one $3$-cycle, $\begin{pmatrix} 5 & 9 & 8 \end{pmatrix}$, and one $1$-cycle, $\begin{pmatrix} 10 \end{pmatrix}$.

Note that these cycles are (pairwise) \hlnotea{disjoint}, and we can write\sidenote{We generally do not include the $1$-cycle and assume that by excluding them, it is known that any number that is supposed to appear loops back to themselves.}
\begin{equation*}
  \sigma = \begin{pmatrix} 1 & 3 & 7 & 2 \end{pmatrix}\begin{pmatrix} 4 & 6 \end{pmatrix}\begin{pmatrix} 5 & 9 & 8 \end{pmatrix}
\end{equation*}
Note that we may also write
\begin{align*}
  \sigma &= \begin{pmatrix} 4 & 6 \end{pmatrix}\begin{pmatrix} 5 & 9 & 8 \end{pmatrix}\begin{pmatrix} 1 & 3 & 7 & 2 \end{pmatrix} \\
    &= \begin{pmatrix} 6 & 4 \end{pmatrix}\begin{pmatrix} 9 & 8 & 5 \end{pmatrix}\begin{pmatrix} 7 & 2 & 1 & 3 \end{pmatrix}
\end{align*}
It is interesting to note that the cycles can rotate their ``elements'' in a \hlnotea{cyclic} manner, i.e.
\begin{gather*}
  \begin{pmatrix} 1 & 3 & 7 & 2 \end{pmatrix} = \begin{pmatrix} 7 & 2 & 1 & 3 \end{pmatrix} \neq \begin{pmatrix} 1 & 2 & 7 & 3 \end{pmatrix}.
\end{gather*}
Although the decomposition of the cycle notation is not unique (i.e. you may rearrange them), each individual cycle is unique, and is proven below\sidenote{See bonus question of A1. Proof will be included in the notes once the assignment is over.}.

\begin{thm}[Cycle Decomposition Theorem]\label{thm:cycle_decomposition_theorem}
\index{Cycle Decomposition Theorem}
  If $\sigma \in S_n$, $\sigma \neq \epsilon$, then $\sigma$ is a product of (one or more) disjoint cycles of length at least $2$. This factorization is unique up to the order of the factors.
\end{thm}

\begin{note}[Convention]
 Every permutation in $S_n$ can be regarded as a permutation of $S_{n + 1}$ by fixing the permutation of $n + 1$. Therefore, we have that
 \begin{equation*}
   S_1 \subseteq S_2 \subseteq \hdots \subseteq S_n \subseteq S_{n + 1} \subseteq \hdots
 \end{equation*}
\end{note}

% subsection permutations (end)

% section introduction_continued (end)

% chapter lecture_2_may_04th_2018 (end)

\chapter{Lecture 3 May 07th 2018}
  \label{chapter:lecture_3_may_07th_2018}

\section{Groups} % (fold)
\label{sec:groups}

\subsection{Groups} % (fold)
\label{sub:groups}

\begin{defn}[Groups]\label{defn:groups}
\index{Groups}
  Let $G$ be a set and $*$ an operation on $G \times G$. We say that $G = (G, *)$ is a \hlnoteb{group} if it satisfies\sidenote{If you wonder why the uniqueness is not specified for \hlnoteb{Identity} and \hlnoteb{Inverse}, see \cref{propo:uniqueness_of_group_identity_and_group_element_inverse}.}
  \begin{enumerate}
    \item \hlnoteb{Closure}: $\forall a, b \in G \quad a * b \in G$
    \item \hlnoteb{Associativity}: $\forall a, b, c \in G \quad a * (b * c) = (a * b) * c$
    \item \hlnoteb{Identity}: $\exists e \in G \enspace \forall a \in G \quad a * e = a = e * a$
    \item \hlnoteb{Inverse}: $\forall a \in G \enspace \exists b \in G \quad a * b = e = b * a$
  \end{enumerate}
\end{defn}

\begin{defn}[Abelian Group]\label{defn:abelian_group}
\index{Abelian Group}
  A group $G$ is said to be abelian if $\forall a, b \in G$, we have $a * b = b * a$.
\end{defn}

\begin{propo}[Group Identity and Group Element Inverse]\label{propo:uniqueness_of_group_identity_and_group_element_inverse}
  Let $G$ be a group and $a \in G$.
  \begin{enumerate}
    \item The identity of $G$ is unique.
    \item The inverse of $a$ is unique.
  \end{enumerate}
\end{propo}

\begin{proof}
  \begin{enumerate}
    \item If $e_1, e_2 \in G$ are both identities of $G$, then we have
      \begin{equation*}
        e_1 \overset{(1)}{=} e_1 * e_2 \overset{(2)}{=} e_2
      \end{equation*}
      where $(1)$ is because $e_2$ is an identity and $(2)$ is because $e_1$ is an identity.

    \item Let $a \in G$. If $b_1, b_2 \in G$ are both the inverses of $a$, then we have
      \begin{equation*}
        b_1 = b_1 * e = b_1 * (a * b_2) \overset{(1)}{=} e * b_2 = b_2
      \end{equation*}
      where $(1)$ is by associativity.
  \end{enumerate}
\end{proof}

\begin{eg}
  The sets $(\mathbb{Z}, +), \, (\mathbb{Q}, +), \, (\mathbb{R}, +)$, and $(\mathbb{C}, +)$ are all abelian, wehre the additive identity is $0$, and the additive inverse of an element $r$ is $(-r)$.
\end{eg}

\begin{note}
  $(\mathbb{N}, +)$ is not a group for neither does it have an identity nor an inverse for any of its elements.
\end{note}

\begin{eg}
  The sets $(\mathbb{Q}, \cdot), \, (\mathbb{R}, \cdot)$ and $(\mathbb{C}, \cdot)$ are \hlwarn{not} groups, since $0$ has no multiplicative inverse in $\mathbb{Q}, \mathbb{R}$ or $\mathbb{C}$.
\end{eg}

We may define that for a set $S$, let $S^* \subseteq S$ contain all the elements of $S$ that has a multiplicative inverse. For example, $\mathbb{Q}^* = \mathbb{Q} \setminus \{0\}$. Then, $(\mathbb{Q}, \cdot), (\mathbb{R}, \cdot)$ and $(\mathbb{C}, \cdot)$ are groups and are in fact abelian, where the multiplicative identity is $1$ and the multiplicative of an element $r$ is $\frac{1}{r}$.

\begin{eg}
  The set $\big( M_n(\mathbb{R}), + \big)$ is an abelian group, where the additive identity is the zero matrix, $0 \in M_n(\mathbb{R})$, and the additive inverse of an element $M = [a_{ij}] \in M_n(\mathbb{R})$ is $-M = [-a_{ij}] \in M_n(\mathbb{R})$.
\end{eg}

\newthought{Consider} the set $M_n(\mathbb{R})$ under the matrix mutiplication operation that we have introduced in \nameref{chapter:lecture_1_may_02nd_2018}. We found that the identity matrix is
\begin{equation*}
  I = \begin{bmatrix}
    1 & 0 & \hdots & 0 \\
    0 & 1 & \hdots & 0 \\
    \vdots & \vdots & & \vdots \\
    0 & 0 & \hdots & 1
  \end{bmatrix} \in M_n(\mathbb{R}).
\end{equation*}
But since not all elements of $M_n(\mathbb{R})$ have a multiplicative inverse\sidenote{The multiplicative inverse of a matrix does not exist if its determinant is $0$.}, $(M_n(\mathbb{R}), \cdot)$ is not a group.

But we can try to do something similar as to what we did before: by excluding the elements that do not have an inverse. In this case, we exclude elements whose determinant is $0$. Define the set
\begin{equation*}
  GL_n(\mathbb{R}) := \{ M \in M_n(\mathbb{R}) \, : \, \det M \neq 0 \}
\end{equation*}
Note that $\because \det I = 1 \neq 0$, we have that $I \in GL_n(\mathbb{R})$. \\
Also, $\forall A, B \in GL_n(\mathbb{R} )$, we have that $\because \det A \neq 0 \, \land \, \det B \neq 0$,
\begin{equation*}
  \det AB = \det A \det B \neq 0,
\end{equation*}
and therefore $AB \in GL_n(\mathbb{R} )$. Finally, $\forall M \in GL_n(\mathbb{R})$, $\exists M^{-1} \in GL_n(\mathbb{R})$ such that
\begin{equation*}
  MM^{-1} = I = M^{-1} M
\end{equation*}
since $\det M \neq 0$. $\therefore (GL_n(\mathbb{R}), \cdot)$ is a group, and is in fact called the \hldefn{general linear group} \hlnoteb{of degree $n$ over $\mathbb{R}$}.

\newthought{Since} we have introduced permutations in \nameref{chapter:lecture_2_may_04th_2018}, we shall formalize the purpose of its introduction below.

\begin{eg}
  Consider $S_n$, the set of all permutations on $\{1, 2, ..., n\}$. By \cref{propo:properties_of_Sn}, we know that $S_n$ is a group. We call $S_n$ the \hldefn{symmetry group} \hlnoteb{of degree $n$}. For $n \geq 3$, the group $S_n$ is not abelian\sidenote{Let us make this an exercise.
  \begin{ex}
    For $n \geq 3$, prove that the group $S_n$ is not abelian.
  \end{ex}}.
\end{eg}

\newthought{Now that} we have a fairly good idea of the basic concept of a group, we will now proceed to look into handling multiple groups. One such operation is known as the \hldefn{direct product}.

\begin{eg}
  \label{eg:direct_product}
  Let $G$ and $H$ be groups. Their direct product is the set $G \times H$ with the component-wise operation defined by
  \begin{equation*}
    (g_1, h_1) * (g_2, h_2) = (g_1 *_G g_2, h_1 *_H h_2)
  \end{equation*}
  where $g_1, g_2 \in G$, $h_1, h_2 \in H$, $*_G$ is the operation on $G$, and $*_H$ is the operation on $H$.

  The \hlnoteb{closure} and \hlnoteb{associativity} property follow immediately from the definition of the operation. The identity is $(1_G, \, 1_H)$ where $1_G$ is the identity of $G$ and $1_H$ is the identity of $H$. The inverse of an element $(g_1, \, h_1) \in G \times H$ is $(g_1^{-1}, \, h_1^{-1})$.
\end{eg}

By induction, we can show that if $G_1, G_2, ..., G_n$ are groups, then so is $G_1 \times G_2 \times \hdots \times G_n$.

To facilitate our writing, use shall use the following notations:

\begin{notation}
  Given a group $G$ and $g_1, g_2 \in G$, we often denote its identity by $1$, and write $g_1 * g_2 = g_1 g_2$. Also, we denote the unique inverse of an element $g \in G$ as $g^{-1}$.

  We will write $g^0 = 1$. Also, for $n \in \mathbb{N}$, we define
  \begin{equation*}
     g^n = \underbrace{g * g * \hdots * g}_{n \text{ times}}
  \end{equation*}
  and
  \begin{equation*}
    g^{-n} = (g^{-1})^n
  \end{equation*}
\end{notation}

With the above notations,

\begin{propo}\label{propo:group_notations}
  Let $G$ be a group and $g, h \in G$. We have \marginnote{
    \begin{ex}
      Prove \cref{propo:group_notations} as an exercise.
    \end{ex}
  }
  \begin{enumerate}
    \item $(g^{-1})^{-1} = g$
    \item $(gh)^{-1} = h^{-1} g^{-1}$
    \item $g^n g^m = g^{n + m}$ for all $n, m \in \mathbb{Z}$
    \item $(g^n)^m = g^{nm}$ for all $n, m \in \mathbb{Z}$
  \end{enumerate}
\end{propo}

\begin{warning}
  In general, it is not true that if $g, h \in G$, then $(gh)^n = g^n h^n$. For example,
  \begin{equation*}
    (gh)^2 = ghgh \quad \text{but} \quad g^2 h^2 = gghh.
  \end{equation*}
  The two are only equal if and only if $G$ is abelian.
\end{warning}

% subsection groups (end)

% section groups (end)

% chapter lecture_3_may_07th_2018 (end)

\chapter{Lecture 4 May 09 2018}
  \label{chapter:lecture_4_may_09_2018}

\section{Groups (Continued)} % (fold)
\label{sec:groups_continued}

\subsection{Groups (Continued)} % (fold)
\label{sub:groups_continued}

\begin{propo}[Cancellation Laws]\label{propo:cancellation_laws}
  Let $G$ be a group and $g, h, f \in G$. Then
  \begin{enumerate}
    \item \begin{enumerate}
        \item (\hlnoteb{Right Cancellation}) $gh = gf \implies h = f$
        \item (\hlnoteb{Left Cancellation}) $hg = fg \implies h = f$
      \end{enumerate}
    \item The equation $ax = b$ and $ya = b$ have unique solution for $x, y \in G$.
  \end{enumerate}
\end{propo}

\begin{proof}
  \begin{enumerate}
    \item \begin{enumerate}
      \item By left multiplication and associativity,
        \begin{equation*}
          gh = gf \iff g^{-1} gh = g^{-1} gf \iff h = f
        \end{equation*}
      \item By right multiplication and associativity,
        \begin{equation*}
          hg = fg \iff hgg^{-1} = fgg^{-1} \iff h = f
        \end{equation*}
    \end{enumerate}

    \item Let $x = a^{-1} b$. Then
      \begin{equation*}
        a x = a (a^{-1} b) = (aa^{-1}) b = b.
      \end{equation*}
      If $\exists u \in G$ that is another solution, then
      \begin{equation*}
        au = b = ax \implies u = x
      \end{equation*}
      by Left Cancellation. The proof for $ya = b$ is similar by letting $y = ba^{-1}$.
  \end{enumerate}\qed
\end{proof}

% subsection groups_continued (end)

\subsection{Cayley Tables} % (fold)
\label{sub:cayley_tables}

For a finite group, defining its operation by means of a table is sometimes convenient.

\begin{defn}[Cayley Table]\label{defn:cayley_table}
\index{Cayley Table}
  Let $G$ be a group. Given $x, y \in G$, let the product $xy$ be an entry of a table in the row corresponding to $x$ and column corresponding to $y$. Such a table is called a \hlnoteb{Cayley Table}.
\end{defn}

\begin{note}
  By \autoref{propo:cancellation_laws}, the entries in each row (and respectively, column) of a Cayley Table are all distinct.
\end{note}

\begin{eg}
  Consider the group $(\mathbb{Z}_2, +)$. Its Cayley Table is
  \begin{center}
    \begin{tabular}{c|c|c}
      $\mathbb{Z}_2$ & $[0]$ & $[1]$ \\
      \hline
      $[0]$     & $[0]$ & $[1]$ \\
      $[1]$     & $[1]$ & $[0]$ 
    \end{tabular}
  \end{center}
  where note that we must have $[1] + [1] = [0]$; otherwise if $[1] + [1] = [1]$ then $[1]$ does not have its additive inverse, which contradicts the fact that it is in the group.
\end{eg}

\marginnote {
  If we replace $1$ by $[0]$ and $-1$ by $[1]$, the Cayley Tables of $\mathbb{Z}_2$ and $\mathbb{Z}^*$ are the same. In thie case, we say that $\mathbb{Z}_2$ and $\mathbb{Z}^*$ are \hlnotea{isomorphic}, which we denote by $\mathbb{Z}_2 \cong \mathbb{Z}^*$.
}

\begin{eg}
  Consider the group $\mathbb{Z}^* = \{1. -1\}$. Its Cayley Table (under multiplication) is
  \begin{center}
    \begin{tabular}{c|c|c}
      $\mathbb{Z}^*$ & $1$    & $-1$ \\
      \hline
      $1$              & $1$  & $-1$ \\
      $-1$             & $-1$ & $1$
    \end{tabular}
  \end{center}
\end{eg}

\begin{eg}\label{eg:cyclic_group_cayley_table}
  Given $n \in \mathbb{N}$, the \hldefn{Cyclic Group} of order $n$ is defined by
  \begin{equation*}
    C_n = \{1, a, a^2, ..., a^{n - 1}\} \quad \text{with } a^n = 1.
  \end{equation*}
  We write $C_n = \langle a : a^n = 1 \rangle$ and $a$ is called a generator of $C_n$. The Cayley Table of $C_n$ is
  \begin{center}
    \begin{tabular}{c | c c c c c c}
      $C_n$     & $1$       & $a$       & $a^2$  & \hdots & $a^{n - 2}$ & $a^{n - 1}$ \\
      \hline
      $1$       & $1$       & $a$       & $a^2$  & \hdots & $a^{n - 2}$ & $a^{n - 1}$ \\
      $a$       & $a$       & $a^2$     & $a^3$  & \hdots & $a^{n - 1}$ & $1$ \\
      $a^2$     & $a^2$     & $a^3$     & $a^4$  & \hdots & $1$         & $a$ \\
      \vdots    & \vdots    & \vdots    & \vdots &        & \vdots      & \vdots \\
      $a^{n-2}$ & $a^{n-2}$ & $a^{n-1}$ & $1$    & \hdots & $a^{n-4}$   & $a^{n-3}$ \\
      $a^{n-1}$ & $a^{n-1}$ & $1$       & $a$    & \hdots & $a^{n-3}$   & $a^{n-2}$
    \end{tabular}
  \end{center}
\end{eg}

\begin{propo}\label{propo:small_groups}
  Let $G$ be a group. Up to isomorphism, we have
  \begin{enumerate}
    \item if $\abs{G} = 1$, then $G \cong \{1\}$.
    \item if $\abs{G} = 2$, then $G \cong C_2$.
    \item if $\abs{G} = 3$, then $G \cong C_3$.
    \item if $\abs{G} = 4$, then either $G \cong C_4$ or $G \cong K_4 \cong C_2 \times C_2$ \marginnote{$K_n$ is known as the \hldefn{Klein n-group}}.
  \end{enumerate}
\end{propo}

\begin{proof}
  \begin{enumerate}
    \item If $\abs{G} = 1$, then it can only be $G = \{1\}$ where $1$ is the identity element.
    \item $\abs{G} = 2 \implies G = \{1, g\}$ with $g \neq 1$. The Cayley Table of $G$ is thus
      \begin{center}
        \begin{tabular}{c | c c}
        $G$ & $1$ & $g$ \\
        \hline
        $1$ & $1$ & $g$ \\
        $g$ & $g$ & $1$
        \end{tabular}
      \end{center}
      where we note that $g^2 = 1$; otherwise if $g^2 = g$, then we would have $g = 1$ by \autoref{propo:cancellation_laws}, which contradicts the fact that $g \neq 1$. Comparing the above Cayley Table with that of $C_2$, we see that $G = \langle g : g^2 = 1 \rangle \cong C_2$.
    \item $\abs{G} = 3 \implies G = \{1, g, h\}$ with $g \neq 1 \neq h$ and $g \neq h$. We can then start with the following Cayley Table:
      \begin{center}
        \begin{tabular}{c | c c c}
        $G$ & $1$ & $g$ & $h$ \\
        \hline
        $1$ & $1$ & $g$ & $h$ \\
        $g$ & $g$ &     &     \\
        $h$ & $h$ &     &     
        \end{tabular}
      \end{center}
      We know that by \autoref{propo:cancellation_laws}, $gh \neq g$ and $gh \neq h$. Thus $gh = 1$. Similarly, we get that $hg = 1$.

      \underline{Claim:} Entries in a row (or column) must be distinct. Suppose not. Then say $g^2 = 1$. But since $gh = 1$, by \autoref{propo:cancellation_laws}, we have that $h = g$, which is a contradiction.

      With that, we can proceed to fill in the rest of the entries: with $g^2 = h$ and $h^2 = g$. Therefore,
      \begin{center}
        \begin{tabular}{c | c c c}
        $G$ & $1$ & $g$ & $h$ \\
        \hline
        $1$ & $1$ & $g$ & $h$ \\
        $g$ & $g$ & $h$ & $1$ \\
        $h$ & $h$ & $1$ & $g$
        \end{tabular}
      \end{center}

      Recall that the Cayley Table for $C_3$ is:
      \begin{center}
        \begin{tabular}{c | c c c}
        $C_3$ & $1$   & $a$   & $a^2$ \\
        \hline
        $1$   & $1$   & $a$   & $a^2$ \\
        $a$   & $a$   & $a^2$ & $1$ \\
        $a^2$ & $a^2$ & $1$   & $a$
        \end{tabular}
      \end{center}
      $\therefore G \cong C_3$ (by identifying $g = a$ and $h = a^2$).

    \item \hlwarn{Proof will be added once assignment 1 is over}
  \end{enumerate}
\end{proof}

% subsection cayley_tables (end)

% section groups_continued (end)

\section{Subgroups}
\label{sec:subgroups}

\subsection{Subgroups}
\label{sub:subgroups}

\begin{defn}[Subgroup]\label{defn:subgroup}
\index{Subgroup}
  Let $G$ be a group and $H \subseteq G$. If $H$ itself is a group, then we say that $H$ is a subgroup of $G$
\end{defn}

% subsection subgroups (end)

% section subgroups (end)

% chapter lecture_4_may_09_2018 (end)

\chapter{Lecture 5 May 11th 2018}
\label{chp:lecture_5_may_11th_2018}

\section{Subgroups (Continued)}
\label{sec:subgroups_continued}
% section Subgroups (Continued)

\subsection{Subgroups (Continued)}
\label{sub:subgroups_continued}
% subsection Subgroups (Continued)

\begin{note}[Recall: definition of a subgroup]
  Let $G$ be a group and $H \subseteq G$. If $H$ itself is a group, then we say that $H$ is a subgroup of $G$.
\end{note}

\begin{note}
  Since $G$ is a group, $\forall h_1, h_2, h_3 \in H \subseteq G$, we have $h_1 (h_2 h_3) = (h_1 h_2) h_3$. So $H$ is a subgroup of $G$ if it satisfies the following conditions, which we shall hereafter refer to as the Subgroup Test.

\noindent\hldefn{Subgroup Test} \\
  \marginnote{Note that the identity in $H$ must also be the identity in $G$. This is because if $h_1, h_1^{-1} \in H$, then $h_1 h_1^{-1} = 1_H$, but $h_1, h_1^{-1} \in G$ as well, and so $h_1 h_1^{-1} = 1_G$. Thus $1_H = 1_G$.}
  \begin{enumerate}
    \item $h_1 h_2 \in H$
    \item $1_G \in H$
    \item $\exists h_1^{-1} \in H$ such that $h_1 h_1^{-1} = 1_G$
  \end{enumerate}
\end{note}

\begin{eg}
  Given a group $G$, it is clear that $\{1\}$ and $G$ are both subgroups of $G$.
\end{eg}

\begin{eg}
  We have the following chain of groups:
  \begin{equation*}
    (\mathbb{Z}, +) \subseteq (\mathbb{Q}, +) \subseteq (\mathbb{R}, +) \subseteq (\mathbb{C}, +)
  \end{equation*}
\end{eg}

Recall that the general linear group is defined as:
\begin{equation*}
  GL_n(\mathbb{R}) = (GL_n(\mathbb{R}), \cdot) = \{A \in M_n(\mathbb{R}) : \det A \neq 0 \}
\end{equation*}

\begin{defn}[Special Linear Group]\label{defn:special_linear_group}
\index{Special Linear Group}
  The \hlnoteb{special linear group} of order $n$ of $\mathbb{R}$ is defined as
  \begin{equation*}
    SL_n(\mathbb{R}) = (SL_n(\mathbb{R}), \cdot) = \{A \in M_n(\mathbb{R}) : \det A = 1 \}
  \end{equation*}
\end{defn}

\begin{eg}
  Clearly, $SL_n(\mathbb{R}) \subseteq GL_n(\mathbb{R})$. Note that the identity matrix $I$ must be in $SL_n(\mathbb{R})$ since $\det I = 1$. Also, $\forall A, B \in SL_n(\mathbb{R})$, we have that
  \begin{equation*}
    \det AB = \det A \det B = 1
  \end{equation*}
  $\therefore AB \in SL_n(\mathbb{R})$. Also, since $\det A^{-1} = \frac{1}{\det A} = 1$, we also have that $\A^{-1} \in SL_n(\mathbb{R})$. We see that $SL_n(\mathbb{R})$ satisfies the \hlnoteb{Subgroup Test}, and hence it is a subgroup of $GL_n(\mathbb{R})$.
\end{eg}

\begin{defn}[Center of a Group]\label{defn:center_of_a_group}
\index{Center of a Group}
  Given a group $G$, the \hlnoteb{the center of a group $G$} is defined as
  \begin{equation*}
    Z(G) = \{z \in G \, : \, \forall g \in G \enspace zg = gz \}
  \end{equation*}
\end{defn}

\begin{eg}
  For a group $G$, $Z(G)$ is an abelian subgroup of $G$.

  \begin{proof}
    Clearly, $1_G \in Z(G)$. Let $y, z \in G$. $\forall g \in G$, we have that
    \begin{equation*}
      (yz)g = y(zg) = y(gz) = (yg)z = (gy)z = g(yz)
    \end{equation*}
    Therefore $yz \in Z(G)$ and so $Z(G)$ is closed under its operation. Also, $\forall h 
    in G$, we can write $h = (h^{-1})^{-1} = g^{-1}$. Since $z \in Z(G)$, we have that $\forall g \in G$,
    \begin{align*}
      zg = gz \iff (zg)^{-1} = (gz)^{-1} &\iff g^{-1} z^{-1} = z^{-1} g^{-1} \\
          &\iff hz^{-1} = z^{-1} h
    \end{align*}
    Therefore $z^{-1} \in Z(G)$. By the \hlnoteb{Subgroup Test}, it follows that $Z(G)$ is a subgroup of $G$.

    Finally, since $Z(G) \subseteq G$, by its definition, we have that $\forall x, y \in Z(G)$, $x, y \in G$ as well, and we have that $xy = yx$. Therefore, $Z(G)$ is abelian. \qed
  \end{proof}
\end{eg}

\begin{propo}[Intersection of Subgroups is a Subgroup]\label{propo:intersection_of_subgroups_is_a_subgroup}
  Let $H$ and $K$ be subgroups of a group $G$. Then their intersection
  \begin{equation*}
    H \cap K = \{g \in G : g \in H \, \land \, g \in K\}
  \end{equation*}
  is also a subgroup of $G$.
\end{propo}

\begin{proof}
  Since $H$ and $K$ are subgroups, we have that $1 \in H$ and $1 \in K$ and hence $1 \in H \cap K$. Let $a, b \in H \cap K$. Since $H$ and $K$ are subgroups, we have that $ab \in H$ and $ab \in K$. Therefore, $ab \in H \cap K$. Similarly, since $a^{-1} \in H$ and $a^{-1} \in K$, $a^{-1} \in H \cap K$. By the \hlnoteb{Subgroup Test}, $H \cap K$ is a subgroup of $G$. \qed
\end{proof}

\begin{propo}[Finite Subgroup Test]\label{propo:finite_subgroup_test}
\index{Finite Subgroup Test}
\marginnote{This result says that if $H$ is a finite nonempty subset, then we only need to prove that it is closed under its operation to prove that it is a subgroup. The other two conditions in the \hlnoteb{Subgroup Test} are automatically implied.}
  If $H$ is a finite nonempty subset of a group $G$, then $H$ is a subgroup if and only if $H$ is closed under its operation.
\end{propo}

\begin{proof}
  The forward direction of the proof is trivially true, since $H$ must satisfy the closure property for it to be a subgroup.

  For the converse, since $H \neq \emptyset$, let $h \in H$. Since $H$ is closed under its operation, we have that
  \begin{equation*}
    h, h^2, h^3, ...
  \end{equation*}
  are all in $H$. Since $H$ is finite, not all of the $h^n$'s are distinct. Then, $\forall n \in \mathbb{N}$, there must $\exists m \in \mathbb{N}$ such that $h^n = h^{n + m}$. Then by \autoref{propo:cancellation_laws}, $h^m = 1$ and so $1 \in H$. Also, because $1 = h^{m - 1} h$, we have that $h^{-1} = h^{m - 1}$, and thus the inverse of $h$ is also in $H$. Therefore, $H$ is a subgroup of $G$ as requried. \qed
\end{proof}

% subsection Subgroups (Continued) (end)

% section Subgroups (Continued) (end)

% chapter lecture_5_may_11th_2018 (end)

\chapter{Lecture 6 May 14th 2018}
\label{chp:lecture_6_may_14th_2018}
% chapter Lecture 6 May 14th 2018

\section{Subgroups (Continued 2)}
\label{sec:subgroups_continued_2}
% section Subgroups (Continued 2)

\subsection{Alternating Groups}
\label{sub:alternating_groups}
% subsection Alternating Groups

Recall that $\forall \sigma \in S_n$, with $\sigma \neq \epsilon$, $\sigma$ can be uniquely decomposed (up to the order) as disjoint cycles of length at least $2$. We will now present a related concept.

\begin{defn}[Transposition]\label{defn:transposition}
\index{Transposition}
  A \hlnoteb{transposition} $\sigma \in S_n$ is a cycle of length $2$, i.e. $\sigma = \begin{pmatrix} a & b \end{pmatrix}$, where $a, b \in \{1, ..., n\}$ and $a\ neq b$.
\end{defn}

\begin{eg}
  We have that\sidenote{If we apply the permutations on the right hand side, we have that
    \begin{gather*}
      1 \quad 2 \quad 3 \quad 4 \quad 5 \\
      \downarrow \\
      1 \quad 2 \quad 3 \quad 5 \quad 4 \\
      \downarrow \\
      1 \quad 4 \quad 3 \quad 5 \quad 2 \\
      \downarrow \\
      2 \quad 4 \quad 3 \quad 5 \quad 1
    \end{gather*}
  }
  \begin{equation*}
    \begin{pmatrix} 1 & 2 & 4 & 5 \end{pmatrix} = \begin{pmatrix} 1 & 2 \end{pmatrix} \begin{pmatrix} 2 & 4 \end{pmatrix} \begin{pmatrix} 4 & 5 \end{pmatrix}
  \end{equation*}
  Also, we can show that\sidenote{
  \begin{ex}
    Show that \autoref{eq:transposition_eg} is true.
  \end{ex}

  \begin{ex}
    Play around with the same idea and create a few of your own transpositions. Note that you will only be able to get an odd number of tranpositions (why?).
  \end{ex}
  }
  \begin{equation}\label{eq:transposition_eg}
    \begin{pmatrix} 1 & 2 & 4 & 5 \end{pmatrix} = \begin{pmatrix} 2 & 3 \end{pmatrix} \begin{pmatrix} 1 & 2 \end{pmatrix} \begin{pmatrix} 2 & 5 \end{pmatrix} \begin{pmatrix} 1 & 3 \end{pmatrix} \begin{pmatrix} 2 & 4 \end{pmatrix}
  \end{equation}
\end{eg}

Observe that the factorization into transpositions are \hlimpo{not unique or disjoint}. However, the following property is true.

\begin{thm}[Parity Theorem]\label{thm:parity_theorem}
\index{Parity Theorem}
  If a permutations $\sigma$ has $2$ factorizations
  \begin{equation*}
    \sigma = \gamma_1 \gamma_2 \hdots \gamma_r = \mu_1 \mu_2 \hdots \mu_s,
  \end{equation*}
  where each $\gamma_i$ and $\mu_j$ are transpositions, then $r \equiv s \mod 2$.
\end{thm}

\begin{proof}
  \hlwarn{This is the bonus question in A2. Proof shall be included after the end of the assignment.}
\end{proof}

\begin{defn}[Odd and Even Permutations]\label{defn:odd_and_even_permutations}
\index{Odd Permutations}\index{Even Permutations}
  A permutation $\sigma$ is even (or odd) if it can be written as a product of an even (or odd) number of transpositions. By \autoref{thm:parity_theorem}, a permutation must either be even or odd, but not both.
\end{defn}

\begin{thm}[Alternating Group]\label{thm:alternating_group}
\index{Alternating Group}
  For $n \geq 2$, let $A_n$ denote the set of all even permutations in $S_n$. Then
  \begin{enumerate}
    \item $\epsilon \in A_n$
    \item $\forall \sigma, \tau \in A_n \enspace \sigma \tau \in A_n$ and $\exists \sigma^{-1} \in A_n$ such that $\sigma \sigma^{-1} = \epsilon = \sigma^{-1} \sigma$
    \item $\abs{A_n} = \frac{1}{2} n!$
  \end{enumerate}
\end{thm}

\begin{note}
  From items 1 and 2, we know that $A_n$ si a subgroup of $S_n$. $A_n$ is called the \hlnoteb{alternating subgroup of degree $n$}.
\end{note}

\begin{proof}
  \begin{enumerate}
    \item We have that $\epsilon = \begin{pmatrix} 1 & 2 \end{pmatrix} \begin{pmatrix} 1 & 2 \end{pmatrix}$. Thus $\epsilon$ is even and so $\epsilon \in A_n$.
    \item $\forall \sigma, \tau \in A_n$, we may write
      \begin{align*}
        \sigma &= \sigma_1 \sigma_2 \hdots \sigma_r \quad \text{and} \\
        \tau   &= \tau_1 \tau_2 \hdots \tau_s,
      \end{align*}
      where $\sigma_i, \tau_j$ are transpositions, and $r, s$ are even integers. Then
      \begin{equation*}
        \sigma \tau = \sigma_1 \sigma_2 \hdots \sigma_r \tau_1 \tau_2 \hdots \tau_s
      \end{equation*}
      is a product of $(r + s)$ transpositions, and thus $\sigma \tau$ is even. THus $\sigma \tau \in A_n$.

      For the inverse, note that since $\sigma_i$ is a transposition, we have that $\sigma_i^2 = \epsilon$ and thus $\sigma_i^{-1} = \sigma_i$. It follows that
      \begin{align*}
        \sigma^{-1} &= (\sigma_1 \sigma_2 \hdots \sigma_r)^{-1} \\
          &= \sigma_r^{-1} \sigma_{r - 1}^{-1} \hdots \sigma_2^{-1} \sigma_1^{-1} \\
          &= \sigma_r \sigma_{r - 1} \hdots \sigma_2 \sigma_1
      \end{align*}
      which is an even permutation and
      \begin{equation*}
        \sigma \sigma^{-1} = \sigma_1 \sigma_2 \hdots \sigma_r \sigma_r \hdots \sigma_2 \sigma_1 = \epsilon.
      \end{equation*}
      Thus $\exists \sigma^{-1} \in A_n$ such that it is the inverse of $\sigma$.
    \item Let $O_n$ denote the set of odd permutations in $S_n$.\marginnote{For the proof of 3, we know that $\abs{S_n} = n!$, which is twice of the suggested order of $A_n$. Since we took out the even permutations of $S_n$, we just need to make the rest of the permutations, the odd permutations, into a set and prove that $A_n$ and this new set has the same size. One way to show this is by creating a bijection between the two.
    
        Also, note that the set of all odd permutations of $S_n$ is not a group, since
        \begin{itemize}
          \item there is no identity element in this set; and
          \item this set is not closed under map composition.
        \end{itemize}
    
        We have shown that $\epsilon$ is an even permutation, and so by the \hyperref[thm:parity_theorem]{Parity Theorem}, it cannot be an odd permutation, and there is only one identity in $S_n$. The set is not closed under map composition since if we compose two odd permutations, we would get an even permutation, which does not belong to this set.
    } Then we have $S_n = A_n \cup O_n$, and by the \hyperref[thm:parity_theorem]{Parity Theorem}, we have that $A_n \cap O_n = \emptyset$. Since $\abs{S_n} = n!$, to prove that $\abs{A_n} = \frac{1}{2} n!$, it suffices to show that $\abs{A_n} = \abs{O_n}$.
    
    Let $\gamma = \begin{pmatrix} 1 & 2 \end{pmatrix}$ and $f : A_n \to O_n$ such that $f(\sigma) = \gamma \sigma$. Since $\sigma$ is even, $\gamma \sigma$ is odd, and so $f$ is well-defined.
    
    Also, if $\gamma \sigma_1 = \gamma \sigma_2$, then by \hyperref[propo:cancellation_laws]{Cancellation Laws}, $\sigma_1 = \sigma_2$, and hence $f$ is injective.
    
    Finally, $\forall \tau \in O_n$, we have that $\gamma \tau = \sigma \in A_n$. Note that
  \begin{equation*}
    f(\sigma) = \gamma \sigma = \gamma \gamma \tau = \tau.
  \end{equation*}
  Therefore, $f$ is surjective.

  It follows that $\abs{A_n} = \abs{O_n}$. \qed
  \end{enumerate}
\end{proof}

% subsection Alternating Groups (end)

\subsection{Order of Elements}
\label{sub:order_of_elements}
% subsection Order of Elements

\begin{notation}
  If $G$ is a group and $g \in G$, we denote
  \begin{equation*}
    \lra{g} = \{ g^k : k \in \mathbb{Z} \}.
  \end{equation*}
  Note that $1 = g^0 \in \lra{g}$.

  If $x = g^m, y = g^n \in \lra{g}$ where $m, n \in \mathbb{Z}$, then
  \begin{equation*}
    xy = g^m g^n = g^{m + n} \in \lra{g}
  \end{equation*}
  and we have $\exists x^{-1} = g^{-m} \in \lra{g}$ such that
  \begin{equation*}
    xx^{-1} = g^m g^{-m} = g^0 = 1.
  \end{equation*}
\end{notation}

Along with the \hlnoteb{Subgroup Test}, we have the following proposition:

\begin{propo}[Cyclic Group as A Subgroup]\label{propo:cyclic_group_as_a_subgroup}
  If $G$ is a group and $g \in G$, then $\lra{g}$ is a subgroup of $G$.
\end{propo}

\begin{defn}[Cyclic Groups]\label{defn:cyclic_groups}
\index{Cyclic Group}
  Let $G$ be a group and $g \in G$. Then we call $\lra{g}$ the \hlnoteb{cyclic subgroup} of $G$ generated by $g$. If $G = \lra{g}$ for some $g \in G$, then we say that $G$ is a \hlnoteb{cyclic group}, and $g$ is a \hldefn{generator} of $G$.
\end{defn}

% subsection Order of Elements (end)

% section Subgroups (Continued 2) (end)

% chapter Lecture 6 May 14th 2018 (end)

\chapter{Lecture 7 May 16th 2018}%
\label{chp:lecture_7_may_16th_2018}
% chapter lecture_7_may_16th_2018

\section{Subgroups (Continued 3)}%
\label{sec:subgroups_continued_3}
% section subgroups_continued_3

\subsection{Order of Elements (Continued)}%
\label{sub:order_of_elements_continued}
% subsection order_of_elements_continued

\begin{eg}
  Consider $(\mathbb{Z}, +)$ . Note that $\forall k \in \mathbb{Z}$, we can write $k = k \cdot 1 = \underbrace{1 + 1 + \hdots + 1}_{k \text{times}}$. So we have that $(\mathbb{Z} , +) = \lra{1}$. Similarly, we would have $(\mathbb{Z} , +) = \lra{-1}$.

\noindent However, observe that $\forall n \in \mathbb{Z}$ with $n \neq \pm 1$, there is no $k \in \mathbb{Z} $ such that $k \cdot n = 1$. Therefore, $\pm 1$ are the only \hlnotea{generators} of $\mathbb{Z}$.
\end{eg}

\newthought{Let} $G$ be a group and $g \in G$. Suppose $\exists k \in \mathbb{Z}$ with $k \neq 0$ such that $g^k = 1$. Then $g^{-k} = ( g^k )^{-1} = 1$. Thus wlog, we can assume that $k \geq 1$. By the \hlnotea{Well Ordering Principle}, $\exists n \in \mathbb{N}$ such that $n$ is the smallest, such that $g^n = 1$.

With that, we may have the following definition:

\begin{defn}[Order of an Element]\index{Order of an Element}
\label{defn:order_of_an_element}
  Let $G$ be a group and $g \in G$. If $n$ is the smallest positive integer such that $g^n = 1$, we say that the order of $g$ is $n$, denoted by $o(g) = n$.

  \noindent If no such $n$ exists, then we say that $g$ has infinite order and write $o(g) = \infty$.
\end{defn}

\begin{propo}[Properties of Elements of Finite Order]
\label{propo:properties_of_elements_of_finite_order}
  Let $G$ be a group with $g \in G$ where $o(g) = n \in \mathbb{N}$. Then
  \begin{enumerate}
    \item $g^k = 1 \iff n | k$;
    \item $g^k = g^m \iff k \equiv m \mod n$; and
    \item $\lra{g} = \{1, g, g^2, ..., g^{n - 1} \}$ where each $g^i$ is distinct from others.
  \end{enumerate}
\end{propo}

\begin{proof}
  \begin{enumerate}
    \item $(\impliedby)$ If $n | k$, then $k = nq$ for some $q \in \mathbb{Z}$. Then
      \begin{equation*}
        g^k = g^{nq} = (g^n)^q = 1^q = 1
      \end{equation*}

      $(\implies)$ Suppose $g^k = 1$. Since $k \in \mathbb{Z}$, the \hlnotea{Division Algorithm}, we can write $k = nq + r$ with $q, r \in \mathbb{Z}$ and $0 \leq r < n$. Note $g^n = 1$. Thus
      \begin{equation*}
        g^r = g^{k - nq}  = g^k (g^n)^{-q} = 1 \cdot 1 = 1.
      \end{equation*}
      Since $0 \leq r < n$, we must have that $r = 0$. Thus $n | k$.

    \item $(\implies)$ $g^k = g^m \implies g^{k - m} = 1 \overset{\text{by } 1}{\implies} n | ( k - m ) \iff k \equiv m \mod n$
    
      $(\impliedby)$ $k \equiv m \mod n \implies \exists q \in \mathbb{Z} \enspace k = qnm$. The result follows from 1.

    \item $(\supseteq)$ is clear by definition of $\lra{g} = \{g^k : k \in \mathbb{Z}\}$.

      To prove $(\subseteq)$, let $x = g^k \in \lra{g}$ for some $k \in \mathbb{Z}$. By the \hlnotea{Division Algorithm}, $k = nq + r$ for some $q, r \in \mathbb{Z}$ and $0 \leq r < n$. Then
      \begin{equation*}
        x = g^k = g^{nq + r} = g^{nq} g^r \overset{\text{by } 1}{=} g^r.
      \end{equation*}
      Since $0 \leq r < n$, we have that $x \in \{1, g, g^2, ..., g^{n - 1} \}$. Thus $\lra{g} = \{1, g, g^2, ..., g^{n - 1} \}$.

      It remains to show that all the elements in $\lra{g}$ are distinct. Suppose $g^k = g^m$ for some $k, m \in \mathbb{Z}$ with $0 \leq k, m < n$. By 2, we have that $k \equiv m \mod 2$. Therefore, $k = m$.

      We can also use 1 by the fact that $g^{k - m} = 1$ from assumption to complete the uniqueness proof.
  \end{enumerate} \qed
\end{proof}

\begin{propo}[Property of Elements of Infinite Order]
\label{propo:property_of_elements_of_infinite_order}
  Let $G$ be a group, and $g \in G$ such that $o(g) = \infty$. Then
  \begin{enumerate}
    \item $g^k = 1 \iff k = 0$;
    \item $g^k = g^r \iff k = m$;
    \item $\lra{g} = \{..., g^{-2}, g^{-1} 1, g, g^2, ...\}$ where each $g^i$ is distinct from others.
  \end{enumerate}
\end{propo}

\begin{proof}
  It suffices to prove 1, since 2 easily becomes true with 1, and 2 $\implies$ 3.

  \begin{enumerate}
    \item $(\impliedby) \; g^0 = 1$

      $(\implies)$ Suppose for contradiction that $g^k = 1$ for some $k \in \mathbb{Z} \; k \neq 0$. Then $g^{-k} = (g^k)^{-1} = 1$. Then we can assume that $k \geq 1$. This, however, implies that $o(g)$ is finite, which contradicts our assumption. Thus $k = 0$.

    \item \begin{equation*}
      g^k = g^m \iff g^{k - m} = 1 \overset{\text{by } 1}{\iff} k - m = 0 \iff k = m
    \end{equation*}
  \end{enumerate} \qed
\end{proof}

\begin{propo}[Orders of Powers of the Element]
\label{propo:orders_of_powers_of_the_element}
  Let $G$ be a group, and $g \in G$ with $o(g) = n \in \mathbb{N}$. We have that
  \begin{equation*}
    \forall d \in \mathbb{N} \enspace d \; | \; n \implies o(g^d) = \frac{n}{d}
  \end{equation*}
\end{propo}

\begin{proof}
  Let $k = \frac{n}{d}$. Note that $(g^d)^k = g^n = 1$. It remains to show that $k$ is the smallest such positive integer. Suppose $\exists r \in \mathbb{N} \enspace (g^d)^r = 1$. Since $o(g) = n$, then $n \; | \; dr$. Then $\exists q \in \mathbb{Z} \enspace dr = nq$ by definition of divisibility. $\because n = dk$ and $d \neq 0$, we have
  \begin{align*}
    dr = dkq \overset{d \neq 0}{\implies} r = kq \implies r > k \quad \because r, k \in \mathbb{N} \implies q \in \mathbb{N}
  \end{align*}\qed
\end{proof}

% subsection order_of_elements_continued (end)

\subsection{Cyclic Groups}%
\index{Cyclic Group}
\label{sub:cyclic_groups}
% subsection cyclic_groups

Recall the definition of a cyclic groups.

\begin{defn*}[Cyclic Groups]
  Let $G$ be a group and $g \in G$. Then we call $\lra{g}$ the \hlnoteb{cyclic subgroup} of $G$ generated by $g$. If $G = \lra{g}$ for some $g \in G$, then we say that $G$ is a \hlnoteb{cyclic group}, and $g$ is a \hldefn{generator} of $G$.
\end{defn*}

\begin{propo}[Cyclic Groups are Abelian]
\label{propo:cyclic_groups_are_abelian}
  All cyclic groups are abelian.
\end{propo}

\begin{proof}
  Note that a cyclic group $G$ is of the form $G = \lra{g}$. So
  \begin{gather*}
    \forall a, b \in G \enspace \exists m, n \in \mathbb{Z} \enspace a = g^m \, \land \, b = g^n \\
    a \cdot b = g^m g^n = g^{m + n} = g^{n + m} = g^n g^m = b \cdot a
  \end{gather*}\qed
\end{proof}

% subsection cyclic_groups (end)

% section subgroups_continued_3 (end)

% chapter lecture_7_may_16th_2018 (end)

\nobibliography*
\bibliography{bibliography}

\printindex

\chapter{List of Symbols}
% chapter List of Symbols

\begin{tabular}{l l}
  $M_n(\mathbb{R})$  & set of $n \times n$ matrices over $\mathbb{R}$ \\
  $\mathbb{Z}_n^*$   & set of integers modulo $n$; each element has its multiplicative inverse \\
  $S_n$              & symmetry group of degree $n$ \\
  $D_{2n}$           & dihedral group of degree $n$; a subset of $S_n$ \\
  $K_n$              & Klein $n$-group \\
  $A_n$              & alternating group of degree $n$; a subset of $S_n$ \\
  $\abs{D_{2n}}$     & order of the dihedral group; the size of the dihedral group \\
  $\begin{pmatrix} 1 & 2 & \hdots & n \end{pmatrix}$ & An $n$-cycle \\
  $\det A$           & determinant of matrix $A$ \\
  $GL_n(\mathbb{R})$ & \tworow{l}{general linear group of degree $n$;}{the set that contains elements of $M_n(\mathbb{R})$ with non-zero determinant} \\
  $SL_n(\mathbb{R})$ & \tworow{l}{special linear group of order $n$;}{the set that contains elements of $GL_n(\mathbb{R})$ with determinant of $1$} \\
  $Z(G)$             & center of group $G$ \\
  $\lra{g}$          & cyclic group with generator $g$ \\
  $n \; | \; d$      & $n$ divides $d$
\end{tabular}

% chapter List of Symbols (end)

\end{document}
