\documentclass[notoc,notitlepage]{tufte-book}
% \nonstopmode % uncomment to enable nonstopmode

\usepackage{classnotetitle}

\title{PMATH433/733 --- Model Theory and Set Theory}
\author{Johnson Ng}
\subtitle{Classnotes for Fall 2018}
\credentials{BMath (Hons), Pure Mathematics major, Actuarial Science Minor}
\institution{University of Waterloo}

\usepackage{stmaryrd}
\input{latex-classnotes-preamble.tex}

\newcommand{\discup}{\; \overset{\cdot}{\cup} \;}
\newcommand{\bigdiscup}{\overset{\cdot}{\bigcup}}
\newcommand{\class}[1]{\left\llbracket \enspace #1 \enspace \right\rrbracket}
\newcommand{\injection}[1]{\overset{#1}{\hookrightarrow}}
\newcommand{\surjection}[1]{\overset{#1}{\hookleftarrow}}
\DeclareMathOperator{\Ord}{Ord }
\DeclareMathOperator{\Card}{Card }
\DeclareMathOperator{\Set}{Set }
\DeclareMathOperator{\Dom}{Dom }
\DeclareMathOperator{\Img}{Im }
\DeclareMathOperator{\Fun}{Fun }
\DeclareMathOperator{\Var}{Var }
\DeclareMathOperator{\con}{con}
\DeclareMathOperator{\fun}{fun}
\DeclareMathOperator{\rel}{rel}

\begin{document}
\hypersetup{pageanchor=false}
\maketitle
\hypersetup{pageanchor=true}
\begin{fullwidth}
\tableofcontents
\end{fullwidth}

\chapter*{\faBook \enspace List of Definitions}
\addcontentsline{toc}{chapter}{List of Definitions}
\theoremlisttype{noname}
\begin{fullwidth}
\listtheorems{defn}
\end{fullwidth}

\chapter*{\faCoffee \enspace List of Theorems}
\addcontentsline{toc}{chapter}{List of Theorems}
\theoremlisttype{allname}
\begin{fullwidth}
\listtheorems{axiom,lemma,thm,crly,propo}
\end{fullwidth}

\chapter*{Foreword}%
\label{chp:foreword}
% chapter foreword

This course has a ratio of about 1:3 for naive set theory to model theory.

% chapter foreword (end)

\part{Set Theory}

\chapter{Lecture 1 Sep 06th}%
\label{chp:lecture_1_sep_06th}
% chapter lecture_1_sep_06th

\section{Introduction to Set Theory}%
\label{sec:introduction_to_set_theory}
% section introduction_to_set_theory

\newthought{In this course}, we shall focus only on \hlnotea{practical set theory}, which is more commonly knowned as \hlnotea{naive set theory}. In practical set theory, we look at set theory as a language of mathematics. Some of the examples of which we look into in this flavour of set theory are (transfinite) induction and recursion, and the measuring of the sizes of sets.

Another approach to set theory, one that is deemed required in order to learn set theory is a more formal way, is to look at set theory as the foundations of mathematics. Such an approach is more axiomatic, rigorous, and grounding as compared to practical set theory. This course will try to work around going into these topics, as they can take a life of their own, and within the context of this course, the topics that will be explored using this approach are not required.

% section introduction_to_set_theory (end)

\section{Ordinals}%
\label{sec:ordinals}
% section ordinals

\subsection{Zermelo-Fraenkel Axioms}%
\label{sub:zermelo_fraenkel_axioms}
% subsection zermelo_fraenkel_axioms

We use the natural numbers, i.e.
\begin{equation*}
  0, 1, 2, 3, 4, ...
\end{equation*}
to \hlnotea{count} finite sets. There are two related meanings attached to the word ``count'' here:
\begin{itemize}
  \item enumeration; and
  \item measuring (of sizes)
\end{itemize}

In order to facilitate the introduction to certain axioms that we shall need, let our current goal be to develop an infinitary generalization of the natural numbers, so as to be able to enumerate and measure arbitrary sets.\marginnote{We have that
\begin{align*}
  \text{ enumeration } &\to \text{ ordinals } \\
  \text{ measuring } &\to \text{ cardinals }
\end{align*}
where $\to$ represents ``leads to'' here.}

\newthought{To construct} the natural numbers, we require 3 basic notions that shall remain undefined but understood:
\begin{itemize}
  \item a set;
  \item membership, denoted by $\in$; and
  \item equality.
\end{itemize}

One such construction is
\begin{align*}
  0 &:= \emptyset, \text{ the empty set } \\
  1 &:= \{0\} = \{ \emptyset \}, \text{ the set whose only member is } 0 \\
  2 &:= \{0, 1\} = \{ \emptyset, \{ \emptyset \} \}, \text{ the set whose only members are } 0 \text{ and } 1.
\end{align*}

\begin{defn}[Successor]\index{Successor}
\label{defn:successor}
  Given a natural number $n$, the \hlnoteb{successor} of $n$ is the natural number next to $n$, which can be obtained by
  \begin{equation*}
    S(n) := n \cup \{ n \}.
  \end{equation*}
\end{defn}

We can use the definition of a successor to construct the rest of the natural numbers.

\begin{eg}
  Just to verify to ourselves that the definition indeed works, observe that
  \begin{equation*}
    S(1) = 2 = \{ \emptyset, \{ \emptyset \} \} = \{ \emptyset \} \cup \{ \{ \emptyset \} \}.
  \end{equation*}
  So to construct the natural number $3$, we see that
  \begin{align*}
    S(2) &= 3 = \{ 0, 1, 2 \} = 2 \cup \{ 2 \} = \{ \emptyset, \{ \emptyset \} \} \cup \{ \{ \emptyset, \{ \emptyset \} \} \} \\
         &= \{ \emptyset, \{ \emptyset \}, \{ \emptyset, \{ \emptyset \} \} \}
  \end{align*}
\end{eg}

Looking at these, we start wondering to ourselves: how do we know that $\emptyset$ exists in the first place? How do we know that we can use $\cup$ and what does it even mean? Now it is meaningless if we cannot take that $\emptyset$ always exists, nor is it meaningful if we cannot take the $\cup$ of sets. And so, to allow us to continue, or even start with these notions, we require axioms.

\begin{axiom}[Empty Set Axiom]
\index{Empty Set Axiom}
\label{axiom:empty_set_axiom}
  There exists a set, denoted by $\emptyset$, with no members.
\end{axiom}

With this axiom, we can indeed construct $0$. To get $1$ from $0$, we have that $1$ is a set whose only member is zero, and so if we take a member from $1$, that member must be $0$.

\begin{axiom}[Pairset Axiom]
\index{Pairset Axiom}
\label{axiom:pairset_axiom}
  Given set $x, y$, there exists a set, denoted by $\{x , y\}$, whose only members are $x$ and $y$. In other words,
  \begin{equation*}
    t \in \{ x, y \} \lrarrow ( t = x \, \lor \, t = y )
  \end{equation*}
\end{axiom}

Now note that in \cref{axiom:pairset_axiom}, if $x = y$, then the set $\{x, y\}$ has only $x$ as its member. For example, we realize that $1 = \{ 0, 0 \} = \{ 0 \}$. But why exactly does this equality make sense? What exactly does ``realize'' mean?

\begin{axiom}[Axiom of Extension]
\index{Axiom of Extension}
\label{axiom:axiom_of_extension}
  Given sets $x, y$, $x = y$ if and only if $x$ and $y$ have the same members.
\end{axiom}

Now, using the above 3 axioms, we are guaranteed that
\begin{align*}
  0 &= \emptyset \text{ exists by the Empty Set Axiom } \\
  1 &= \{ \emptyset \} \text{ exists by the Pairset Axiom } \\
  2 &= \{ \emptyset, \{ \emptyset \} \} \text{ exists by the Pairset Axiom }
\end{align*}

Now we've constructed $3$ to be the set whose only members are $0, 1$, and $2$. So far, within our axioms, there is no such thing as $\{0, 1, 2\}$, which is what our $3$ is supposed to be. We now require the following axiom:

\begin{axiom}[Union Set Axiom]
\index{Union Set Axiom}
\label{axiom:union_set_axiom}
  Given a set $x$, there exists a set denoted by $\cup x$, whose members are precisely the members of the members of $x$, i.e.
  \begin{equation*}
    t \in \cup x \lrarrow ( t \in y \text{ for some } y \in x )
  \end{equation*}
\end{axiom}

So, by this axiom, we have that given any $n$, $S(n) = \cup \{ n, \{ n \} \}$, or in other words,
\begin{equation*}
  t \in S(n) \lrarrow t \in n \, \lor \, t = n.
\end{equation*}

With all of the above axioms, we can iteratively construct each and every natural number in a rigorous manner. However, our goal is to construct infinitely many of them.

It is tempting to simply take the infinitude of natural numbers simply as an axiom, i.e.

\begin{quotebox}{be-magenta}{light}\label{sp:natural_numbers_axiom}
  There exists a set whose members are precisely the natural numbers.
\end{quotebox}

There is a certain rule to which we set down axioms, and that is, axioms must be expressable in a ``finitary'' manner, i.e. they must be expressible using first-order logic.

\begin{defn}[Definite Condition]\index{Definite Condition}
\label{defn:definite_condition}
  We define a \hlnoteb{definite condition} as follows:
  \begin{itemize}
    \item $x \in y$ and $x = y$ are definite conditions, where $x$ and $y$ are both indeterminants, standing for sets, or are sets themselves;
    \item if $P$ and $Q$ are definite conditions, then so are
      \begin{itemize}
        \item not $P$, denoted as $\neg P$;
        \item $P$ and $Q$, denoted as $P \land Q$;
        \item $P$ or $Q$, denoted as $P \lor Q$;
        \item for all $x$, $P$, denoted as $\forall x P$; and
        \item there exists $x$, $P$, denoted as $\exists x P$.
      \end{itemize}
  \end{itemize}
\end{defn}

\begin{eg}
  \begin{equation*}
    x \in 1, 0 \in 2 , 2 \in 0
  \end{equation*}
  are all definite conditions. Note, however, that $2 \in 0$ is false.
\end{eg}

\begin{note}
  ``If $P$ then $Q$'', which is also written as $P \rarrow Q$, is also a definite condition since it is ``\hlnotea{equivalent}''\sidenote{We have yet to define what equivalent statements are but we shall take this for granted for now.} to the statement $\neg P \lor Q$.

  Consequently, $P if and only if Q$, which is also expressed as $P \lrarrow Q$, can be written as
  \begin{equation*}
    (\neg P \lor Q) \land (\neg Q \lor P)
  \end{equation*}
\end{note}

Now, with this definition, and first-order logic notations in mind, we can write:

\marginnote{
  \begin{ex}
    Write \cref{axiom:axiom_of_extension} in first-order logic notation.
  \end{ex}

  \begin{solution}
    \begin{gather*}
      \forall x \; \forall y \\
      ( x = y ) \lrarrow ( \forall t \; ( ( t \in x ) \lrarrow ( t \in y ) ) )
    \end{gather*}
  \end{solution}
}
\begin{itemize}
  \item Empty Set Axiom: $\exists x \; \forall t \; \neg ( t \in x )$
  \item Pairset Axiom: $\forall x \; \forall y \; \exists p \; \forall t \; ( t \in p \lrarrow ( ( t = x ) \lor ( t = y ) ) )$
    \item Union Set Axiom: $\forall x \; \exists z \; \forall t \; ( ( t \in z ) \lrarrow ( \exists y \; ( (y \in x) \land ( t \in y ) ) ) )$
\end{itemize}

Note that the statement that we proposed as an axiom for the set of natural numbers in page \pageref{sp:natural_numbers_axiom} is not definite, although that itself is not obvious.

For example, we may try to write
\begin{equation*}
  \exists x \; ( \forall t \; ( ( t \in x ) \lrarrow ( (t = 0) \lor (t = 1) \lor ( t = 2 ) \lor ... ) ) )
\end{equation*}
and then notice that we do not have the notion of ``$...$'' within the ``tools'' that we are allowed to use.

% subsection zermelo_fraenkel_axioms (end)

% section ordinals (end)

% chapter lecture_1_sep_06th (end)

\chapter{Lecture 2 Sep 11th}%
\label{chp:lecture_2_sep_11th}
% chapter lecture_2_sep_11th

\section{Ordinals (Continued)}%
\label{sec:ordinals_continued}
% section ordinals_continued

\subsection{Zermelo-Fraenkel Axioms (Continued)}%
\label{sub:zermelo_fraenkel_axioms_continued}
% subsection zermelo_fraenkel_axioms_continued

We stopped at the discussion about allowing for an infinite set, so that we can construct our set of infinite natural numbers. The idea here is to take \textit{the smallest set that contains $0$ and is preserved by the successor function}\sidenote{Q: Why the smallest set?}

\begin{axiom}[Infinity Axiom]
\index{Infinity Axiom}
\label{axiom:infinity_axiom}
  There exists a set $I$ that contains $0$ and is preserved by the successor function. We may express this as
  \begin{equation*}
    \exists I ( ( 0 \in I ) \land \forall x ( x \in I \rarrow S(x) \in I ) )
  \end{equation*}
  where we have defined that $S(x) \in I$ means
  \begin{equation*}
    \exists y ( \forall t ( t \in y \lrarrow (t \in x) \lor ( t = x ) ) \land (y \in I) )
  \end{equation*}
  We call $I$ the \hldefn{successor set}.
\end{axiom}

Since we want the smallest of such successor sets, we can try taking the intersection of all successor sets. But before we can do that, we require more axiomatic statements.

\begin{defn}[Subsets]\index{Subsets}
\label{defn:subsets}
  $x \subseteq y$ means that every element of $x$ is an element of $y$, i.e.
  \begin{equation*}
    \forall t ( ( t \in x ) \rarrow ( t \in y ) )
  \end{equation*}
\end{defn}

With a definition of a subset, we can define the Powerset Axiom.

\begin{axiom}[Powerset Axiom]
\index{Powerset Axiom}
\label{axiom:powerset_axiom}
  Given a set $x$, there exists a set $\mathcal{P}(x)$ that contains all subsets of $x$, i.e.
  \begin{equation*}
    \forall t ( ( t \subseteq \mathcal{P}(x) ) \lrarrow \left( t \subseteq x \right) )
  \end{equation*}
\end{axiom}

We also require the following axiom.

\begin{axiom}[(Bounded) Separation Axiom]
\index{Bounded Separation Axiom}\index{Separation Axiom}
\label{axiom:bounded_separation_axiom}
Given a set $x$ and a definition condition $P$, there exists a set whose elements are precisely the members of $x$ that satisfies $P$, i.e.\marginnote{There are two important aspects to the Bounded Separation Axiom:
  \begin{itemize}
    \item it is bounded by the set $x$; and
    \item $P$ is a definite condition.
  \end{itemize}
}
  \begin{equation*}
    \forall x \; \exists y \; \forall t \; ( ( t \in y ) \lrarrow \forall y \; ( ( t \in x ) \land P(t) ) )
  \end{equation*}
  where
  \begin{equation*}
    y = \{ z \in x \mid P(z) \}.
  \end{equation*}
\end{axiom}

\begin{ex}[Set Intersection]\index{Set Intersection}
  Prove that given a non-empty set $x$, there exists a set $\cap x$ satisfying
  \begin{equation*}
    \forall t \; ( ( t \in \cap x ) \lrarrow \forall y \; ( ( y \in x ) \rarrow (t \in y) ) )
  \end{equation*}
\end{ex}

\begin{proof}
  \hlwarn{to be solved}
\end{proof}

\begin{defn}[Natural Numbers]\index{Natural Numbers}
\label{defn:natural_numbers}
Let $I$ be a successor set. The set of natural numbers is\sidenote{We can also write $J \subseteq I$ as $J \in \mathcal{P}(I)$ and invoke the Bounded Separation Axiom.}
  \begin{equation*}
    \omega := \cap \{ J \subseteq I : J \text{ is a successor set } \}
  \end{equation*}
\end{defn}

\begin{note}
  $J$ being a successor set can be expressed by the definite condition
  \begin{equation*}
    ( 0 \in J ) \land \forall x \; ( x \in J \rarrow S(x) \in J ),
  \end{equation*}
  so we can write the definite condition in the above definition by
  \begin{equation*}
    \omega := \cap \{ J \subseteq I : ( 0 \in J ) \lor \forall x \; ( x \in J \rarrow S(x) \in J ) \}
  \end{equation*}
\end{note}

\begin{ex}
  Show that the definition of $\omega$ does not actually depend on $I$, i.e. if given $I_1$ and $I_2$ such that we have
  \begin{align*}
    \omega_1 &= \cap \{ J \subseteq I_1 : J \text{ is a successor set } \} \\
    \omega_2 &= \cap \{ J \subseteq I_2 : J \text{ is a successor set } \}
  \end{align*}
  we have
  \begin{equation*}
    \omega_1 = \omega_2.
  \end{equation*}
\end{ex}

\begin{proof}
  \hlwarn{to be solved}
\end{proof}

Another useful axiom that we will use later is the following:

\begin{axiom}[Replacement Axiom]
\index{Replacement Axiom}
\label{axiom:replacement_axiom}
  Suppose $P$ is a binary definite condition\sidenote{A \hldefn{binary definite condition} has only two variables.} such that for every set $x$, there is a unique $y$ satisfying $P(x, y)$. Given a set $A$, there is a set $B$ such that $t \in B$ if and only if there is an $a \in A$ with $P(a, t)$.
\end{axiom}

\begin{note}
  The slogan for the Replacement Axiom is:
  \begin{quotebox}{be-red}{light}
    The image of a set under a definite operation exists.
  \end{quotebox}
\end{note}

These eight axioms, along with another ninth axiom called the Regularity Axiom\sidenote{We shall not discuss too much about this. According to the lecture and the lecture notes, the Regularity Axiom states that every set has a minimal element. On Wikipedia, the axiom states that every set has an element that does not intersect with the set itself.}, constitutes the \hlnotea{Zermelo-Fraenkel Set Theory}.

Note that all axioms, save the \hyperref[axiom:axiom_of_extension]{Extensionality}, assert the existence of sets.

% subsection zermelo_fraenkel_axioms_continued (end)

\subsection{Classes}%
\label{sub:classes}
% subsection classes

There are times where we are interested in a collection of sets that do not form a set themselves.

\begin{eg}[Russell's Paradox]\index{Russell's Paradox}
  There is no set containing all sets.

  \begin{proof}
    Suppose such a set exists, and call it $U$. Now consider the set
    \begin{equation*}
      R := \{ x \in U : x \notin x \},
    \end{equation*}
    which exists by \hyperref[axiom:bounded_separation_axiom]{Bounded Separation}. Observe that
    \begin{gather*}
      R \in R \implies R \notin R \quad \text{\Lightning} \\
      \implies R \notin R \implies R \in R \quad \text{\Lightning}
    \end{gather*}
    Thus such a set $U$ cannot exist.
  \end{proof}
\end{eg}

To talk about such collections, that may or may not be sets, we define \textit{classes}.

\begin{defn}[Class]\index{Class}
\label{defn:class}
  A class is any collection of sets defined by definite property, i.e. given any difinite condition $P$,
  \begin{equation*}
    \class{ z \mid P(z) }
  \end{equation*}
  is the class of all sets satisfying $P$.
\end{defn}

Here, instead of \hyperref[axiom:bounded_separation_axiom]{Bounded Separation}, we have what is called \hlnotea{unbounded separation}.

\begin{note}
  We shall use $\class{}$ rather than $\{ \; \; \}$ to emphasize that we are talking about classes, i.e. we may be talking about non-sets.
\end{note}

\begin{eg}
  \begin{equation*}
    \Set := \class{ z \mid z = z }
  \end{equation*}
  is the universal class of all sets.
\end{eg}

\begin{note}
  \begin{itemize}
    \item Every set is a class.
      \begin{proof}
        Suppose $x$ is a set. We may write
        \begin{equation*}
          x = \class{ z \mid z \in x }.
        \end{equation*}\qed
      \end{proof}

    \item Some classes are not sets; these are called \hldefn{proper classes}. E.g. the universal class of all sets, and
      \begin{equation*}
        \text{Russell} := \class{ z \mid z \notin z }.
      \end{equation*}
  \end{itemize}
\end{note}

% subsection classes (end)

% section ordinals_continued (end)

% chapter lecture_2_sep_11th (end)

\chapter{Lecture 3 Sep 13th}%
\label{chp:lecture_3_sep_13th}
% chapter lecture_3_sep_13th

\section{Ordinals (Continued 2)}%
\label{sec:ordinals_continued_2}
% section ordinals_continued_2

\subsection{Cartesian Products and Function}%
\label{sub:cartesian_products_and_function}
% subsection cartesian_products_and_function

\begin{defn}[Ordered Pairs]\index{Ordered Pairs}
\label{defn:ordered_pairs}
  Given sets $x, y$, an \hlnoteb{ordered pair} of $x$ and $y$ is defined as\sidenote{This invokes the Pairset Axiom thrice.}\marginnote{Why did we not define an ordered pair as
  \begin{equation*}
    (x, y) = \{ \{x\}, \{y \} \}
  \end{equation*}
  instead?}
  \begin{equation*}
    (x, y) = \{ \{ x \}, \{ x, y \} \}
  \end{equation*}
\end{defn}

\begin{note}
  Note that we must have
  \begin{equation*}
    ( (x, y) = (x', y') ) \iff ( x = x' \land y = y' ).
  \end{equation*}

  \begin{proof}
    The $(\impliedby)$ direction is clear by Extensionality. For the other direction, we shall break it into 2 cases:

    \noindent\textbf{Case 1}: $x = y$. Then $\{x, y\} = \{x\}$ by Extensionality, and so
    \begin{equation*}
      (x, y) = \{ \{ x \} \}
    \end{equation*}
    Therefore, we have that
    \begin{equation*}
      \{ \{ x \} \} = (x, y) = (x', y') = \{ \{ x' \}, \{ x', y' \} \}
    \end{equation*}
    So we have
    \begin{equation*}
      \{ x \} = \{ x' \} \implies x = x'
    \end{equation*}
    and
    \begin{equation*}
      \{ x \} = \{ x', y' \} \implies y' = x = y.
    \end{equation*}
    Thus we have
    \begin{equation*}
      x = x' \land y = y'.
    \end{equation*}

    \noindent \textbf{Case 2}: Suppose $x \neq y$ and $x' \neq y'$ \sidenote{If any of them are equal, Case 1 would apply.} We have
    \begin{equation*}
      \{ \{ x \}, \{ x, y \} \} = \{ \{ x' \}, \{ x', y' \} \}
    \end{equation*}
    Then
    \begin{equation*}
      \{ x \} = \{ x' \} \lor \{ x \} = \{ x', y' \}
    \end{equation*}
    The latter leads to a contradiction, since it would imply
    \begin{equation*}
      x' = x = y'.
    \end{equation*}
    Thus $x = x'$. Also, we have
    \begin{equation*}
      \{ x, y \} = \{ x' \} \lor \{ x, y \} = \{ x', y' \}
    \end{equation*}
    Now the former leads to a contradiction since it would imply that
    \begin{equation*}
      x = x' = y.
    \end{equation*}
    Now since $x = x'$, it must be that $y = y'$, otherwise $y = x' = x$ would contradict our assumption. Therefore, we have that
    \begin{equation*}
      x = x' \land y = y'.
    \end{equation*}\qed
  \end{proof}
\end{note}

With ordered pairs, we can build Cartesian products:

\begin{defn}[Cartesian Product]\index{Cartesian Product}
\label{defn:cartesian_product}
  Given classes $X$ and $Y$, the \hlnoteb{Cartesian Product} of $X$ and $Y$ is defined as
  \begin{equation*}
    X \times Y := \class{ z : z = (x, y), x \in X, y \in Y }
  \end{equation*}
\end{defn}

\begin{note}
  We can express this definition using definite conditions;
  \begin{fullwidth}
  \begin{gather*}
    \forall x, y \Bigg( (x \in X) \land (y \in Y) \land \Big( \exists a, b ( \forall t ( t \in a \lrarrow t = x ) ) \land \forall t ( t \in b \lrarrow (t = x) \lor (t = y) ) \Big) \land \\
    \forall t \Big( t \in z \lrarrow \big( (t = a) \lor (t = b) \big) \Big) \Bigg)
  \end{gather*}
  \end{fullwidth}
\end{note}

\begin{note}
  \begin{itemize}
    \item A Cartesian product is a class.
    \item If $A$ is a set and $B$ is a class, and $B \subseteq A$, then $B$ is also a set. This is easy to show: observe that by Extentionality,
      \begin{equation*}
        B = \{ a \in A \mid a \in B \}.
      \end{equation*}
      By Bounded Separation Axiom, $B$ is a set\sidenote{This statement can be rephrased as: subclasses of a set are subsets.}.
  \end{itemize}
\end{note}

Consequently, Cartesian products of sets are sets themselves; if $X$ and $Y$ are sets, we want to show that $X \times Y$ is a set so it is sufficient to show that it is contained in one. Recall that
\begin{equation*}
  (x, y) = \{ \{ x \}, \{ x, y \} \}
\end{equation*}
and $\{ x, y \} \subset X \cup Y$ which means $\{ x, y \} \in \mathcal{P}(X)$, and we observe that $\{ x \} \in \mathcal{P}(X \cup Y)$. So $(x, y) \in \mathcal{P}(X \cup Y)$. Therefore, $X \times Y \subset \mathcal{P} ( \mathcal{P} (X \cup Y) )$, and we show to ourselves that $X \times Y$ is indeed a set.

\begin{defn}[Definite Operation]\index{Definite Operation}
\label{defn:definite_operation}
  Given classes $X$ and $Y$, a \hlnoteb{definite operation} $f: X \to Y$ is a subclass $\Gamma(f) \subseteq X \times Y$ such that
  \begin{equation*}
    \forall x \in X \; \exists ! y \in Y \; (x, y) \in \Gamma(f).
  \end{equation*}
\end{defn}

\begin{note}
  We write $f(x) = y$ to mean $(x, y) \in \Gamma(f)$. We also refer to $\Gamma(f)$ as the \hldefn{graph of $f$}.
\end{note}

\begin{eg}
  The successor function $S : \Set \to \Set$ is a definite operation such that\marginnote{To show that $S$ is a definite operation, we need to show that $S$ is a definite condition.}
  \begin{equation*}
    S(x) = x \cup \{x\}
  \end{equation*}
  This is true since is can be expressed as
  \begin{equation*}
    \forall t ( t \in y \lrarrow ( t \in x \lor t = x ) ).
  \end{equation*}
\end{eg}

\begin{note}
  If $X$ and $Y$ are sets and $f$ is a definite operation, then $\Gamma(f) \subseteq X \times Y$ is a set. In such a case, we call $f$ a function.
\end{note}

\begin{defn}[Functions]\index{Functions}
\label{defn:functions}
  A function is a definite operation $f : X \to Y$ where $X$ and $Y$ are both sets.
\end{defn}

We can now restate the Replacement Axiom.

\begin{axiom}[Replacement Axiom (Restated)]
\index{Replacement Axiom}
\label{axiom:replacement_axiom_restated}
  If $f : X \to Y$ is a definite operation, and $A \subseteq X$ is a set, then $\exists B \subseteq Y$ that is a set such that $t \in B$ if and only if $t = f(a)$ for some $a \in A$.
\end{axiom}

% subsection cartesian_products_and_function (end)

\subsection{The Natural Numbers}%
\label{sub:the_natural_numbers}
% subsection the_natural_numbers

\begin{thm}[Induction Principle]
\index{Induction Principle}
\label{thm:induction_principle}
  Suppose $J \subseteq \omega$, $0 \in J$ and whenever $n \in J$, $S(n) \in J$. Then $J = \omega$.
\end{thm}

\begin{proof}
  By assumption, $J$ is a successor set, therefore $\omega \subseteq J$ by definition. Thus, sinec $J \subseteq \omega$, we have $J = \omega$.\qed
\end{proof}

\begin{lemma}[Properties of the Natural Numbers]
\label{lemma:properties_of_the_natural_numbers}
  Suppose $n \in \omega$. We have
  \begin{enumerate}
    \item $n \subseteq \omega$;
    \item $\forall m \in n \quad m \subseteq n$;
    \item $n \notin n$;
    \item $n = 0 \veebar 0 \in n$; and
    \item $y \in n \implies S(y) \in n \veebar S(y) = n$.
  \end{enumerate}
\end{lemma}

\begin{proof}
  \begin{enumerate}
    \item Let\sidenote{We construct this $J$ and show that it is a successor set. Note that if $J = \omega$, our proof is complete.}
      \begin{equation*}
        J := \{ n \in \omega : n \subseteq \omega \} \subseteq \omega.
      \end{equation*}
      Note that $\emptyset \subseteq \omega$ and so $0 \subseteq \omega$. By membership, $0 \in J$.
      
      Suppose $m \in J$. Consider $S(m) = m \cup \{ m \}$. Since $J \subseteq \omega$, $m \in \omega$. Since $m \in \omega$, $\{ m \} \subseteq \omega$. Therefore $S(m) = m \cup \{ m \} \subseteq \omega$, and so $S(m) \in J$. So $J$ is a successor set. And thus by \hyperref[thm:induction_principle]{Induction Principle}, $J = \omega$.

    \item Let
      \begin{equation*}
        J := \{ n \in \omega: \forall m \in n, m \subseteq n \}.
      \end{equation*}
      It is vacuously true that $0 \in J$ since $\emptyset$ is a subset of every $n \in J$. Suppose $n \in J$. Then $\forall m \in n$, we have $m \subseteq n$. Consider $S(n) = n \cup \{ n \}$. Note that $n \in S(n)$ and $n \subseteq S(n)$. For $x \in S(n)$ such that $x \neq n$, we must have that $x \in n$. By assumption, $x \subseteq n \subseteq S(n)$. Therefore, $S(n) \in J$, and so $J$ is a successor set. By the Induction Principle, $J = \omega$.

    \item Let
      \begin{equation*}
        J := \{ n \in \omega : n \notin n \}.
      \end{equation*}
      We have $0 = \emptyset \notin \emptyset$. So $0 \in J$.

      Let $n \in J$. Consider $S(n) = n \cup \{n\}$. In particular, note that $n \in S(n)$. Suppose, for contradiction, that $S(n) \in S(n)$. Then $S(n) = n$ or $S(n) \in n$.

      $S(n) = n \implies n \in S(n) = n$ \Lightning $n \notin n$.

      $S(n) \in n \implies S(n) \subseteq n$ by part 2 $\implies n \in n$ \Lightning $n \notin n$.

      Thus $S(n) \notin S(n)$ and so $S(n) \in J$. So $J$ is a successor set, and so by the \hyperref[thm:induction_principle]{Induction Principle}, $J = \omega$.

    \item It suffices to show that
      \begin{equation*}
        \omega = \{0\} \cup \{ n \in \omega: 0 \in n \}.
      \end{equation*}
      Let $J =$ RHS. We have that $0 \in J$. Suppose $n \in J$ such that $n \neq 0$. Then $0 \in n$. Since $n \subseteq S(n) = n \cup \{n\}$, we have that $0 \in S(n)$. Therefore, $S(n) \in J$. So $J$ is a successor set, and so by the Induction Principle, $J = \omega$ as required.

    \item Let
      \begin{equation*}
        J := \{ n \in \omega : y \in n \implies S(y) \in n \veebar S(y) = n \}.
      \end{equation*}
      $0 \in J$ is vacuously true, since there are no $y \in 0$. Suppose $n \in J$. Let $y \in S(n) = n \cup \{ n \}$. We have two choices: either $y \in n$ or $y = n$. If $y \in n$, then $S(y) \in n \veebar S(y) = n$, since $n \in J$. We have that

      $S(y) \in n \subseteq S(n)$ in which case we are done; and

      $(sy) \subseteq n \in S(n)$.

      Otherwise, if $y \notin n$, then $y = n$. Then we simply have $S(y) = S(n)$. Thus $J$ is a succesor set and so by the Induction Principle, $J = \omega$.
  \end{enumerate}\qed
\end{proof}

% subsection the_natural_numbers (end)

\subsection{Well-Orderings}%
\label{sub:well_orderings}
% subsection well_orderings

\begin{defn}[Strict Partially Ordered Set]\index{Strict Partially Ordered Set}\index{Strict Poset}
\label{defn:strict_partially_ordered_set}
  A \hlnoteb{strict partially ordered set} (or \hlnoteb{strict poset}\sidenote{This is my unofficial terminology}) is a set $E$ together with $R \subseteq E^2 = E \times E$ such that
  \begin{enumerate}
    \item (\hlnotea{anti-reflexive}) $\forall a \in E \quad (a, a) \notin R$;
    \item (\hlnotea{anti-symmetric}) $\forall a, b \in E \quad (a, b) \in R \land (b, a) \in R \implies a = b$; and
    \item (\hlnotea{transitivity}) $\forall a, b, c \in E \quad (a, b), (b, c) \in R \implies (a, c) \in R$.
  \end{enumerate}
\end{defn}

\begin{defn}[Strict Totally Ordered Set]\index{Strict Totally Ordered Set}\index{Strict Linearly Ordered Set}
\label{defn:strict_totally_ordered_set}
  A strict poset is \hlnoteb{total} (or \hlnoteb{linear}) if
  \begin{equation*}
    \forall a, b \in E \quad (a, b) \in R \veebar (b, a) \in R
  \end{equation*}
\end{defn}

\begin{defn}[Well-Order]\index{Well-Order}
\label{defn:well_order}
  A strict linear order is \hlnoteb{well-ordered} if
  \begin{equation*}
    \forall X \subseteq E ( X \neq \emptyset ) \quad \exists a \in X \quad \forall b \in X ( b \neq a ) \quad (a, b) \in R
  \end{equation*}
  i.e. every nonempty subset of $E$ has a \hlimpo{least element}.
\end{defn}

We shall prove the following next lecture.\sidenote{Anti-reflexivity and Anti-symmetry were proven in this lecture, but I am moving it to the next for ease of reading.}

\begin{propononum}[$\omega$ is Strictly Well-ordered]
  $(\omega, \in)$ is a strict well-ordering.
\end{propononum}

% subsection well_orderings (end)

% section ordinals_continued_2 (end)

% chapter lecture_3_sep_13th (end)

\chapter{Lecture 4 Sep 18th}%
\label{chp:lecture_4_sep_18th}
% chapter lecture_4_sep_18th

\section{Ordinals (Continued 3)}%
\label{sec:ordinals_continued_3}
% section ordinals_continued_3

\subsection{Well-Orderings (Continued)}%
\label{sub:well_orderings_continued}
% subsection well_orderings_continued

\marginnote{
  \begin{marginlemmanonum}[\cref{lemma:properties_of_the_natural_numbers}]
  Suppose $n \in \omega$. We have
  \begin{enumerate}
    \item $n \subseteq \omega$;
    \item $\forall m \in n \quad m \subseteq n$;
    \item $n \notin n$;
    \item $n = 0 \veebar 0 \in n$; and
    \item $y \in n \implies S(y) \in n \veebar S(y) = n$.
  \end{enumerate}
\end{marginlemmanonum}
}
\begin{propo}[$\omega$ is Strictly Well-Ordered]
\label{propo:_omega_is_strictly_well_ordered}
  $(\omega, \in)$ is a strict well-ordering.
\end{propo}

\begin{proof}
  By \cref{lemma:properties_of_the_natural_numbers}, we have that $\forall n \in \omega$, $n \notin n$. (\hlnotea{anti-reflexivity \faCheck}).

  \noindent $\forall n, m \in \omega$, suppose, for contradiction, that $n \in m$ and $m \in n$. Again, by \cref{lemma:properties_of_the_natural_numbers}, we have $n \subseteq m$ and $m \subseteq n$, which implies that $n = m$. Thus, we have $n \in m = n$ and $m \in n = m$, a contradiction to the fact that $n \notin n$ and $m \notin m$ (\hlnotea{anti-symmetry \faCheck}).

  \noindent $\forall x, y, z \in \omega$ such that $x \in y$ and $y \in z$, by \cref{lemma:properties_of_the_natural_numbers}, $y \in z \implies y \subseteq z \implies x \in z$ (\hlnotea{transitivity \faCheck}).

  To show totality of the relation, let $n \in \omega$. WTS for any $m \in \omega$, either
  \begin{equation*}
    m \in n, \quad m = n, \text{ or } n \in m.
  \end{equation*}
  Let\sidenote{We construct $J$ such that $J$ will contain all the possible cases, and use this fact to prove that $J = \omega$ so these 3 cases are the only scenarios that can happen.}
  \begin{equation*}
    J = \underset{ \in n }{n} \cup \underset{= n}{ \{ n \} } \cup \underset{> n}{ \{ m \in \omega : n \in m \} }.
  \end{equation*}
  \noindent\underline{Case 1: $n = 0$.} In this case, we have\sidenote{Note that $0 = \emptyset$.}
  \begin{equation*}
    J = \emptyset \cup \{ \emptyset \} \cup \{ m \in \omega : 0 \in m \}
  \end{equation*}
  As a consequence of \cref{lemma:properties_of_the_natural_numbers} (4), we have that $J = \omega$.

  \noindent\underline{Case 2: $n \neq 0$.} Again, by \cref{lemma:properties_of_the_natural_numbers} (4), since $n \neq 0$, we must have $0 \in n \subseteq J$ and so $0 \in J$. Now suppose that $m \in J$.

  \underline{Case 2(a): $m \in n$.} Then by \cref{lemma:properties_of_the_natural_numbers} (5), $S(m) \in n$ or $S(m) = n$.\\
  $S(m) \in n \implies S(m) \in J$\\
  $S(m) \in n \implies S(m) \in J$

  \underline{Case 2(b): $m = n$.} Then $S(m) = S(n) = n \cup \{ n \}$. And so $n \in S(m)$, which implies $S(m) \in J$.

  \underline{Case 2(c): $n \in m$} Then since $S(m) = m \cup \{ m \}$, we have that $m \in m \subseteq S(m)$. Therefore $S(m) \in J$.

  Therefore, $J$ is a sucessor subset of $\omega$. Thus by the Induction Principle, $J = \omega$. (\hlnotea{totality \faCheck})

  To prove that $\in$ is a well-ordering, suppose $X \subseteq \omega$ is non-empty. Suppose, for contradiction, that $X$ has no $\in$-least element. Now consider
  \begin{equation*}
    J = \{ n \in \omega : S(n) \cap X = \emptyset \}
  \end{equation*}
  \noindent\underline{Claim: $J$ is a successor set.}\sidenote{Since we want to prove that $\in$ is a well-ordering, we can suppose that there is a non-empty subset of $\omega$ that is not empty, and has no $\in$-least element. The core idea here is that, by the construction of $J$, if $J = \omega$, then all elements of $\omega$ would be disjoint from $X$, forcing $X$ to be the empty set.}

  By \cref{lemma:properties_of_the_natural_numbers} (4), $0$ is the $\in$-least element of $\omega$. If $0 \in X$, then $0$ would be $\in$-least in $X$, contradicting our supposition. Thus $0 \notin X$, And so
  \begin{equation*}
    S(0) \cap X = ( 0 \cup \{ 0 \} ) \cap X = \{ 0 \} \cap X = \emptyset
  \end{equation*}
  since $0 \notin X$. Thus $0 \in J$.

  Suppose $n \in J$. By construction of $J$, we have $S(n) \cap X = \emptyset$. Observe that
  \begin{equation*}
    S(S(n)) \cap X = ( S(n) \cup \{ S(n) \} ) \cap X.
  \end{equation*}
  Now if RHS of the above is non-empty (aiming for contradiction), then we may have $S(n) \in X$. Then $S(n)$ would be the $\in$-least element in $X$, a contradiction. If $m \in S(n)$, we have that $m \notin X$ since $S(n) \cap X = \emptyset$. Thus $SS(n) \cap X = \emptyset$ and so $S(n) \in J$. Therefore, by the Induction Principle, $J = \omega$.

  We observe that $\forall n \in \omega$,
  \begin{equation*}
    \emptyset = S(n) \cap X) = ( n \cup \{ n \} ) \cap X
  \end{equation*}
  $\implies n \notin X$, and so we must have $X = \emptyset$ (\hlnotea{well-ordered \faCheck}).\qed
\end{proof}

\begin{note}
  Given $n, m \in \omega$, we often write $n < m$ to mean $n \in m$.
\end{note}

\begin{defn}[Ordinals]\index{Ordinals}
\label{defn:ordinals}
  An \hlnoteb{ordinal} is a set $\alpha$ satisfying:
  \begin{enumerate}
    \item $x \in \alpha \implies x \subseteq \alpha$;
    \item $(\alpha, \in)$ is a strict well-ordering.
  \end{enumerate}
\end{defn}

\begin{eg}
  $\omega$ is an ordinal: $\forall n \in \omega$, by \cref{lemma:properties_of_the_natural_numbers}, $n \subseteq \omega$, and $\omega$ is proven to have a strict well-ordering under $\in$.
\end{eg}

\begin{eg}
  Every natural number is an ordinal (\textit{finite ordinals}): by \cref{lemma:properties_of_the_natural_numbers} (2), the first property is satisfied; well-ordering follows from the property of $\omega$.
\end{eg}

Let $\Ord$ denote the class of all ordinals. We shall show later that $\Ord$ is a proper class.

\begin{ex}
  Verify that for a set to be an ordinal is a definite condition.

  Observe that
  \begin{equation*}
    \forall t ( t \in \Ord \lrarrow ( ( x \in t \implies x \subseteq t ) \land ( (t, \in) \text{ is a strict well-ordering } ) ) )
  \end{equation*}
  where $( x \in t \implies x \subset t )$ is the definite condition
  \begin{equation*}
    \forall x ( x \in t \rarrow \forall a ( a \in x \rarrow a \in t ) )
  \end{equation*}
  and $(t, \in)$ is a strict well-ordering is the definite condition
  \begin{equation*}
    \forall s ( s \subseteq t \land s \neq \emptyset \rarrow \exists a ( a \in s \rarrow \forall b ( b \in s \land b \neq a \rarrow (a, b) \in (\in)) ) )
  \end{equation*}
\end{ex}

\begin{lemma}[Proper Subsets of an Ordinal Are Its Elements]
\label{lemma:proper_subsets_of_an_ordinal_are_its_elements}
  If $\alpha, \beta \in \Ord$ and $\alpha \subsetneq \beta$, then $\alpha \in \beta$.
\end{lemma}

\begin{proof}
  We shall prove that $\alpha$ is the least element in $\beta$ that is not in $\alpha$ itself.\sidenote{We shall construct a subset of $\beta \setminus \alpha$ and show that $\alpha$ is its element.}

  Let $D := \beta \setminus \alpha = \{ x \in \beta : x \notin \alpha \} \subset \beta$ \sidenote{Exists by Bounded Separation Axiom.}. Since $\alpha \subsetneq \beta$, $D \neq \emptyset$. Since $\beta \in \Ord$, $(\beta, \in)$ has a strict well-ordering, and so $D$ has a least element, $d$. Note that $d \in \beta$, and since $\beta \in \Ord$, $d \subseteq \beta$.

  \noindent\underline{Claim: $\alpha = d$.}\sidenote{If $\alpha = d$, then $\alpha$ is the said least element.} WTS $\alpha \subseteq d$. $\forall x \in \alpha$, we have $x, d \in \beta$. Then since $(\beta, \in)$ is a strict well-ordering, we have either
  \begin{equation*}
    x < d, \quad x = d, \; \text{ or } d < x
  \end{equation*}
  Note that $x \neq d$, otherwise $x = d \in D = \beta \setminus \alpha$.

  \sidenote{
    This is an errorneous proof.
    \begin{marginwarning}
      \begin{gather*}
      d < x \land x < \alpha \\
      \underset{\text{transitivity}}{\implies} d < \alpha \implies d \in \alpha
      \end{gather*}

      This argument is errorneous because we do not yet know if $\alpha \in \beta$.
    \end{marginwarning}} If $d < x$, then $d \in x$ (by our notation). Now since $\alpha \in \Ord$, $x < \alpha \implies x \in \subseteq$, and so $d \in \alpha$, which is yet another contradiction ($d \in D = \beta \setminus \alpha$).

    Thus we must have $x < d$, i.e. $x \in d$. So $\alpha \subseteq d$.

    WTS $d \subseteq \alpha$. Suppose not. Then let $x \in d \setminus \alpha$. Then since $d \in D = \beta \setminus \alpha$, we have $x \in \beta \setminus \alpha$, which then contradicts the minimality of $d$. Therefore, $d = \alpha$ as required.\qed
\end{proof}

\begin{propo}[Properties of Ordinals]
\label{propo:properties_of_ordinals}
\marginnote{
  Some of proofs of these properties are available in the course notes.
  \begin{ex}
    Prove \cref{item:properties_of_ordinals_3}, \cref{item:properties_of_ordinals_4}, and \cref{item:properties_of_ordinals_5} of \cref{propo:properties_of_ordinals}.
  \end{ex}
}
  \begin{enumerate}
    \item Every member of an ordinal is an ordinal.\label{item:properties_of_ordinals_1}
    \item $\alpha \in \Ord \implies \alpha \notin \alpha$.\label{item:properties_of_ordinals_2}
    \item $\alpha \in \Ord \implies S(\alpha) \in \Ord$.\label{item:properties_of_ordinals_3}
    \item $\alpha, \beta \in \Ord \implies \alpha \cap \beta \in \Ord$.\label{item:properties_of_ordinals_4}
    \item $\alpha, \beta \in \Ord \implies \alpha \in \beta \lor \alpha = \beta \lor \beta \in \alpha$.\label{item:properties_of_ordinals_5}
    \item $E \subseteq \Ord$ a subset $\implies (E, \in)$ is a strict well-ordering.\label{item:properties_of_ordinals_6}\sidenote{\hlwarn{I think} that such an $E$ need not be an ordinal itself. For example, $E = \{ 1, 5, 10 \} \subset \Ord$, but $4 \in 5$ and $4 \notin E$, and so $5 \in E$ but $5 \nsubseteq E$.}
    \item $\Ord$ is a proper class.\label{item:properties_of_ordinals_7}
  \end{enumerate}
\end{propo}

\begin{proof}
  \begin{enumerate}
    \item Suppose $x \in \beta \in \Ord$. WTS $x \in \Ord$, and we shall show that $x$ satisfies \cref{defn:ordinals}.

      Since $\beta \in \Ord, \, x \in \beta \implies x \subseteq \beta$. Thus $(x, \in)$ is a strict well-ordering (through inheriting the property). So it suffices to show that $y \in x \implies y \subseteq x$. So let $y \in x$, and let $t \in x$ \sidenote{To show that $y \subseteq x$, we need to show that $\forall t \in y$, $t \in x$.}. Observe that
      \begin{align*}
        t \in y &\implies t < y \\
        y \in x &\implies y < x
      \end{align*}
      and $t, y, x \in \beta \in \Ord$. Therefore, by transitivity, we have $t < y < x \implies t \in x$.

    \item Suppose not, i.e. $\alpha \in \alpha$. Then $\alpha \subseteq \alpha \in \Ord$, and so $(\alpha, \in)$ is a strict well-ordering, i.e. $\alpha \notin \alpha$, a contradiction.

    \setcounter{enumi}{5}
    \item Suppose $A \subseteq E$ and $A \neq \emptyset$. Let $\alpha \in A$.

      \noindent\underline{Case 1: $\alpha \cap A = \emptyset$.} Then $\forall \beta \in \alpha \implies \beta \notin A$. Therefore $\alpha$ is $\in$-least in $A$.

      \noindent\underline{Case 2: $a \cap A \neq \emptyset$.} Let $A' = \alpha \cap A \subseteq \alpha$. Since $\alpha \in A \subseteq E \subseteq \Ord$, we have $(\alpha, \in)$ is a strict well-ordering, and so $A'$ has a strict well-ordering as well, and thus it must have a $\in$-least element, $x$. Then $x$ is the $\in$-least element in $A$.

    \item If $\Ord$ is a set, then by \cref{item:properties_of_ordinals_6}, $(\Ord, \in)$ is a strict well-ordering. Also, by \cref{item:properties_of_ordinals_1}, every element of $\Ord$ is a subset of $\Ord$. Therefore, $\Ord$ satisfies \cref{defn:ordinals}, and so $\Ord \in \Ord$, which contradicts \cref{item:properties_of_ordinals_2}. Therefore $\Ord \notin \Set$.
  \end{enumerate}\qed
\end{proof}

% subsection well_orderings_continued (end)

% section ordinals_continued_3 (end)

% chapter lecture_4_sep_18th (end)

\chapter{Lecture 5 Sep 20th}%
\label{chp:lecture_5_sep_20th}
% chapter lecture_5_sep_20th

\section{Ordinals (Continued 4)}%
\label{sec:ordinals_continued_4}
% section ordinals_continued_4

\begin{note}
  If $A, B \in \Ord$, we will write $A < B$ to mean $A \in B$.
\end{note}

\begin{propo}[Properties of Ordinals 2]
\label{propo:properties_of_ordinals_2}
  \begin{enumerate}
    \item If $\alpha \in \Ord$, then $\alpha < S(\alpha)$, and there is nothing in between.\label{item:properties_of_ordinals_2_1}
    \item Let $E \subseteq \Ord$, where $E \neq \emptyset$ is a set, and $\sup E := \cup E$. Then $\sup E \in \Ord$, and it is a least upper bound for $E$.\label{item:properties_of_ordinals_2_2}\sidenote{I noted down from the lectures that this is "not necessarily strict", but I do not remember what it means now. \hlwarn{(Clarification required.)}
      
      Perhaps this related to my question; can $E = \sup E$? \newthought{This} is not necessarily true. If $E \notin \Ord$, then $E \neq \sup E$.}

    \item If $E \subseteq \Ord$ is a subset, then there is a least ordinal that is not in $E$.\label{item:properties_of_ordinals_2_3}\marginnote{
      \begin{ex}
        Prove \cref{propo:properties_of_ordinals_2} \cref{item:properties_of_ordinals_2_3}.
      \end{ex}
      \newthought{Recommended strategy}: $\alpha \in \Ord$ such that $E \subsetneq \alpha$ and take the least element of $\alpha \setminus E$ (which is non-empty). Prove that this least element is the least ordinal that is not in $E$.

      You can take $\alpha = SS(\sup E)$. Verify that this works.
    }
  \end{enumerate}
\end{propo}

\begin{proof}
  \begin{enumerate}
    \item Since $S(\alpha) = \alpha \cup \{ \alpha \}$, $\alpha \in S(\alpha)$ and so $\alpha < S(\alpha)$.

      It suffices to show that $\forall x < S(\alpha)$, we have $x \leq \alpha$. Let $x < S(\alpha)$, i.e. $x \in S(\alpha)$. So $x \in \alpha$ or $x = \alpha$, i.e. $x < \alpha$ or $x = \alpha$.

    \item By definition, $\forall x \in E \subseteq \Ord$, we have that $x \subseteq \Ord$. Since $\cup E \subseteq E$, we have that $\cup E \subseteq \Ord$ is a subset. Thus by \cref{propo:properties_of_ordinals} \cref{item:properties_of_ordinals_6}, $(\cup E, \in)$ is a strict well-ordering.

      \sidenote{This part shows that $\cup E$ is also an ordinal.} Suppose $\alpha \in \cup E$, then $\exists e \in E$ such that $\alpha \in e \subseteq E \subseteq \Ord$. So $e$ is an ordinal and so $\alpha \subseteq e$. \sidenote{Now we show that $\alpha \subseteq \cup E$.} $\forall x \in \alpha$, we have $x \in e \in E$, and so $x \in \cup E$ by definition. Therefore $\alpha \subseteq \cup E$.

      And so, we have shown that $\cup E = \sup E \in \Ord$.

      \noindent\underline{Claim 1: $\sup E$ is an upper bound for $E$.}

      Suppose, for contradiction, that $\exists e \in E$ such that $\sup E < e$. Then since $\sup E$ and $e$ are both ordinals, we have $\sup E \in e \in E$. Then by definition of $\cup$, we have that $\sup E \in \cup E = \sup E$, but by \cref{propo:properties_of_ordinals} \cref{item:properties_of_ordinals_2}, $\sup E \notin \sup E$, a contradiction.

      Thus $\sup E$ is an upper bound as claimed.

      \noindent\underline{Claim 2: $\sup E$ is the supremum (least upper bound).}

      $\forall \alpha < \sup E$, we have that $\alpha \in \sup E = \cup E$, and so $\exists e \in E$ such that $\alpha \in e$. Then $\alpha < e \in E$, i.e. $\alpha$ is not an upper bound of $E$.
  \end{enumerate}
\end{proof}

\begin{defn}[Successor Ordinal]\index{Successor Ordinal}
\label{defn:successor_ordinal}
  The \hlnoteb{successor ordinal} is an ordinal of the form $S(\alpha)$ for some $\alpha \in \Ord$.
\end{defn}

\begin{defn}[Limit Ordinal]\index{Limit Ordinal}
\label{defn:limit_ordinal}
  A \hlnoteb{limit ordinal} is an ordinal that is not a successor.
\end{defn}

\begin{eg}
  $0$ and $\omega$ are both limit ordinals; $0$ is vacuosly a limit ordinal, and $\omega$ is not a successor of any $\alpha \in Ord$ \sidenote{Need a more careful proof, which I cannot do. The idea is to show that any such ordinal $\alpha$ will be an element of $\omega$, and so will its successor $S(\alpha)$, and $\omega \notin \omega$.}.

  On the other hand, for $n \in \omega$ such that $n \neq 0$, $\exists \cup n \in \omega$ such that $S(\cup n) = n$ \sidenote{See A1.}.
\end{eg}

\begin{ex}
  Prove that $S(\omega)$ is a successor ordinal.
\end{ex}

\begin{solution}
  We have that $\omega \in \Ord$, and so $S(\omega)$ is a successor ordinal.
\end{solution}

\subsection{Transfinite Induction \& Recursion}%
\label{sub:transfinite_induction_n_recursion}
% subsection transfinite_induction_n_recursion

\begin{thm}[Transfinite Induction Theorem v1]
\index{Transfinite Induction Theorem}
\label{thm:transfinite_induction_theorem_v1}
  Suppose $P$ is a definite condition, with the property
  \begin{equation}\label{eq:transfinite_induction_v1_condition}
    \forall \alpha \in \Ord \land ( \forall \beta < \alpha \; P(\beta) ) \implies P(\alpha).
  \end{equation}
  Then $P$ is true of all ordinals.
\end{thm}

\begin{proof}
  $P(0)$ is vacuously true, since there are no elements that are less than $0$. Suppose $P(\alpha)$ is false for some $\alpha \in \Ord$ such that $\alpha > 0$. By the Bounded Separation Axiom,
  \begin{equation*}
    D := \{ \beta \leq \alpha : \neg P(\beta) \}
  \end{equation*}
  is a set \sidenote{Note that $\beta \leq \alpha \iff \beta < \alpha \lor \beta = \alpha \iff \beta \in S(\alpha)$}. Note that $D \neq \emptyset$, since $\alpha \in D$. Since $\alpha \in \Ord$, we have $D \subseteq \alpha \subseteq \Ord$, and so $(D, \in)$ has a strict well-ordering. Let $\alpha_0 \in D$ be $\in$-least. Then $\forall \beta < \alpha_0$, we have that $\neg P(\beta)$, which contradicts the assumption \cref{eq:transfinite_induction_v1_condition}. Thus $P(\alpha)$ is true for all ordinals.\qed
\end{proof}

\begin{thm}[Transfinite Induction Theorem v2]
\index{Transfinite Induction Theorem}
\label{thm:transfinite_induction_theorem_v2}
  Suppose $P$ is a definite condition satisfying\marginnote{This statement strongly resembles the Induction Princple that we have learnt in the earlier years of university. In contrast, v1 resembles Strong Induction Principle. It can be shown that v1 $\iff$ v2. v1 $\implies$ v2 is proven in this lecture.
    
    \begin{ex}
      Prove that \cref{thm:transfinite_induction_theorem_v2} $\implies$ \cref{thm:transfinite_induction_theorem_v1}.
    \end{ex}}
  \begin{enumerate}
    \item $P(0)$;
    \item $\forall \beta \in \Ord \; P(\beta) \implies P(S(\beta))$; and
    \item If $\alpha \in \Ord$ is a limit ordinal and $\forall \beta < \alpha$, $P(\beta)$, then $P(\alpha)$.
  \end{enumerate}
  Then $P$ is true of all ordinals.
\end{thm}

\begin{proof}
  It suffices to show that $P$ satisfies \cref{eq:transfinite_induction_v1_condition}, i.e. $\forall \alpha \in \Ord$, we want to prove that $\forall \beta < \alpha$, if $P(\beta)$, then $P(\alpha)$.

  When $\alpha = 0$, we have $P(0)$ and so \cref{eq:transfinite_induction_v1_condition} is satisfies. When $\alpha > 0$ is a limit ordinal, our assumption immediately satisfies \cref{eq:transfinite_induction_v1_condition}. Now suppose $\alpha > 0$ is a successor ordinal, and suppose that $\alpha = S(\gamma)$ for some $\gamma \in \Ord$. By the assumption in \cref{eq:transfinite_induction_v1_condition}, we have that
  \begin{equation*}
    \forall \beta < \gamma \; P(\beta) \implies P(\gamma)
  \end{equation*}
  and so by condition (2), we have $P(S(\gamma))$ since $\gamma \in \Ord$. Thus we have $P(\alpha) = P(S(\gamma))$. \qed
\end{proof}

We shall prove the following in the next lecture:

\begin{thmnonum}[Transfinite Recursion]
  Let $X$ be a class of all definite operations whose domain is an ordinal. Given a definite operation
  \begin{equation*}
    G : X \to \Set
  \end{equation*}
  $\exists ! F : \Ord \to \Set$, a definite operation, such that $F(\alpha = F(F \restriction_{\alpha}))$, for all $\alpha \in \Ord$.
\end{thmnonum}

We want to use Transfinite Recursion to construct definite operations on ordinals such that they have properties that we are familiar with (and hence desire).

\begin{note}[Notation - Restriction]
  Let $H : U \to Y$ be a definite operation on classes $U, Y$, and $Z \subseteq U$ a subclass. $H \restriction_{Z}$ is the definite operation
  \begin{equation*}
    H \restriction_{Z} : Z \to Y
  \end{equation*}
  obtained by restricting $H$ onto $Z$.
\end{note}

\begin{note}
  In the theorem, we stated that $F$ has its domain on $\Ord$. We know that for $\alpha \in \Ord$, $\alpha \subseteq \Ord$, and so $F \restriction_{\alpha}$ makes sense; in particular,
  \begin{equation*}
    F \restriction_{\alpha} : \alpha \to \Set.
  \end{equation*}
  Note that $F \restriction_{\alpha} \in X$, and so $G(F \restriction_{\alpha})$ is valid and makes sense.
\end{note}

% subsection transfinite_induction_n_recursion (end)

% section ordinals_continued_4 (end)

% chapter lecture_5_sep_20th (end)

\chapter{Lecture 6 Sep 25th}%
\label{chp:lecture_6_sep_25th}
% chapter lecture_6_sep_25th

\section{Ordinals (Continued 5)}%
\label{sec:ordinals_continued_5}
% section ordinals_continued_5

\subsection{Transfinite Induction \& Recursion (Continued)}%
\label{sub:transfinite_induction_n_recursion_continued}
% subsection transfinite_induction_n_recursion_continued

\begin{thm}[Transfinite Recursion v1]
\index{Transfinite Recursion}
\label{thm:transfinite_recursion_v1}
  Let $X$ be a class of all definite operations whose domain is an ordinal. Given a definite operation
  \begin{equation*}
    G : X \to \Set
  \end{equation*}
  $\exists ! F : \Ord \to \Set$, a definite operation, such that $F(\alpha) = G(F \restriction_{\alpha}))$, for all $\alpha \in \Ord$.
\end{thm}

Before proving the theorem, we shall note the following definition.

\begin{defn}[$\alpha$-function]\index{$\alpha$-function}
\label{defn:alpha_function}
  Using definitions in \cref{thm:transfinite_recursion_v1}, a function $t$ with domain in the ordinals is called an \hlnoteb{$\alpha$-function} defined by $G$ if
  \begin{equation*}
    \forall \beta < \alpha \quad t(\beta) = G(t \restriction_\beta).
  \end{equation*}
\end{defn}

\begin{proof}
  We shall first prove for \textbf{uniqueness}. Suppose $F$ and $F'$ are two definition operations such that
  \begin{gather*}
    F: \Ord \to \Set \quad F' : \Ord \to \Set \\
    F(\alpha) = G(F\restriction_\alpha) \quad F'(\alpha) = G(F'\restriction_\alpha)
  \end{gather*}

  \sidenote{Here, we want to use \hyperref[thm:transfinite_induction_theorem_v1]{Transfinite Induction v1} to show that they are unique.}Suppose $\forall \beta < \alpha \in \Ord$, we have $F(\beta) = F'(\beta)$. Note that
  \begin{gather*}
    F(\beta) = F'(\beta) \iff F\restriction_\alpha = F'\restriction_\alpha \\
    \implies F(\alpha) = G(F\restriction_\alpha) = G(F'\restriction_\alpha) = F'(\alpha)
  \end{gather*}
  Thus, uniqueness of $F$ is guaranteed.

  To prove existence, firstly, we note that the $\alpha$-functions defined in \cref{defn:alpha_function} are approximations to the $F$ that we want. However, before going further, we need to show that they are also unique and that we can form a chain of extensions on these functions over $\Ord$.

  \paragraph{Uniqueness of $t_\alpha$} Let $t, t'$ be a $\alpha$-functions defined by $G$. WTS $\forall \beta < \alpha$, $t(\beta) = t'(\beta)$. If an $\alpha$-function defined by $G$ exists, we shall denote it as $t_\alpha$.

  Consider the definite condition
  \begin{equation*}
    P(x) := ( x \geq \alpha ) \lor ( t(x) = t'(x) ).
  \end{equation*}
  Suppose that $\forall \gamma < \beta$, $P(\gamma)$ holds, i.e. $\gamma \geq \alpha$ or $t(\gamma) = t'(\gamma)$, which implies that $t\restriction_\beta = t'\restriction_\beta$. Therefore $t(\beta) = t'(\beta)$, i.e. $P(\beta)$ holds. Thus $t_\alpha$ is unique if it exists by Transfinite Induction.

  \paragraph{$t_\alpha$ as a chain of extensions} Now $\forall \beta < \alpha \in \Ord$, we have that $\beta \subseteq \alpha$. If $t_\alpha$ and $t_\beta$ exist, then
  \begin{equation*}
    \Gamma(t_\beta) \subseteq \Gamma(t_\alpha),
  \end{equation*}
  or in other words
  \begin{equation*}
    t_\alpha \restriction_\beta = t_\beta.
  \end{equation*}
  We shall denote this relation as $t_\beta \subseteq t_\alpha$.

  \paragraph{Existence of $t_\alpha$} The existence of $t_\alpha$ is a definite condition: by the Replacement Axiom, a function that maps $\alpha \mapsto t_\alpha$ is definite, and by Bounded Separation Axiom, the set
  \begin{equation*}
    \Gamma(t_\alpha) = \{ (\beta, G(t_\alpha \restriction_\beta) \mid \beta < \alpha, t_\alpha(\beta) = G(t_\alpha \restriction_\beta) \} \subseteq \Ord \times \Set
  \end{equation*}
  exists. \sidenote{We use Transfinite Induction v2 to CTP.}Now $t_0 = t_\emptyset$ is vacuously true. Suppose for any successor ordinal $\alpha$, $t_\alpha$ exists. Since $\alpha \in \Ord$, we have that there is nothing between $\alpha$ and its successor $S(\alpha)$, and $\alpha < S(\alpha)$. Thus
  \begin{equation*}
    t_{S(\alpha)} = t_\alpha \cup \{ (\alpha, G(t_\alpha)) \},
  \end{equation*}
  which exists by Union Set Axiom. We see that $t_{S(\alpha)}$ extends $t_\alpha$ onto $\alpha$ itself.

  Suppose $\alpha > 0$ is a limit ordinal. Since $t_\alpha$ is a definite condition by Replacement, by Bounded Separation, we have that\sidenote{\hlwarn{Verify the motivation in using or the reason behind getting this.}}
  \begin{equation*}
    t_\alpha = \bigcup_{\beta < \alpha} t_\beta = \cup \{ t_\beta : \beta < \alpha \}.
  \end{equation*}
  Note that $t_\alpha$ is, indeed, an $\alpha$-function defined by $G$:
  \begin{itemize}
    \item $t_\alpha$ is a function on $\alpha$: we have that $\forall \beta < \alpha$,the $t_\beta$'s form a chain of extensions;
    \item $t_\alpha$ is an $\alpha$-function defined by $G$: $\forall \beta < \alpha$, since $\alpha$ is a limit ordinal, $S(\beta) < \alpha$, and so
      \begin{equation*}
        t_\alpha(\beta) = t_{S(\beta)}(\beta) = G(t_{S(\beta)} \restriction_\alpha) = G(t_\beta \restriction_\alpha).
      \end{equation*}
  \end{itemize}
  And so by Transfinite Induction, $\forall \alpha \in Ord$, $t_\alpha$ exists as required.

  \paragraph{Construction of $F$} Now for any $\beta < \alpha$, we have a chain of extensions
  \begin{equation*}
    t_0 \subseteq t_1 \subseteq t_2 \subseteq \hdots \subseteq t_\beta \subseteq t_\alpha \subseteq \hdots
  \end{equation*}

  Let\sidenote{I will leave the proof unfinished here. \hlwarn{Need to verify my understanding}}
  \begin{equation*}
    F := \bigcup_{\alpha \in \Ord} t_\alpha = \cup \class{ t_\alpha \mid \alpha \in \Ord }
  \end{equation*}
\end{proof}

\begin{crly}[Transfinite Recursion v2]
\index{Transfinite Recursion}
\label{crly:transfinite_recursion_v2}
  Given $G_1 \in \Set$, $G_2 : \Set \to \Set$ a definite operation, $G_3 : X \to \Set$ a definite operation, where $X$ is the class of all definite opeartion whose domain is an ordinal. Then
  \begin{equation*}
    \exists ! F : \Ord \to \Set
  \end{equation*}
  such that
  \begin{enumerate}
    \item $F(0) = G_1$;
    \item $\forall \alpha \in \Ord \enspace F(S(\alpha)) = G_2(F(\alpha))$; and
    \item $\forall \beta > 0$ a limit ordinal, $F(\beta) = G_3(F\restriction_\beta)$.
  \end{enumerate}
\end{crly}

\begin{proof}
  The result is clear by \cref{thm:transfinite_induction_theorem_v1} with $G : X \to Set$ defined by
  \begin{equation*}
    G(f) = \begin{cases}
      G_1            & f = \emptyset \\
      G_2(f(\alpha)) & \Dom(f) = S(\alpha) \\
      G_3(f)         & \Dom(f) > 0 \text{ a limit ordinal }
    \end{cases}
  \end{equation*}\qed
\end{proof}

% subsection transfinite_induction_n_recursion_continued (end)

\subsection{Ordinal Arithmetric}%
\label{sub:ordinal_arithmetric}
% subsection ordinal_arithmetric

\subsubsection{Ordinal Addition}
\label{ssub:Ordinal Addition}

\begin{defn}[Ordinal Addition]\index{Ordinal Addition}
\label{defn:ordinal_addition}
  Let $\beta \in \Ord$. For any $\alpha \in \Ord$, we define
  \begin{equation*}
    \beta + \alpha
  \end{equation*}
  using Transfinite Recursion\sidenote{Note that we are using \cref{crly:transfinite_recursion_v2} with
  \begin{align*}
    G_1 &= \beta \\
    G_2 &= S : \Set \to \Set \\
    G_3 &: X \to \Set \text{ by } G_3(f) = \sup \Img(f)
  \end{align*}
  } on $\alpha$ as follows:
  \begin{itemize}
    \item $\beta + 0 := \beta$;
    \item if $\alpha$ is a successor ordinal, then $\beta + S(\alpha) := S(\beta + \alpha)$; and
    \item if $\alpha > 0$ is a limit ordinal, then $\beta + \alpha := \sup \{ \beta + \gamma : \gamma < \alpha \}$.
  \end{itemize}
\end{defn}

\begin{ex}
  Using both the Induction Principle and Transfinite Induction, prove that $\beta + \alpha \in \Ord$.
\end{ex}

\begin{eg}
  We have that
  \begin{equation*}
    0, 1, 2, ..., \omega, \omega + 1, \omega + 2, ..., \omega + \omega
  \end{equation*}
  Observe that
  \begin{equation*}
    \omega + 1 = \omega + S(0) = S(\omega + 0) = S(\omega)
  \end{equation*}
  and so $\omega + 1$ is a successor to $\omega$. In general, we have that $\forall \alpha \in \Ord$, $\alpha + 1 = S(\alpha)$. For example,
  \begin{equation*}
    \omega + 2 = \omega + S(1) = S(\omega + 1).
  \end{equation*}
  On the other hand, note that
  \begin{equation*}
    \omega + \omega = \sup \{ \omega + n : n \in \omega \}.
  \end{equation*}
  Unlike regular addition, ordinal addition is not commutative. For instance, while $\omega + 1 = S(\omega)$,
  \begin{equation*}
    1 + \omega = \sup \{ 1 + n : n \in \omega \} = \omega.
  \end{equation*}
\end{eg}

\begin{ex}
  Prove that ordinal addition is only commutative for ``finite'' ordinals.
\end{ex}

\subsubsection{Ordinal Multiplication}
\label{ssub:Ordinal Multiplication}

\begin{defn}[Ordinal Multiplication]\index{Ordinal Multiplication}
\label{defn:ordinal_multiplication}
  Let $\beta \in \Ord$. For any $\alpha \in Ord$, we define
  \begin{equation*}
    \beta \cdot \alpha
  \end{equation*}
  using Transfinite Recusion\sidenote{Here, we use
  \begin{align*}
    G_1    & = 0 \\
    G_2    & : \Set \to \Set \text{ by } G_2(x) = x + \beta \\
    G_3(f) & = \sup \Img(f)
  \end{align*}
  } as follows:
  \begin{itemize}
    \item $\beta \cdot 0 := 0$;
    \item if $\alpha$ is a successor ordinal, $\beta \cdot S(\alpha) := \beta \alpha + \beta$ \\
    \item if $\alpha > 0$ is a limit ordinal, $\beta \cdot \alpha := \sup \{ \beta \cdot \gamma : \gamma < \alpha \}$.
  \end{itemize}
\end{defn}

\begin{eg}
  We have
  \begin{equation*}
    \omega \cdot 1 = \omega \cdot S(0) = \omega \cdot 0 + \omega = 0 + \omega = \omega.
  \end{equation*}
\end{eg}

\begin{ex}
  Prove that in general, $\forall \beta \in \Ord$, we have $\beta \cdot 1 = \beta$.
\end{ex}

\begin{ex}
  Prove that $\forall \alpha, \beta \in \Ord$, $\alpha \cdot \beta \in \Ord$.
\end{ex}

\begin{eg}
  We have
  \begin{equation*}
    \omega \cdot 2 = \omega \cdot S(1) = \omega \cdot 1 + \omega = \omega + \omega.
  \end{equation*}
\end{eg}

\begin{ex}
  Prove that in general, $\forall \beta \in \Ord$, we have $\beta \cdot 2 = \beta + \beta$.
\end{ex}

Note that ordinal multiplication, like its addition counterpart, is not necessarily commutative.

\begin{eg}
  While we have
  \begin{equation*}
    1 \cdot \omega = \sup \{ 1 \cdot n \mid n \in \omega \} = \omega = \omega \cdot 1,
  \end{equation*}
  observe that
  \begin{equation*}
    2 \cdot \omega = \sup \{ 2 \cdot n \mid n \in \omega \} = \omega \neq \omega + \omega = \omega \cdot 2.
  \end{equation*}
\end{eg}

\begin{propo}[Properties of Ordinal Addition \-and Ordinal Multiplication]
\label{propo:properties_of_ordinal_addition_and_ordinal_multiplication}
  Let $\alpha, \beta, \delta \in \Ord$.\marginnote{
  \begin{ex}
    Prove \cref{propo:properties_of_ordinal_addition_and_ordinal_multiplication}.
  \end{ex}}
  \begin{itemize}
    \item $\alpha < \beta \iff \delta + \alpha < \delta + \beta$;
    \item $\alpha = \beta \iff \delta + \alpha = \delta + \beta$;
    \item (\hlnotea{(associativity)}) $(\alpha + \beta) + \delta = \alpha + (\beta + \delta)$;
    \item if $\delta \neq 0$, then $\alpha < \beta \iff \delta \alpha < \delta \beta$;
    \item if $\delta \neq 0$, then $\alpha = \beta \iff \delta \alpha = \delta \beta$;
    \item $(\alpha\beta)\delta = \alpha(\beta\delta)$.
  \end{itemize}
\end{propo}

\subsubsection{Ordinal Exponentiation}
\label{ssub:Ordinal Exponentiation}

\begin{defn}[Ordinal Exponentiation]\index{Ordinal Exponentiation}
\label{defn:ordinal_exponentiation}
  Let $\beta \in \Ord$. For any $\alpha \in \Ord$, define
  \begin{equation*}
    \beta^\alpha
  \end{equation*}
  using Transfinite Recursion by
  \begin{itemize}
    \item $\beta^0 := 1$;
    \item if $\alpha$ is a successor ordinal, then $\beta^{S(\alpha)} := \beta^{\alpha} \cdot \beta$;
    \item if $\alpha > 0$ is a limit ordinal, then $\beta^\alpha := \sup \{ \beta^\gamma \mid \gamma < \alpha \}$.
  \end{itemize}
\end{defn}

% subsection ordinal_arithmetric (end)

In the next lecture, we shall study the following theorem:

\begin{thmnonum}[Strict Well-Ordered Sets are Isomorphic to a Unique Ordinal]
  Every strict well-ordering is isomorphic to an ordinal. Both the ordinal and the isomorphism are unique.
\end{thmnonum}

The definition of isomorphism is:

\begin{defn}[Isomorphism]\index{Isomorphism}
\label{defn:isomorphism}
  Let $E, F$ be sets and $R, S$ be relations defined on each set respectively so. We say that $(E, R)$ and $(F, S)$ are \hldefn{isomorphic}, which we denote by
  \begin{equation*}
    (E, R) \simeq (F, S),
  \end{equation*}
  if $\exists f : E \to F$, a bijection, such that
  \begin{equation*}
    e_1 R e_2 \iff f_1 S f_2.
  \end{equation*}
  Such an $f$ is called an \hlnoteb{isomorphism}.
\end{defn}

% section ordinals_continued_5 (end)

% chapter lecture_6_sep_25th (end)

\chapter{Lecture 7 Sep 27th}%
\label{chp:lecture_7_sep_27th}
% chapter lecture_7_sep_27th

\section{Ordinals (Continued 6)}%
\label{sec:ordinals_continued_6}
% section ordinals_continued_6

\subsection{Well-Orderings and Ordinals}%
\label{sub:well_orderings_and_ordinals}
% subsection well_orderings_and_ordinals

Before proving the theorem stated at the end of last lecture, we require the following 2 lemmas:

\begin{lemma}[Rigidity of Well-Orderings]
\index{Rigid}
\label{lemma:rigidity_of_well_orderings}
  Well-orderings are rigid, i.e. the only automorphism\sidenote{An \hldefn{automorphism} is an isomorphism from a set to itself.} is the identity.
\end{lemma}

\begin{proof}
  Suppose $(E, <)$ is a well-ordering, and $f : E \to E$ an automorphism. Let\sidenote{We look at the fellas that were `moved'.}
  \begin{equation*}
    D = \{ x \in E \mid f(x) \neq x \}.
  \end{equation*}
  Suppose for contradiction that $f$ is not the identity map, i.e. $D \neq \emptyset$. Then, since $D \subseteq E$, $D$ has a well-ordering, and so we can pick $\alpha \in D$ to be the least element.

  \noindent\underline{Case 1: $f(a) < a$.} Then $f(a) \notin D$ since $a$ is least. But then that would mean
  \begin{equation*}
    f( f(a) ) = f(a) \implies f(a) = a
  \end{equation*}
  since $f$ is a bijection. This contradicts the choice that $a \in D$.

  \noindent\underline{Case 2: $a < f(a)$.} Since $f$ is a bijection, its inverse exists, and so
  \begin{align*}
    f^{-1}(a) < a &\implies f^{-1}(a) \notin D \\
                  &\iff ff^{-1}(a) = f^{-1}(a) \iff a = f^{-1}(a)
  \end{align*}
  which contradicts the choice that $a \in D$, yet again. Thus there is no such element $a \in D$, forcing $D = \emptyset$, and so $f$ must be the identity map.\qed
\end{proof}

\begin{lemma}[Strict Well-Ordering $\not\simeq$ Any of Its Proper Initial Segment]
\label{lemma:strict_well_ordering_notsimeq_any_of_its_proper_initial_segment}
  A strict well-ordering is not isomorphic to any proper initial segment\sidenote{
  \begin{margindefn}[Initial Segment]\index{Initial Segment}
  \label{defn:initial_segment}
  For a strict well-order $(E, <)$, an \hlnoteb{initial segment} is a subset of the form
  \begin{equation*}
    \{ x \in E : x < b \}
  \end{equation*}
  for some $b \in E$.
  \end{margindefn}} of itself.
\end{lemma}

\begin{proof}
  Let $(E, <)$ be a strict well-ordering. $\forall b \in E$,
  \begin{equation*}
    I_b := \{ x \in E : x < b \}
  \end{equation*}
  has an induced well-order, in particular $(I_b, <)$.

  Suppose for contradiction that there exists an isomorphism $f : E \to I_b$. Let
  \begin{equation*}
    D = \{ x \in E \mid f(x) \neq x \}
  \end{equation*}
  $b \notin I_b$ and so $b \notin D$. \hlwarn{Proof is left incomplete until I verify the proof with the prof.}
\end{proof}

\begin{thm}[Strict Well-Ordered Sets are Isomorphic to a Unique Ordinal]
\label{thm:strict_well_ordered_sets_are_isomorphic_to_a_unique_ordinal}
  Every strict well-ordering is isomorphic to an ordinal. Both the ordinal and the isomorphism are unique.
\end{thm}

\begin{proof}
  \hlnotec{Uniqueness}

  Let $(E, R)$ be a strict well-ordering. Suppose that
  \begin{equation}\label{eq:unique_ordinal_for_swo_1}
    (E, R) \simeq (\alpha, \in) \text{ and } (E, R) \simeq (\beta, \in)
  \end{equation}
  where $\alpha, \beta \in \Ord$. Then, either
  \begin{equation*}
    \alpha < \beta, \quad \alpha = \beta \enspace \text{ or } \enspace \beta < \alpha.
  \end{equation*}
  Suppose $\alpha < \beta$ (this argument also works for $\beta < \alpha$, by simply swapping the inequality on $\alpha$ and $\beta$). Then $\alpha$ is a proper initial segment of $\beta$. From \cref{eq:unique_ordinal_for_swo_1}, we have that $(\alpha, \in) \simeq (\beta, \in)$ via $(E, R)$, but this contradicts \cref{lemma:strict_well_ordering_notsimeq_any_of_its_proper_initial_segment}. Thus we must have $\alpha = \beta$.

  \noindent\hlnotec{Existence}

  If $E = \emptyset$, then we can choose $0 \in \Ord$ to be the ordinal of which $E$ is isomorphic to. Suppose $E \neq \emptyset$. Denote an initial segment of $E$ by
  \begin{equation*}
    I_x := \{ y \in E \mid y < x \}.
  \end{equation*}
  Let
  \begin{equation*}
    A = \{ x \in E \mid \exists \beta \in \Ord \enspace (I_x, R) \simeq (\beta, \in) \}.
  \end{equation*}
  Notice that $(I_x, R) \simeq (\beta, \in)$ is a definite condition: the both $I_x$ and $\beta$ are sets, and so by Replacement, there is a graph, $\Gamma(f)$, from $I_x$ to $\beta$; injectivity of an element in $\Gamma(f)$ is expressible as
  \begin{equation*}
    \forall y_1 \forall y_2 \forall \beta_1 \forall \beta_2 ( y_1, y_2 \in I_x \land \beta_1, \beta_2 \in \Ord ( (y_1, \beta_1) = (y_2, \beta_2) \lrarrow y_1 = y_2 ) );
  \end{equation*}
  surjectivity is expressible as
  \begin{equation*}
    \forall \beta ( \beta \in \alpha \rarrow \exists y ( y \in I_x \rarrow (y, \beta) \in \Gamma(f) ) ).
  \end{equation*}
  Thus by Bounded Separation, $A$ is a set. Also, $A$ is nonempty, since the least element of $E$ will be isomorphic to $0$.

  By our uniqueness proof above, let $f$ be a function on $A$, where $f(x)$ is the unique ordinal that is isomorphic to $(I_x, R)$. By Replacement,
  \begin{equation*}
    \Img(f) = \{ f(x) \in \Ord \mid x \in A \} \subset \Ord
  \end{equation*}
  is a set. By \cref{propo:properties_of_ordinals_2} \cref{item:properties_of_ordinals_2_3}, $\exists \alpha \in \Ord \setminus \Img(f)$ that is $\in$-least. We want to show that $f : A \to \Img(f)$ is an isomorphism between $(E, R)$ and $(\alpha, \in)$.\sidenote{This is why we need to show that
  \begin{enumerate}
    \item $f$ is order-preserving, which is one of the requirements of an isomorphism (by our definition in \cref{defn:isomorphism});
    \item $f$ is injective;
    \item $\alpha = \Img(f)$;
    \item $A = E$,
  \end{enumerate}
  where the last 2 items will force $f$ to be surjective.}

  \underline{$f$ is order-preserving}: We shall also show here that $A$ is \hlnotea{downward closed}. $\forall x, y \in E$, we want to show that $xRy \land y \in A \implies x \in A$. By the assumption, we have that
  \begin{equation*}
    f(x) \overset{h}{\simeq} I_X \subsetneq I_y \overset{h}{\simeq} f(y)
  \end{equation*}
  Since $f(x), f(y) \in \Ord$, we have either
  \begin{equation*}
    f(x) < f(y), \quad f(x) = f(y), \enspace \text{ or } \enspace f(y) < f(x).
  \end{equation*}
  If $f(x) = f(y)$, then $I_x \simeq I_y$ which contradicts \cref{lemma:strict_well_ordering_notsimeq_any_of_its_proper_initial_segment}. If $f(y) < f(x)$, then
  \begin{equation*}
    h(I_x) \subseteq h(I_y) = f(y) < f(x) = h(I_x),
  \end{equation*}
  which is a contradiction. Thus we must have $f(x) < f(y)$, i.e. $f$ preserves order as claimed, and $f(x)$ is an initial segment of $f(y)$, i.e. $f(x) \in \Ord$, which implies that $x \in A$.

  \underline{$\alpha = \Img(f)$}: Suppose $\beta \in \alpha \implies \beta < \alpha \implies \beta \in \Img(f)$ by choice of $\alpha$ being the least. Therefore, $\alpha \in \Img(f)$.

  Now suppose that $\beta \in \Img(f)$. Then $\exists x \in A$ such that $(I_x, R) \simeq (\beta, \in)$. Again, we have 3 possibilities; either
  \begin{equation*}
    \alpha < \beta, \quad \alpha = \beta \enspace \text{ or } \enspace \beta < \alpha.
  \end{equation*}
  Now $\alpha < \beta \implies \alpha \in \beta \implies \alpha = h(I_y)$ where $yRx$ and $I_y \subset I_X$. Since $A$ is downward closed, $\alpha \in \Img(f)$, a contradiction. We also have that $\alpha \neq \beta$ since $\beta \in \Img(f)$ and $\alpha \in \Ord \setminus \Img(f)$, i.e. $\alpha \notin \Img(f)$. Thus $\beta < \alpha$, and so $\beta \in \alpha$. Therefore $\alpha = \Img(f)$.

  \underline{$f$ is injective}: Suppose that $f(x) = f(y)$. $xRy \implies I_x$ is an initial segment of $I_y$, which contradicts \cref{lemma:strict_well_ordering_notsimeq_any_of_its_proper_initial_segment}. The argument is similar for if $yRx$. Thus we must have $x = y$.

  \underline{$A = E$}: It suffices to show that $E \setminus A = \emptyset$. Suppose for contradiction that $E \setminus A \neq \emptyset$, i.e. $E = A$. Then $\exists x \in E \setminus A$, since $E \setminus A \subset E$ which has a strict well-ordering. Since $f$ preserves order, for any $y \in E$, $xRy \implies y \notin A$. On the other hand, $yRx \implies y \in A$. Thus $I_x = A$. However, since $f$ is an isomorphism between $(A, R)$ and $(\alpha, \in)$ (since we assume that $A = E$), we have that $I_x = A \simeq \alpha$, i.e. $x \in A$, which is a contradiction to the choice that $x \in E \setminus A$.

  This completes the proof.\qed
\end{proof}

% subsection well_orderings_and_ordinals (end)

% section ordinals_continued_6 (end)

\section{Cardinals}%
\label{sec:cardinals}
% section cardinals

While ordinals allow us to enumerate, we cannot use it to ``measure''. For example, $\omega \neq \omega + 1$, but they have the same size.

\begin{defn}[Equinumerous]\index{Equinumerous}
\label{defn:equinumerous}
  Two sets $A$ and $B$ have the same size, or \hlnoteb{equinumerous}, if there is a bijection from $A$ to $B$. We denote this relation by $\abs{A} = \abs{B}$.\sidenote{Note that we have yet to define $\abs{\cdot}$.}
\end{defn}

The following is a well-known theorem that makes proving equinumerosity a lot easier.

\begin{lemma}[Schr\"{o}der-Bernstein Theorem]
\index{Schr\"{o}der-Bernstein Theorem}
\label{lemma:schroder_bernstein_theorem}
  Given two sets $A$ and $B$, $\abs{A} = \abs{B}$ if and only if there exists injections in both directions, i.e. an injection from $A$ to $B$, and an injection from $B$ to $A$.
\end{lemma}

\begin{proof}
  The $(\implies)$ direction is easy, since a bijection exists. So it suffices to show the $(\impliedby)$ direction. We shall use $A \hookrightarrow B$ to say that there is an injection from $A$ to $B$.

  Suppose
  \begin{equation*}
    A \injection{} B \injection{g} A
  \end{equation*}
  Then $\exists f : A \to A$ an injective map, and we would have
  \begin{equation}\label{eq:sbthm_core}
    f(A) \subseteq g(B) \subseteq A.
  \end{equation}
  From here, it suffices to show that for an injective ap $f : X \to X$, if we have
  \begin{equation*}
    f(X) \subseteq Y \subseteq X,
  \end{equation*}
  then $\abs{Y} = \abs{X}$. From our observation in \cref{eq:sbthm_core}, we have
  \begin{equation*}
    X \supseteq Y \supseteq f(X) \supseteq f(Y) \supseteq f^2(X) \supseteq f^2(Y) \supseteq f^3(X) \supseteq \hdots
  \end{equation*}
  Let
  \begin{equation*}
    Z = X \setminus Y \discup f(X) \setminus f(Y) \discup f^2(X) \setminus f^2(Y) \discup \hdots
  \end{equation*}
  and
  \begin{equation*}
    W = X \setminus Z
  \end{equation*}
  Then
  \begin{equation*}
    X = Z \discup W
  \end{equation*}

  \noindent\underline{Claim:} For sets $A$ and $B$ such that $B \subseteq A$, we have that\sidenote{Forgive me if the proof of this claim is a little sloppy.}
  \begin{equation*}
    f(A \setminus B) = f(A) \setminus f(B).
  \end{equation*}
  Note that since $f$ is injective, $f : B \to f(B)$ is a bijective map. Suppose $\exists x \in A \setminus B$ such that $f(x) \in f(B)$. Since $f : B \to f(B)$ is bijective, $\exists b \in B$ such that $f(b) = f(x)$, but $f$ is injective. Thus the claim is true.

  Using a similar argument, it can be shown that $f(A \discup B) = f(A) \discup f(B)$.

  Observe that
  \begin{align*}
    f(Z) &= f(X \setminus Y) \discup f( f(X) \setminus f(Y) ) \discup f ( f^2(X) \setminus f^2(Y) ) \discup \hdots \\
         &= f(X) \setminus f(Y) \discup f^2(X) \setminus f^2(Y) \discup f^3(X) \setminus f^3(Y) \discup \hdots
  \end{align*}
  and note that
  \begin{equation*}
    f(Z) = Z \setminus ( X \setminus Y ).
  \end{equation*}
  Since $W = X \setminus Z$, we have $W \subseteq Y$. Since $Z \cap W = \emptyset$, we still have $f(Z) \cap W = \emptyset$. Also, note that $( X \setminus Y ) \cap W = \emptyset$. Thus, we have
  \begin{equation*}
    Y = X \setminus ( X \setminus Y ) = (Z \discup W) \setminus (X \setminus Y) = f(Z) \discup W
  \end{equation*}
  Let $g : X \to Y$ such that
  \begin{equation*}
    g(A) = \begin{cases}
      A    & A \subseteq W \\
      f(A) & A \subseteq Z
    \end{cases}
  \end{equation*}
  Clearly so, $g$ is bijective.\qed
\end{proof}

\begin{eg}
  We claimed that $\abs{\omega} = \abs{\omega + 1}$.

  We can simply use the identity map from $\omega \to \omega + 1$. For $\omega + 1 \to \omega$, consider the mapping
  \begin{equation*}
    f(\alpha) = \begin{cases}
      S(\alpha) & \alpha \in \omega \\
      0         & \alpha = \omega
    \end{cases}
  \end{equation*}
  This map is clearly injective by properties of elements of $\omega$.
\end{eg}

\begin{defn}[Cardinal]\index{Cardinal}
\label{defn:cardinal}
  A \hlnoteb{cardinal} is an ordinal $\alpha$ with the property that $\forall \beta < \alpha$, $\abs{\alpha} \neq \abs{\beta}$
\end{defn}

In the next lecture, we shall see that the collection of cardinals is a proper class, and is a subclass of the ordinals.

\begin{defn}[Finite \& Countable]\index{Finite}\index{Countable}
\label{defn:finite_n_countable}
  A set $A$ is \hlnoteb{finite} if $\abs{A} = \abs{n}$ for some $n \in \omega$. $A$ is \hlnoteb{countable} if $A$ is finite or $\abs{A} = \abs{\omega}$.
\end{defn}

% section cardinals (end)

% chapter lecture_7_sep_27th (end)

\chapter{Lecture 8 Oct 02nd}%
\label{chp:lecture_8_oct_02nd}
% chapter lecture_8_oct_02nd

\section{Cardinals (Continued)}%
\label{sec:cardinals_continued}
% section cardinals_continued

\begin{note}
  If $\kappa \in \Card$ and $\kappa$ is infinite, then $\kappa$ is a limit ordinal. In other words, successor ordinals are either finite or are not Cardinals. This is true since $\forall \alpha \in \Ord$ such that $\alpha \geq \omega$, clearly we have $\alpha \hookrightarrow S(\alpha)$, and we can define a function $f : S(\alpha) \to \alpha$ such that
  \begin{equation*}
    f(\beta) = \begin{cases}
      S(\beta) & \beta < \omega \\
      \beta    & \omega \leq \beta < \alpha \\
      0        & \beta = \alpha
    \end{cases},
  \end{equation*}
  which is injective, and so by \hyperref[lemma:schroder_bernstein_theorem]{Schr\"{o}der-Bernstein}, $\abs{S(\alpha)} = \abs{\alpha}$.
\end{note}

\begin{propo}[The Least Cardinality Not Equinumerous to Subsets of a Set]
\label{propo:the_least_cardinality_not_equinumerous_to_subsets_of_a_set}
  $\forall E \in \Set \; \exists \alpha \in \Ord \; \forall e \subseteq E$
  \begin{equation*}
    \abs{e} \neq \abs{\alpha}
  \end{equation*}
  and there exists a least such $h(E) \in \Ord$.
\end{propo}

\begin{note}
  Note that $h(E) \in \Card$.

  \begin{proof}
    Suppose not, i.e. $\exists \alpha \in Ord$ such that $\abs{h(E)} = \abs{\alpha}$ and $\alpha < h(E)$. Since $h(E)$ is the least, we must have $\abs{\alpha} = \abs{A}$ or some $A \subseteq E$. Then $\abs{h(E)} = \abs{A}$, which is a contradiction to the definition of $h(E)$. \qed
  \end{proof}

  In particular, we have that $h(\omega)$ is an uncountable cardinal.
\end{note}

Now to prove \cref{propo:the_least_cardinality_not_equinumerous_to_subsets_of_a_set}.

\begin{proof}
  It suffices to prove the existence of $h(E)$. Consider the class
  \begin{equation*}
    H = \class{ \alpha \in \Ord \mid \exists e \subseteq E \; \abs{e} = \abs{\alpha} }.
  \end{equation*}
  If we can show that $H$ is a set, then the least element not in $H$ shall be our $h(E)$. Consider
  \begin{equation*}
    W := \{ (A, R) \mid A \subseteq E, \, (A, R) \text{ is a strict well-ordering } \}
  \end{equation*}
  which is a set by Replacement, i.e.
  \begin{equation*}
    W \subseteq \mathcal{P}(E) \times \mathcal{P}( E \times E ).
  \end{equation*}
  Note that $W \neq \emptyset$, since $\emptyset \subseteq E$ and the empty relation would be a well-ordering of $\emptyset$. By \cref{thm:strict_well_ordered_sets_are_isomorphic_to_a_unique_ordinal}, $\exists f : W \to \Ord$ such that $f(A, R)$ is a unique ordinal. By Replacement, $\Img(f) \subseteq \Ord$ is a set.

  \underline{Claim: $\Img(f) = H$}: It is clear that $\Img(f) \subseteq H$, since all elements of $\Img(f)$ are isomorphic to some subset of $E$ by definition. Now let $\alpha \in H$. Then $\exists g : \alpha \to A$ a bijection, for some $A \subseteq E$. Then define $\prec$ on $A$ by
  \begin{equation*}
    a \prec b \iff g^{-1}(a) < g^{-1}(b).
  \end{equation*}
  Then $(\alpha, <) \overset{g}{\underset{\simeq}{\to}} (A, \prec)$. Therefore, $(A, \prec) \in W$ and $f(A, \prec) = (\alpha, <)$, i.e. $H \subseteq \Img(f)$. Thus $H = \Img(f)$ and so $H$ is a set as required.\qed
\end{proof}

\begin{remark}
  This revelation tells us that $\Card$ is a proper class.
\end{remark}

To use $\Card$ to measure all sets, we need every set to be equinumerous with a cardinal. In particular, every set would then have to be equinumerous to an ordinal. This would then require evrey set to have a strict well-ordering, which is something that we cannot prove with our axioms thus far.

\subsection{Axiom of Choice}%
\label{sub:axiom_of_choice}
% subsection axiom_of_choice

\begin{defn}[Choice Function]\index{Choice Function}
\label{defn:choice_function}
  Suppose $\mathcal{F}$ is a set. A \hlnoteb{choice function} on $\mathcal{F}$ is a function
  \begin{equation*}
    c : \mathcal{F} \to \cup \mathcal{F} \text{ such that } \forall F \in \mathcal{F} \enspace c(F) \in F.
  \end{equation*}
\end{defn}

\begin{note}
  If $\emptyset \in \mathcal{F}$, then $\mathcal{F}$ has no choice function, since nothing belongs in $\emptyset$.
\end{note}

\begin{axiom}[Axiom of Choice]
\index{Axiom of Choice}
\label{axiom:axiom_of_choice}
  Every $\mathcal{F} \in \Set$ such that $\emptyset \notin \mathcal{F}$ admits a choice function.\sidenote{This is, again, an existential axiom.}
\end{axiom}

\begin{note}
  Unlike the other axioms, while the Axiom of Choice asserts the existence of choice functions on sets, the choice function need not be unique. Recall that in other axioms, the sets of which we assert their existence are unique.
\end{note}

\begin{thm}[Axiom of Choice and Its Equivalents]\label{thm:axiom_of_choice_and_its_equivalents}
  TFAE
  \begin{enumerate}
    \item Axiom of Choice
    \item Well-ordering Principle: Every set admits a well-ordering.\label{item:well_ordering_principle}
    \item Zorn's Lemma: If $(E, R)$ is a strict poset with the property that \hlnotec{every totally ordered subset of $E$ has an upper bound}, i.e.
      \begin{equation*}
        \forall A \subset E ( \forall a, b \in A \; aRb \lor bRa \lor a = b ) \; \forall a \in A \exists e \in E ( aRe \lor a = e ).
      \end{equation*}
      Then $(E, R)$ has a maximal elements, i.e. $\exists z \in E$ such that $\forall x \in E$, $\neg z R x$.\label{item:zorn_s_lemma}
  \end{enumerate}
\end{thm}

\begin{proof}
  $(1) \implies (2)$: Let $A \in \Set$. If $A = \emptyset$, then there is nothing to do and the statement is vacuously true. So suppose $A \neq \emptyset$.  By the asusmption, fix a choice function $c$ on $\mathcal{F} := \mathcal{P}(A) \setminus \{ \emptyset \}$. Let $\theta \in \Ord \setminus A$. Define a definite operation $F : \Ord \to \Set$ such that
  \begin{equation*}
    F(\alpha) = \begin{cases}
      c(A \setminus \Img(F\restriction_\alpha)) & A \setminus \Img(F\restriction_\alpha) \neq \emptyset \\
      \theta                                    & \text{otherwise}
    \end{cases}
  \end{equation*}
  Note that $F$ exists by \hyperref[thm:transfinite_recursion_v1]{Transfinite Recursion}\sidenote{\hlwarn{I am not sure how.}}.

  \underline{Claim 1}: $F$ halts, i.e. $\exists \alpha \in \Ord$ such that $F(\alpha) = \theta$ and $\forall \beta \in \Ord$ such that $\alpha < \beta$, $F(\beta) = \theta$.

  Suppose not. Then $F$ must be injective and has codomain $\cup \mathcal{F} = \cup ( \mathcal{P}(A) \setminus \{ \emptyset \} ) = A$, i.e. we have that $F : \Ord \to A$ injective. Then by \cref{propo:the_least_cardinality_not_equinumerous_to_subsets_of_a_set}, there exists $h(A)$ that is the least ordinal that is not equinumerous with any subset of $A$. We may consider $F \restriction_{h(A)} : h(A) \to A$ since $h(A) \subset \Ord$. Now $\forall \alpha < \beta \in h(A)$, by our supposition, $F(\beta) \neq \theta$, and so $F(\beta) = c(A \setminus \Img( F \restriction_\beta )) \in ( A \setminus \Img(F \restriction_\beta) )$. Thus $F(\beta) \notin \Img(F \restriction_\beta)$. But since $\alpha < \beta$, it must be that $F(\alpha) \in \Img(F \restriction_\beta)$. Then $F(\alpha) \neq F(\beta)$. Consequently, since $\forall \beta \in h(A)$, we have that $F(\beta) \neq \theta$, and so we created an injection from $h(A)$ to $A$. This is impossible by the definition of $h(A)$. Thus it must be the case that $\exists \beta \in h(A)$ such that $F(\beta) = \theta$.

  Let $\alpha$ be the least such $\beta$. The previous paragraph showed that $F \restriction_\alpha$ is an injection from $\alpha$ to $A$. It remains to show that the map is surjective. Suppose $\Img(F\restriction_\alpha) \neq A$. Then $A \setminus \Img(F\restriction_\alpha) \neq \emptyset$. Then
  \begin{equation*}
    F(\alpha) = c(A \setminus \Img(F \restriction_\alpha)) \in A
  \end{equation*}
  which is a contradiction since $F(\alpha) = \theta$. So $A = \Img(F\restriction_\alpha)$ and so $F \restriction \alpha$ is surjective.

  Therefore $F \restriction_\alpha$ is a bijection from $\alpha$ to $A$, and so $A$ has an induced strict well-ordering from $\alpha$.

  \noindent$(3) \implies (1)$: Let $\mathcal{F}$ be a set such that $\emptyset \notin \mathcal{F}$. Let $\Lambda$ be the set of all partial choice functions on $\mathcal{F}$, identified with their graphs, i.e. $\forall f \in \Lambda$, $f : \mathcal{G} \to \cup \mathcal{G}$ such that $f(G) \in G$ for all $G \in \mathcal{G}$, and $\mathcal{G} \subseteq \mathcal{F}$. Note that $\Lambda$ is indeed a set since the graphs exist by Replacement, and $\Lambda$ is therefore a set from Bounded Separation. $\Lambda \neq \emptyset$, since the function $f(F) = x$ exists for $F \in \mathcal{F} \neq \emptyset$, and $F \neq \emptyset$.

  Now $(\Lambda, \subseteq)$ is a poset, where we order the functions by extensions. For every $\Theta$ that is a totally ordered subset of $\Lambda$, we have that the union, $\cup \Theta$ is the upper bound of $\Theta$. Thus the assumptions for \hyperref[item:zorn_s_lemma]{Zorn's Lemma} are satisfied, and so there exists a maximal function
  \begin{equation*}
    f : \mathcal{G} \to \cup \mathcal{G} \text{ in } \Lambda.
  \end{equation*}
  To prove that this $f$ is a choice function on $\mathcal{F}$, we want to prove that $f : \mathcal{F} \to \cup \mathcal{F}$, i.e.\ we need to show that $\Dom(f) = \mathcal{F}$. Suppose not, i.e.\ $\exists F \in \mathcal{F}$ such that $F \notin \Dom(f)$. Then since $F \neq \emptyset$, $\exists x \in F$, and so $f \cup \{ (F, x) \}$ is a larger partial choice function on $\mathcal{F}$, contradicting the maximality of $f$ in $\Lambda$. Thus $\Dom(f) = \mathcal{F}$ as claimed, and so $f$ is a choice function on $\mathcal{F}$, proving the Axiom of Choice.

  \noindent$(2) \implies (3)$: Suppose $(E, R)$ is a strict poset. By $(2)$, let $<$ be a strict well-ordering on $E$. Now by \cref{thm:strict_well_ordered_sets_are_isomorphic_to_a_unique_ordinal}, $\exists! \alpha \in \Ord$ such that $(E, R) \simeq (\alpha, \in)$ through a unique isomorphism. Therefore, we may assume that $E \in \Ord$. Suppose that $(E, R)$ satisfies the assumptions of Zorn's Lemma.
  
  Assume, to the contrary, that $(E, R)$ does not have an $R$-maximal element. From \cref{propo:the_least_cardinality_not_equinumerous_to_subsets_of_a_set}, $\exists h(E) \in Ord$ such that $\forall \beta < h(E)$, $\forall A \subseteq E$, $\abs{\beta} \neq \abs{A}$\sidenote{The strategy here is to use, once again, \cref{propo:the_least_cardinality_not_equinumerous_to_subsets_of_a_set} to arrive at a contradiction that is similar to when we were proving $(1) \implies (2)$.}. Recursively so, define $F : h(E) \to E$ by
  \begin{align*}
    F(0)         & = e \text{ for some } e \in E \\
    F(S(\beta)) & = \; < \text{-least element } \gamma \text{ of } E \text{ such that } F(\beta)R\gamma \enspace
  \end{align*}
  and for $\beta > 0$ a limit ordinal,
  \begin{equation*}
    F(\beta) = \begin{cases}
      < \text{-least } \gamma \text{ such that } F(\zeta) R \gamma \text{ for all } \zeta < \beta \text{ if such } \gamma \text{ exists } \\
      e \qquad \text{ otherwise}
    \end{cases}
  \end{equation*}
  Note that this function is well-defined, since $F(\beta)R\gamma$ properly distinguishes the ordinals, for there are no $R$-maximal element in $E$, and $<$ is a strict well-ordering on $E$.

  Now since $h(E) \in \Card$, it is a limit ordinal, to show that $F$ is injective, it suffices to show that $\forall \beta < h(E)$, $F \restriction_\beta$ is strictly order-preserving, i.e.\ $\forall x < y < \beta$, $F(x) R F(y)$. We shall prove this by Transfinite Induction.

  $\beta = 0$ is vacuously true. If $\beta > 0$ is a limit ordinal, then $\beta = \bigcup_{\gamma < \beta} \gamma$, and so the strict ordering is preserved as given by the induction hypothesis. For $\beta$ a successor ordinal, consider $F \restriction_{S(\beta)}$. $\forall x < y < S(\beta)$, if $y \neq \beta$, then we are done by the induction hypothesis. Suppose $y = \beta$. Since $\beta$ is a successor ordinal, $\exists \gamma \in \Ord$ such that $S(\gamma) = \beta$. Since $\gamma < S(\gamma)$ (by \cref{propo:properties_of_ordinals_2} \cref{item:properties_of_ordinals_2_1}), either $x = \gamma$ or $x < \gamma$. If $x < \gamma$, then our proof is complete by the induction hypothesis. If $x = \gamma$, then since $x = \gamma < S(\gamma) = \beta$, regardless if $\gamma$ is a limit ordinal or successor ordinal, we have that $F(\gamma) R F(\beta)$.

  Thus, by Transfinite Induction, we have that $F \restriction_\beta$ is strictly order-preserving for any $\beta < h(E)$, implying that $F : h(E) \hookrightarrow E$, hence contradicting the definition of $h(E)$. Thus, an $R$-maximal must exist.\qed\
\end{proof}

% subsection axiom_of_choice (end)

% section cardinals_continued (end)

% chapter lecture_8_oct_02nd (end)

\chapter{Lecture 9 Oct 04th}%
\label{chp:lecture_9_oct_04th}
% chapter lecture_9_oct_04th

\section{Cardinals (Continued 2)}%
\label{sec:cardinals_continued_2}
% section cardinals_continued_2

\subsection{Axiom of Choice (Continued)}%
\label{sub:axiom_of_choice_continued}
% subsection axiom_of_choice_continued

From hereon, unless stated otherwise, we shall assume AC.

\begin{propo}[Using Cardinals to Measure Sets]\label{propo:using_cardinals_to_measure_sets}
  Assume AC. Every set is equinumerous with a cardinal.
\end{propo}

\begin{proof}
  Let $A \in \Set$. By the Well-Ordering Principle, $A$ is well-orderable, i.e.\ there is a strict well-ordering on $A$. By \cref{thm:strict_well_ordered_sets_are_isomorphic_to_a_unique_ordinal}, $\exists! \alpha \in \Ord$ such that $(A, <) \simeq (\alpha, \in)$. Let
  \begin{equation*}
    S = \{ \beta \leq \alpha \mid \abs{\beta} = \abs{\alpha} \},
  \end{equation*}
  which is a set by Bounded Separation. Note that $S \neq \emptyset$ since $\alpha \in S$. Let $\beta$ be the least such ordinal in $S$. By this minimal choice, $\beta \in \Card$, $\abs{\beta} = \abs{\alpha} = \abs{A}$.\qed\
\end{proof}

And now our notation of $\abs{A} = \abs{B}$ makes sense provided the following definition.

\begin{defn}[Cardinality]\index{Cardinality}\label{defn:cardinality}
  Let $A \in \Set$. $\abs{A}$, in which we shall call the \hlnoteb{cardinality} of $A$, is the (unique) cardinal which is equinumerous with $A$.
\end{defn}

\begin{propo}[Lesser Cardinality]\label{propo:lesser_cardinality}
  $\forall A, B \in \Set \quad \abs{A} \leq \abs{B} \iff \exists f : A \hookrightarrow B$.
\end{propo}

\begin{proof}
  Let $\kappa = \abs{A}$ and $\lambda = \abs{B}$. If $\kappa \leq \lambda$, then
  \begin{equation*}
    A \overset{\text{bijection}}{\to} \kappa \overset{id}{\hookrightarrow} \lambda \overset{\text{bijection}}{\to} B
  \end{equation*}
  By composition of the 3 functions, $A \hookrightarrow B$.

  Conversely, suppose $\exists h : A \hookrightarrow B$. Suppose to the contrary that $\lambda < \kappa$. Then $\lambda \subseteq \kappa$. Then
  \begin{equation*}
    \kappa \overset{\text{bijection}}{\to} A \overset{h}{\hookrightarrow} B \overset{\text{bijection}}{\to} \lambda
  \end{equation*}
  and so there exists an injection from $\kappa \to \lambda$. By \hyperref[lemma:schroder_bernstein_theorem]{Schr\"{o}der-Bernstein}, we have $\abs{\kappa} = \abs{\lambda}$, which contradicts the fact that $\kappa \in \Card$. Thus $\kappa \leq \lambda$.\qed\
\end{proof}

\begin{crly}[Cardinalities are Always Comparable]\label{crly:cardinalities_are_always_comparable}
  $\forall A, B \in \Set \quad A \hookrightarrow B \lor B \hookrightarrow A$.
\end{crly}

\begin{proof}
  WLOG, suppose $\neg ( B \hookrightarrow A )$. Then $\neg( \abs{B} \leq \abs{A} )$, i.e.\ $\abs{A} < \abs{B}$, i.e.\ (not by \cref{propo:lesser_cardinality}), $\exists f : A \hookrightarrow B$.\qed
\end{proof}

\begin{propo}[Functions are ``Lossy Compressions'']\label{propo:functions_are_lossy_compressions}
  Suppose $f : A \to B$. Then $\abs{\Img(f)} \leq \abs{A}$.
\end{propo}

\begin{proof}
  Let
  \begin{equation*}
    \mathcal{F} = \{ f^{-1}(y) \mid y \in \Img(f) \}
  \end{equation*}
  be the set of \hlnotea{fibres}\sidenote{\begin{margindefn}[Fibres]\index{Fibres}\label{defn:fibres}
    Let $f : A \to B$. For $y \in \Img(f)$, the \hlnoteb{fibre} of $y$ is defined as
    \begin{equation*}
      f^{-1}(y) = \{ x \in A \mid f(x) = y \}.
    \end{equation*}
    The fibres are also commonly called the \hldefn{pullback}.
  \end{margindefn}} of $f$. Note that $\emptyset \notin \mathcal{F}$, as otherwise we would be saying that $\exists y \in \Img(f)$ that has no pre-image. Let $h : \Img(f) \to A$ by
  \begin{equation*}
    h(y) := c(f^{-1}(y)) \in A
  \end{equation*}
  where $c : \mathcal{F} \to \cup \mathcal{F}$ is a choice function that exists by AC. Clearly so, $h$ is injective, and so by \cref{propo:lesser_cardinality}, $\abs{\Img(f)} \leq \abs{A}$.\qed\
\end{proof}

\begin{propo}[Countable Union of Countable Sets is Countable]\label{propo:countable_union_of_countable_sets_is_countable}
  Let $A \in \Set$ be countable, and every $a \in A$ is also countable. Then $\cup A$ is countable.
\end{propo}

\begin{proof}
  \hlwarn{to be added}
\end{proof}

% subsection axiom_of_choice_continued (end)

\subsection{Hierarchy of Infinite Cardinals}%
\label{sub:hierarchy_of_infinite_cardinals}
% subsection hierarchy_of_infinite_cardinals

\begin{note}[Notation]
  Let $\kappa \in \Card$. Let $\kappa^+ := h(\kappa)$, which is the least ordinal not equinumerous with any subset of $\kappa$. We proved that $\forall E \in \Set$, $h(E) \in \Card$. Therefore, $\kappa^+ \in \Card$.
\end{note}

\begin{remark}
  $\kappa^+$ is the least cardinal that contains $\kappa$. This follows immediately from the definition of $h(\kappa)$.
\end{remark}

\newthought{And so} we observe that $\kappa \mapsto \kappa^+$ is a ``successor'' operation on cardinals.\sidenote{Note that $\kappa + 1$ is not necessarily $\kappa^+$.}

\begin{defn}[Cardinal Numbers]\index{Cardinal Numbers}\label{defn:cardinal_numbers}
  Using Transfinite Recursion, define the following ordinal-enumerated collection of cardinals
  \begin{itemize}
    \item $\aleph_0 = \omega$;
    \item $\forall \alpha \in \Ord$ that is a successor ordinal, $\aleph_{S(\alpha)} = \aleph_{\alpha + 1} = \aleph_\alpha^+$; and
    \item $\forall \alpha > 0$ that is a limit ordinal, $\aleph_\alpha := \sup \{ \aleph_\beta\mid \beta < \alpha \}$.
  \end{itemize}
  The $\aleph_\alpha$'s are called \hlnoteb{cardinal numbers}.
\end{defn}

\begin{lemma}[Cardinal Numbers are Cardinals]\label{lemma:cardinal_numbers_are_cardinals}
  If $\alpha \in \Ord$, then $\aleph_\alpha \in \Card$.
\end{lemma}

\begin{proof}
  We shall use Transfinite Induction. The result is clear for $\alpha = 0$, since $\aleph_0 = \omega$ and $\forall n \in \omega$, $\abs{n} \neq \abs{\omega}$. For successor ordinals $\alpha$, since $h(\alpha)$ is an ordinal, we have that $\aleph_\alpha^+ = h(\aleph_\alpha)$ is also a cardinal. Now for $\alpha > 0$ a limit ordinal, suppose that $\beta < \aleph_\alpha$. Since $\aleph_\alpha = \sup \{ \aleph_\gamma \mid \gamma < \alpha \}$, $\exists \gamma < \alpha$ such that $\beta < \aleph_\gamma$. Since $\aleph_\gamma$ is a cardinal by the Inductive Hypothesis, and $\beta < \aleph_\gamma < \aleph_\alpha$, we have that
  \begin{equation*}
    \abs{\beta} < \abs{\aleph_\gamma} \leq \abs{\aleph_\alpha}.
  \end{equation*}
  Thus $\aleph_\alpha$ is not equinumerous with any lesser ordinal, i.e.\ it is a cardinal.\qed\
\end{proof}

\begin{lemma}[Ordinals Index the Cardinal Numbers]\label{lemma:ordinals_index_the_cardinal_numbers}
  $\forall \alpha < \beta \in \Ord$, we have $\aleph_\alpha < \aleph_\beta$.
\end{lemma}

\begin{proof}
  We shall use Transfinite Induction on $\beta$. $\beta = 0$ is true vacuously so. For $\beta$ a successor ordinal, suppose  $\forall \alpha < \beta$, $\aleph_\alpha < \aleph_\beta$. Now $\aleph_{\beta + 1} = \aleph_\beta^+ = h(\aleph_\beta)$, which we have that $\aleph_\beta < h(\aleph_\beta)$ as proven before.

  Now suppose that $\beta > 0$ is a limit ordinal. Then $\aleph_\beta = \sup \{ \aleph_\alpha \mid \alpha < \beta \}$ and $\forall \gamma < \alpha < \beta$, $\aleph_\gamma < \aleph_\alpha$. Since $\beta$ is a limit ordinal, $\exists \zeta < \beta$ such that $\alpha < \zeta$. By the Induction Hypothesis, we have that $\aleph_\alpha < \aleph_\zeta$, and $\aleph_\zeta \leq \aleph_\beta$. Thus $\aleph_\zeta \subseteq \aleph_\beta$, and so $\aleph_\alpha < \aleph_\beta$.\qed\
\end{proof}

\begin{lemma}[Infinite Cardinals are Distant]\label{lemma:infinite_cardinals_are_distant}
  $\forall \alpha \in \Ord$, $\alpha \leq \aleph_\alpha$. The inequality is strict if $\alpha$ is a successor ordinal.
\end{lemma}

\begin{proof}
  Again, we shall use Transfinite Induction on $\alpha$. For $\alpha = 0$, we have $0 < \aleph_0 = \omega$, and so $\alpha = 0$ holds. For $\alpha$ a successor ordinal, suppose $\alpha \leq \aleph_\alpha$. Thus $\alpha + 1 \leq \aleph_\alpha + 1$. By definition of $h(\aleph_\alpha)$ and definition of cardinal numbers
  \begin{equation*}
    \alpha + 1 \leq \aleph_\alpha + 1 < \aleph_\alpha^+ = \aleph_{\alpha + 1}.
  \end{equation*}
  Thus the statement holds for $\alpha + 1$, and indeed, the inequality is strict for successor ordinals. For $\alpha > 0$ a limit ordinal, suppose that $\forall \beta < \alpha$, we have $\beta \leq \aleph_\beta$. By \cref{lemma:ordinals_index_the_cardinal_numbers}, we have
  \begin{equation*}
    \beta \leq \aleph_\beta < \aleph_\alpha.
  \end{equation*}
  Thus
  \begin{equation*}
    \alpha = \sup \{ \beta \mid \beta < \alpha \} < \aleph_\alpha
  \end{equation*}
  as required.\qed\
\end{proof}

\begin{propo}[All Infinite Cardinals are Indexed by the Ordinals]\label{propo:all_infinite_cardinals_are_indexed_by_the_ordinals}
  Every infinite cardinal is of the form $\aleph_\alpha$ for some $\alpha \in \Ord$.
\end{propo}

\begin{proof}
  Let $\kappa \in \Card$. By \cref{lemma:infinite_cardinals_are_distant}, we have $\kappa \leq \aleph_\kappa < \aleph_{\kappa + 1}$. And so we can show that $\forall \beta \in \Ord$, $\forall \kappa < \aleph_\beta$, $\exists \alpha < \beta$ such that $\kappa = \aleph_\alpha$. We shall use Transfinite Induction on $\beta$.
  
  Since there are no infinite cardinals strictly below $\omega$, $\beta = 0$ is trivially true. Suppose $\beta = \gamma + 1$ is a successor ordinal, where $\gamma \in \Ord$, and suppose $\kappa < \aleph_\beta$. Since $\gamma < \beta$, \cref{lemma:ordinals_index_the_cardinal_numbers} implies that $\aleph_\gamma < \aleph_\beta = \aleph_{\gamma + 1} = \aleph_\gamma^+$, and by definition, there are no cardinals between $\aleph_\gamma$ and $\aleph_\beta$. Thus $\kappa \leq \aleph_\gamma$. We thus have that either $\kappa = \aleph_\gamma$ or, by the Induction Hypothesis, $\exists \alpha < \gamma$ such that $\kappa = \aleph_\alpha$. Thus the statement holds for successor ordinals.

  Let $\beta > 0$ be a limit ordinal and $\kappa < \aleph_\beta = \sup \{ \aleph_\gamma \mid \gamma < \beta \}$. Then $\exists \gamma < \beta$ such that $\kappa < \aleph_\gamma$, and so by the Induction Hypothesis, $\exists \alpha < \gamma$ such that $\kappa = \aleph_\alpha$.\qed\
\end{proof}

Consequently, we have ourselves an \textit{ordinal-valued, order-preserving complete indexing} of the infinite cardinals. 

\begin{ex}
  For the inequality in \cref{lemma:infinite_cardinals_are_distant}, show that the equality can occur. In particular, consider the sequence of ordinals defined recursively by $\alpha_0 = 0$, and $\alpha_{n + 1} = \aleph_{\alpha_n}$, and verify that $\alpha = \aleph_\alpha$. In fact, this works if we start with any ordinal $\alpha_0$, not just $0$.
\end{ex}

% subsection hierarchy_of_infinite_cardinals (end)

% section cardinals_continued_2 (end)

% chapter lecture_9_oct_04th (end)

\chapter{Lecture 10 Oct 11th}%
\label{chp:lecture_10_oct_11th}
% chapter lecture_10_oct_11th

\section{Cardinals (Continued 3)}%
\label{sec:cardinals_continued_3}
% section cardinals_continued_3

\subsection{Cardinal Arithmetic}%
\label{sub:cardinal_arithmetic}
% subsection cardinal_arithmetic
\marginnote{Contents in this lecture should be extended upon. A lot of the contents need to be explored for it was presented tersely so without all the details of which we need.}

\subsubsection{Cardinal Summation}%
\label{ssub:cardinal_summation}
% subsubsection cardinal_summation

\begin{defn}[Cardinal Sum]\index{Cardinal Sum}\label{defn:cardinal_sum}
  $\forall \kappa_1, \kappa_2 \in \Card$. Let the \hlnoteb{cardinal sum}
  \begin{equation*}
    \kappa_1 + \kappa_2 := \abs{X_1 \cup X_2}
  \end{equation*}
  where $X_1, X_2 \in \Set$ such that
  \begin{equation*}
    \abs{X_1} = \kappa_1 \text{ and } \abs{X_2} = \kappa_2
  \end{equation*}
  and $X_1 \cap X_2 = \emptyset$.
\end{defn}

\begin{remark}
  This definition does not depend on the choice of $X_1$ and $X_2$, i.e. if we have another $X_1'$ and $X_2'$ such that\marginnote{
\begin{ex}
  Prove this remark.
\end{ex}}
  \begin{equation*}
    \abs{X_i'} = \abs{X_i} = \kappa_i \quad i = 1, 2
  \end{equation*}
  and $X_1' \cap X_2' = \emptyset$, then
  \begin{equation*}
    \abs{X_1' \cup X_2'} = \abs{X_1 \cup X_2}.
  \end{equation*}
  This shows that the cardinal summation is well-defined.
\end{remark}

\begin{note}
  If $X, Y \in \Set$ are arbitarily chosen, then
  \begin{equation*}
    \abs{X \cup Y} \leq \abs{X} + \abs{Y}
  \end{equation*}
\end{note}

\begin{warning}
  The cardinal summation is different from ordinal summation. For example, $\aleph_0 + \aleph_0$, where the $+$ represents the ordinal summation, is not a cardinal, as we have shown that $\abs{\omega + \omega} = \abs{\omega}$.

  Therefore, there is a need to explicitly mention the context of which $+$ is used.
\end{warning}

% subsubsection cardinal_summation (end)

\subsubsection{Cardinal Product}%
\label{ssub:cardinal_product}
% subsubsection cardinal_product

\begin{defn}[Cardinal Product]\index{Cardinal Product}\label{defn:cardinal_product}
  $\forall \kappa_1, \kappa_2 \in \Card$, the \hlnoteb{cardinal product}
  \begin{equation*}
    \kappa_1 \kappa_2 := \abs{X_1 \times X_2}
  \end{equation*}
  where $X_1, X_2 \in \Set$ with $\abs{X_i} = \kappa_i$, for $i = 1, 2$.
\end{defn}

\begin{ex}
  Prove that \cref{defn:cardinal_product} is well-defined.
\end{ex}

\begin{remark}
  We may as well choose
  \begin{equation*}
    X_1 = \kappa_1 \text{ and } X_2 = \kappa_2,
  \end{equation*}
  and so $\kappa_1 \kappa_2 = \abs{\kappa_1 \times \kappa_2}$.\sidenote{We cannot do so for cardinal sums, for $\kappa_1 \cap \kappa_2 \neq \emptyset$.}
\end{remark}

% subsubsection cardinal_product (end)

\begin{ex}
  Prove that the cardinal sum and product agrees with ordinal sum and products on the finite ordinals. This is the usual arithmetic on natural numbers.
\end{ex}

\begin{thm}[Dominance of the Larger Cardinal]\label{thm:dominance_of_the_larger_cardinal}
  Let $\kappa_1, \kappa_2 \in \Card$ not both finite. Then\marginnote{\begin{ex}
    Prove/read \cref{thm:dominance_of_the_larger_cardinal}.
  \end{ex}}
  \begin{enumerate}
    \item $\kappa_1 + \kappa_2 = \max \{ \kappa_1, \kappa_2 \}$; and
    \item if neither $\kappa_1$ or $\kappa_2$ is $0$, then $\kappa_1 \kappa_2 = \max \{ \kappa_1, \kappa_2 \}$.
  \end{enumerate}
\end{thm}

We can generalize the notions of cardinal sum and cardinal product. But first, a definition.

\begin{defn}[$I$-sequence]\index{$I$-sequence}\label{defn:i_sequence}
  Let $I \in \Set$. By an \hlnoteb{$I$-sequence} of sets, we mean a definite operation\sidenote{Note that $f: I \to \Img(f)$ is a function by the Replacement Axiom.}
  \begin{equation*}
    f : I \to \Set.
  \end{equation*}
  We write such sequences as
  \begin{equation*}
    ( x_i : i \in I )
  \end{equation*}
  where $x_i := f(i)$.
\end{defn}

\begin{defn}[Generalized Cardinal Sum]\index{Generalized Cardinal Sum}\label{defn:generalized_cardinal_sum}
  Suppose $(\kappa_i : i \in I)$ is a sequence of cardinals. We define the \hlnoteb{(generalized) cardinal sum} to be
  \begin{equation*}
    \Sigma_{i \in I} \kappa_i := \abs{ \bigcup_{i \in I} X_i }
  \end{equation*}
  where $(X_i : i \in I)$ is a sequence of \hlnotec{pairwise disjoint sets} with $\abs{X_i} = \kappa_i$.
\end{defn}

\begin{ex}
  Check that \cref{defn:generalized_cardinal_sum} is well-defined.
\end{ex}

\begin{note}
  Observe that
  \begin{equation*}
    \bigcup_{i \in I} X_i = \cup \{ X_i \mid i \in I \} = \cup \Img(f)
  \end{equation*}
  where $(X_i : i \in I)$ is a sequence of functions and $f : I \to Set$ is given by $f(i) = X_i$.
\end{note}

\begin{thm}[Properties of Cardinal Sum]\label{thm:properties_of_cardinal_sum}
  Let $I \in \Set$ be infinite, and $(\kappa_i : i \in I)$ a sequence of cardinals not all zero. Then\marginnote{\begin{ex}
    Prove/read \cref{thm:properties_of_cardinal_sum}
  \end{ex}}
  \begin{enumerate}
    \item $\sup_{i \in I} \kappa_i \in \Card$; and
    \item $\sum_{i \in I} \kappa_i = \max \{ \abs{I}, \sup_{i \in I} \kappa_i \}$.
  \end{enumerate}
\end{thm}

\begin{eg}
  We have that
  \begin{equation*}
    \sum_{0 < n \in \omega} n = \max \{ \abs{\omega \setminus \{0\}}, \sup_{0 < n \in \omega} n \} = \max \{ \aleph_0, \omega \} = \aleph_0.
  \end{equation*}
\end{eg}

\begin{defn}[Generalized Cardinal Product]\index{Generalized Cardinal Product}\label{defn:generalized_cardinal_product}
  Suppose $(\kappa_i : i \in I)$ is a sequence of cardinals. Then the \hlnoteb{cardinal product} is defined as
  \begin{equation*}
    \prod_{i \in I} \kappa_i := \abs{ X_1 \times X_2 \times \ldots } = \abs{ \underset{i \in I}{\times} X_i }
  \end{equation*}
  where $(X_i : i \in I)$ is a sequence of sets with $\abs{X_i} = \kappa_i$.
\end{defn}

\begin{ex}
  Check that \cref{defn:generalized_cardinal_product} is well-defined.
\end{ex}

\begin{note}
  Note that $\underset{i \in I}{\times} X_i$ is properly defined, as
  \begin{align*}
    \underset{i \in I}{\times} X_i &:= \{ (a_i : i \in I) \mid \forall i \in I, a_i \in X_i \} \\
                                    &= \left\{ f : I \to \bigcup_{i \in I} X_i, \, f(i) = X_i \right\}.
  \end{align*}
\end{note}

\begin{remark}
  Once again, we might as well take $X_i = \kappa_i$, just as we did when we defined pair products.
\end{remark}

\begin{eg}
  Suppose $\kappa_i = 2$ for all $i \in I$. Define a function such that
  \begin{equation*}
    \underset{i \in I}{\times} 2 \to \mathcal{P}(I)
  \end{equation*}
  given by
  \begin{equation*}
    (a_i : i \in I) \mapsto \{ i \in I : a_i = 1 \}.
  \end{equation*}
  Note that $2 = \{0, 1\}$, and so each $a_i = 0$ or $1$. Clearly so, this is a bijection\sidenote{This is the usual correspondence between subsets and characteristic functions.}. Consequently, we have
  \begin{equation*}
    \prod_{i \in I} 2 = \abs{ \underset{i \in I}{\times} 2 } = \abs{\mathcal{P}(I)}
  \end{equation*}
\end{eg}

We claim that
\begin{equation*}
  \abs{I} < \abs{\mathcal{P}(I)}.
\end{equation*}

% subsection cardinal_arithmetic (end)

\subsection{An Interlude on the Continuum Hypothesis}%
\label{sub:an_interlude_on_the_continuum_hypothesis}
% subsection an_interlude_on_the_continuum_hypothesis

\begin{thm}[Cantor's Diagonalization]\index{Cantor's Diagonalization}\label{thm:cantor_s_diagonalization}
  $\forall I \in \Set$, we have $\abs{I} < \abs{\mathcal{P}(I)}$.
\end{thm}

\begin{proof}
  Clearly we have that $I \hookrightarrow \mathcal{P}(I)$ through the map $i \mapsto \{i\}$. Thus $\abs{I} \leq \abs{\mathcal{P}(I)}$.

  Suppose to the contrary that there exists a bijection $f : I \to \mathcal{P}(I)$. Let\sidenote{This definition looks awfully familiar to Russell's Paradox.}
  \begin{equation*}
    \Delta = \{ i \in I : i \notin f(i) \} \subseteq I.
  \end{equation*}
  which is a set by Bounded Separation. Thus $\Delta \in \mathcal{P}(I)$. Then $\exists i_0 \in I$ such that $f(i_0) = \Delta$. Now if $i_0 \in \Delta$, then $i_0 \in f(i_0) = \Delta$, but this contradicts the membership condition which states that $i_0 \notin f(i_0)$. If $i_0 \notin \Delta$, then $i_0 \notin f(i_0) = \Delta$, but by the membership condition, it must be that $i_0 \in \Delta$, yet another contradiction. Thus such a bijection does not exist.\qed\
\end{proof}

This proves our earlier claim. In fact, so long as $\abs{I} > 2$,
\begin{equation*}
  \prod_{i \in I} 2 \neq \max \{ \abs{I}, \sup_{i \in I} 2 \} = \max \{ \abs{I}, 2 \},
\end{equation*}
since $RHS = \abs{I}$ while $LHS = \abs{\mathcal{P}(I)}$.

\begin{defn}[Cardinal Exponentiation]\index{Cardinal Exponentiation}\label{defn:cardinal_exponentiation}
  $\forall \kappa, \lambda \in \Card$, the \hlnoteb{cardinal exponentiation} is defined as
  \begin{equation*}
    \kappa^\lambda := \abs{ \Fun(\lambda, \kappa) },
  \end{equation*}
  where $\Fun(\lambda, \kappa)$ is the set of all functions from $\lambda$ to $\kappa$.
\end{defn}

\begin{ex}
  Prove that
  \begin{equation*}
    \prod_{i < \lambda} \kappa = \kappa^\lambda.
  \end{equation*}
\end{ex}

As a consequence, we have that $2^\lambda = \abs{\mathcal{P}(\lambda)}$. Then what is $\abs{\mathcal{P}(\aleph_0)}$?

\begin{axiom}[Continuum Hypothesis]\index{Continuum Hypothesis}\label{axiom:continuum_hypothesis}
  We have that
  \begin{equation*}
    \aleph_0 < 2^{\aleph_0} = \abs{\mathcal{P}(\aleph_0)},
  \end{equation*}
  i.e. $2^{\aleph_0} = \aleph_1$.
\end{axiom}

More generally,

\begin{axiom}[Generalized Continuum Hypothesis]\index{Generalized Continuum Hypothesis}\label{axiom:generalized_continuum_hypothesis}
  $\forall \kappa \in \Card$, we have
  \begin{equation*}
    2^\kappa = \kappa^+.
  \end{equation*}
\end{axiom}

In this course, we will not assume the Continuum Hypothesis (nor for the general case).

It has been proven by Paul Cohen (1963)\cite{cohen1963} that the Continuum Hypothesis is independent from ZFC.

% subsection an_interlude_on_the_continuum_hypothesis (end)

% section cardinals_continued_3 (end)

% chapter lecture_10_oct_11th (end)

\part{Model Theory}

\chapter{Lecture 11 Oct 16th}%
\label{chp:lecture_11_oct_16th}
% chapter lecture_11_oct_16th

The course will not cover for cofinality and coregularity, but it may be helpful to read through the material.

\newthought{We shall} now venture into \hlnotea{Model Theory}.

\section{First-order Logic}%
\label{sec:first_order_logic}
% section first_order_logic

\subsection{Structure}%
\label{sub:structure}
% subsection structure

\begin{defn}[Structure]\index{Structure}\label{defn:structure}
  A structure $\mathcal{M}$ consists of the following data:
  \begin{enumerate}
    \item A non-empty set $M$, called the \hldefn{universe} of $\mathcal{M}$;
    \item A sequence $(c_i: i \in I_{\con})$, where $I_{\con}$ is an $I$-sequence of constants, of distinguished elements of $M$, called the \hldefn{constants} of $\mathcal{M}$;
    \item A sequence of $M$-valued functions on powers of $M$,
      \begin{equation*}
        ( f_i : M^{n_i} \to M : i \in I_{\fun} ),
      \end{equation*}
      called the \hldefn{basic functions} of $\mathcal{M}$, and for each $i \in I_{\fun}$, $n_i < \omega$ is called the \hldefn{arity} of $f_i$;
    \item A sequence of subsets of powers of $M$,
      \begin{equation*}
        ( R_i \subset M^{m_i} : i \in I_{\rel} )
      \end{equation*}
      called the \hldefn{basic relations} of $\mathcal{M}$, and for each $i \in I_{\rel}$, $m_i < \omega$ is called the \hldefn{arity} of $R_i$.
  \end{enumerate}
\end{defn}

\begin{note}
  \begin{enumerate}
    \item Note that we defined $M \neq \emptyset$, as there is nothing too interesting to study from an empty universe.
    \item Also, note that we shall always use the corresponding capital alphabet as the universe of the structure (e.g. the universe of the structure $\mathcal{M}$ is $M$).
    \item While $M \neq \emptyset$, we allow $I_{\con}, I_{\fun}$ and $I_{\rel}$ to be $\emptyset$. In such a case, the structure that we have is about a \hlnotea{pure set}.
    \item If $f$ is a $0-$ary basic function, then we have
      \begin{equation*}
        f : M^0 \to M.
      \end{equation*}
      By convention, we have that $M^0 = 1 = \{ 0 \}$, and so we have $f(0) \in M$. Thus, such an $f$ is ``essentially'' a basic constant. Therefore, we shall usually assume that the arity of $f$ is strictly positive.
  \end{enumerate}
\end{note}

\begin{eg}
  Consider $\mathbb{R}$, the set of real numbers\sidenote{We did not construct $\mathbb{R}$ in our section on Set Theory. I may write up a full construction from $\mathbb{N}$ to $\mathbb{R}$ on my site.}. The following are some of the structures that we can study on $\mathbb{R}$:
  \begin{enumerate}
    \item as a pure set: $\mathcal{R} = \mathbb{R}$, with $I_{\con} = I_{\fun} = I_{\rel} = \emptyset$.
    \item as an ordered set: $\mathcal{R} = (\mathbb{R}, <)$, with the basic \hlnotec{binary} relation $<$, and no basic functions or constants.
    \item as an additive group: $\mathcal{R} = (\mathbb{R}, 0, +, -)$, with
      \begin{itemize}
        \item $0$ as a constant;
        \item $+$ as a basic \hlnotec{binary} function; and
        \item $-$ as a basic \hlnotec{unary} function.
      \end{itemize}

    \item as a ring: $\mathcal{R} = (\mathbb{R}, 0, 1, +, -, \cdot)$.
    \item as a $\mathbb{Q}$-vector space: $\mathcal{R} = (\mathbb{R}, 0, +, -, (\lambda_q)_{q \in \mathbb{Q}})$, where $\lambda_q : \mathbb{R} \to \mathbb{R}$ is scalar multiplication by $q$.
    \item as an ordered ring: $\mathcal{R} = ( \mathbb{R}, 0, 1, +, -, \cdot, < )$.
  \end{enumerate}
\end{eg}

\begin{defn}[Expansion \& Reduct]\index{Expansion}\index{Reduct}\label{defn:expansion_n_reduct}
  Suppose $\mathcal{M}$ and $\mathcal{N}$ are structures with the same universe. We say that $\mathcal{M}$ is an \hlnoteb{expansion} of $\mathcal{N}$ or that $\mathcal{N}$ is a \hlnoteb{reduct} of $\mathcal{M}$ if the basic constants, basic functions, and basic relations of $\mathcal{N}$ are contained in those of $\mathcal{M}$.
\end{defn}

\begin{eg}
  \begin{itemize}
    \item $(\mathbb{R}, 0, +, -)$ is a reduct of $(\mathbb{R}, 0, 1, +, -, \cdot)$;
    \item $(\mathbb{R}, 0, 1, +, -, \cdot, <)$ is an expansion of $(\mathbb{R}, 0, 1, +, -, \cdot)$.
  \end{itemize}
\end{eg}

% subsection structure (end)

\subsection{Language}%
\label{sub:language}
% subsection language

\begin{eg}
  Consider the following 2 structures
  \begin{gather*}
    \mathcal{R} = ( \mathbb{R}, 0, +, - ) \\
    \mathcal{Z} = \left( \faktor{\mathbb{Z}}{2 \mathbb{Z}}, 0, +, - \right)
  \end{gather*}
  Notice that the $0, +$ and $-$ do not not actually share the same meaning, since, e.g., $+$ in $\mathcal{R}$ is addition on the reals, while $+$ in $\mathcal{Z}$ is addition on the integers modulo $2$.
\end{eg}

\begin{defn}[Language]\index{Language}\label{defn:language}
  A \hlnoteb{language} $\mathcal{L}$ consists of $3$ sets of symbols:
  \begin{enumerate}
    \item a set $\mathcal{L}^{\con}$ of constant symbols;
    \item a set $\mathcal{L}^{\fun}$ of function symbols, where each function symbol comes with an arity, which is a natural number;
    \item a set $\mathcal{L}^{\rel}$ of relation symbols, where each relation symbol comes with an arity, which is a natural number.
  \end{enumerate}
\end{defn}

\begin{defn}[$\mathcal{L}$-structure]\index{$\mathcal{L}$-structure}\label{defn:l_structure}
  An \hlnoteb{$\mathcal{L}$-structure} is a structure $\mathcal{M}$ with bijections between
  \begin{align*}
    \mathcal{L}^{\con} \to I_{\con} \quad & \quad c \mapsto c^\mathcal{M} \\
    \mathcal{L}^{\fun} \to I_{\fun} \quad & \quad f \mapsto f^\mathcal{M} \\
    \mathcal{L}^{\rel} \to I_{\rel} \quad & \quad R \mapsto R^\mathcal{M}
  \end{align*}
  that preserves arity. We call
  \begin{equation*}
    c^{\mathcal{M}}, f^{\mathcal{M}}, \text{ and } R^{\mathcal{M}}
  \end{equation*}
  the \hldefn{Interpretation} of $c, f, R$ in $\mathcal{M}$.
\end{defn}

So in our previous example, we have that $\mathcal{R}$ and $\mathcal{Z}$ are both $\mathcal{L}$-structures, where $\mathcal{L} = \{ 0, +, - \}$ is the language with
\begin{itemize}
  \item one constant symbol, $0$;
  \item one binary function symbol, $+$;
  \item one unary function symbol, $-$.
\end{itemize}
This particular language is often referred to as the \hlnotea{language of additive groups}, for obvious\sidenote{Obvious, if you have studied \href{https://tex.japorized.ink/PMATH347S18/classnotes.pdf}{Group Theory}.} reasons.

\begin{remark}
  \begin{itemize}
    \item To be precise, we should really write
      \begin{equation*}
        \mathcal{R} = (\mathbb{R}, 0^\mathcal{R}, +^\mathcal{R}, -^\mathcal{R}),
      \end{equation*}
      so as to not obfuscate the symbols themselves and their interpretations in $\mathcal{R}$, but we shall forgive ourselves for this abuse of notation, for we shall leave this for the context to resolve this confusion.

    \item Every group is naturally an $\mathcal{L}$-structure, where $\mathcal{L} = \{ 0, +, - \}$. The converse is definitely false. E.g. the following $\mathcal{L}$-structure
      \begin{equation*}
        \mathcal{M} = ( \mathbb{Z}, 0^\mathcal{M}, +^\mathcal{M}, -^\mathcal{M} )
      \end{equation*}
      given by
      \begin{align*}
        0^\mathcal{M} &= 12 \\
        +^\mathcal{M} &: \mathbb{Z}^2 \to \mathbb{Z} \quad (a, b) \mapsto -2 \\
        -^\mathcal{M} &: \mathbb{Z} \to \mathbb{Z} \quad a \mapsto 2^2
      \end{align*}
      is not a group, since there are no identities nor inverses. But it is indeed an $\mathcal{L}$-structure.
  \end{itemize}
\end{remark}

\begin{eg}
  Let $F$ be a field, and let $\mathcal{L}$ be the language of $F$-vector spaces, i.e.
  \begin{align*}
    \mathcal{L}^{\con} &= \{ 0 \} \\
    \mathcal{L}^{\fun} &= \{ +, -, (\lambda_f)_{f \in F} \} \\
    \mathcal{L}^{\rel} &= \emptyset
  \end{align*}
  where $+$ is a binary function, $-$ a unary function, and $\lambda_f$ a unary function for each $f \in F$. Then any $F$-vector spaces $V$ is an $\mathcal{L}$-structure:
  \begin{itemize}[leftmargin=2.0cm,labelsep=0.5cm]
    \item[$0$] is interpreted as the zero vector
    \item[$+$] is interpreted as vector addition
    \item[$-$] is interpreted as the additive inverse of a vector
    \item[$\lambda_f$] is interpreted as scalar multiplication by $f$
  \end{itemize}
  The converse is, however, \hlimpo{not true}, and we shall study the reasons behind why this is not true later on.
\end{eg}

\begin{defn}[$\mathcal{L}$-Embedding]\index{$\mathcal{L}$-Embedding}\label{defn:l_embedding}
  Suppose $\mathcal{L}$ is a language, and $\mathcal{M}$ and $\mathcal{N}$ are $\mathcal{L}$-structures. An \hlnoteb{$\mathcal{L}$-embedding}, $j : \mathcal{M} \to \mathcal{N}$, is an injective function $j : M \to N$ such that
  \begin{enumerate}
    \item $\forall c \in \mathcal{L}^{\con} \quad j(c^\mathcal{M}) = c^\mathcal{N}$;
    \item $\forall f \in \mathcal{L}^{\fun}$ each with arity $n_f$, and $\forall a_1, \ldots, a_{n_f} \in M$, we have
      \begin{equation*}
        j\big( f^\mathcal{M}(a_1, \ldots, a_{n_f}) \big) = f^\mathcal{N} \big( j(a_1), \ldots, j(a_{n_f}) \big)
      \end{equation*}
    \item $\forall R \in \mathcal{L}^{\rel}$ each with arity $m_R$, and $\forall (a_1, \ldots, a_{m_R}) \in M^{m_R}$, we have
      \begin{equation*}
        (a_1, \ldots, a_{m_R}) \in R^\mathcal{M} \iff \big( j(a_1), \ldots, j(a_{m_R}) \big) \in R^\mathcal{N}.
      \end{equation*}
  \end{enumerate}
\end{defn}

\begin{defn}[Substructure]\index{Substructure}\label{defn:substructure}
  Continuing with the above assumptions and notation, if $M \subseteq N$, then we say that $\mathcal{M}$ is a \hlnoteb{substructure} on $\mathcal{N}$ if the identity map $id : M \to N$ is an $\mathcal{L}$-embedding. We denote this notion, without confusion, by $\mathcal{M} \subset \mathcal{N}$.

  We may also say that $\mathcal{N}$ is an \hldefn{extension} of $\mathcal{M}$.
\end{defn}

% subsection language (end)

% section first_order_logic (end)

% chapter lecture_11_oct_16th (end)

\chapter{Lecture 12 Oct 18th}%
\label{chp:lecture_12_oct_18th}
% chapter lecture_12_oct_18th

\section{First-order Logic (Continued)}%
\label{sec:first_order_logic_continued}
% section first_order_logic_continued

\subsection{Language (Continued)}%
\label{sub:language_continued}
% subsection language_continued

\begin{note}\label{note:interpretations_in_substructs}
  Notice that $\mathcal{L}$-structures $\mathcal{M} \subseteq \mathcal{N}$ iff
  \begin{itemize}
    \item $M \subseteq N$;
    \item $\forall c \in \mathcal{L}^{\con} \quad c^\mathcal{M} = c^\mathcal{N}$;
    \item $\forall f \in \mathcal{L}^{\fun}$, each with arity $n_f$, $f^\mathcal{M} = f^\mathcal{M} \restriction_{M^{n_f}}$;
    \item $\forall R \in \mathcal{L}^{\rel}$, each with arity $m_R$, $R^\mathcal{M} \subseteq R^\mathcal{N} \cap M^{m_R}$.
  \end{itemize}
\end{note}

\begin{ex}
  Suppose $\mathcal{N}$ is an $\mathcal{L}$-structure with $A \subset N$, where $A \neq \emptyset$. Show that $A$ is the universe of some (unique) substructure of $\mathcal{N}$ iff
  \begin{itemize}
    \item $\forall c \in \mathcal{L}^{\con} \quad c^\mathcal{N} \in A$;
    \item $\forall f \in \mathcal{L}^{\fun}$ that is $n$-ary, $f^\mathcal{N}(A^n) \subset A$.
  \end{itemize}
\end{ex}

\newthought{The choice} of the language determine what the substructures are.

\begin{eg}
  The following is table showing an example of a substructure in the given structures:

  \begin{tabular}{c | l}
    \multicolumn{1}{l|}{Structure}                          & Substructures \\
    \hline
    $\mathbb{R}$                                            & all non-empty subsets \\
    $(\mathbb{R}, 0, +)$                                    & all \href{https://en.wikipedia.org/wiki/Monoids}{submonoids} of $\mathbb{R}$ \footnotemark \\
    $(\mathbb{R}, 0, +, -)$                                 & all subgroups \\
    $(\mathbb{R}, 0, 1, +, -, \cdot)$                       & all subrings \\
    $(\mathbb{R}, <)$                                       & all non-empty subsets with induced order \\
    $(\mathbb{R}, 0, +, -, (\lambda_q)_{q \in \mathbb{Q}})$ & all $\mathbb{Q}$-subspaces
  \end{tabular}
  \footnotetext{Not that substructures of $(\mathbb{R}, 0, +)$ is not necessarily a group, and this is why we have always specified for $-$ for the language of additive groups. However, this is not necessary for the unique inverse in the language of fields, of which we shall clarify in a later section.}
\end{eg}

\begin{defn}[$\mathcal{L}$-isomorphism]\index{$\mathcal{L}$-isomorphism}\label{defn:l_isomorphism}
  An $\mathcal{L}$-isomorphism is a surjective $\mathcal{L}$-embedding.
\end{defn}

\begin{ex}
  Let $j : \mathcal{M} \to \mathcal{N}$ be an $\mathcal{L}$-embedding. Then $j$ induces an $\mathcal{L}$-isomorphism between $\mathcal{M}$ and a unique substructure $\mathcal{M}' \subseteq \mathcal{N}$.
\end{ex}

% subsection language_continued (end)

\subsection{Terms \& Formulas}%
\label{sub:terms_n_formulas}
% subsection terms_n_formulas

From hereon, we shall have the following countable infinite set,
\begin{equation*}
  \Var = \{ x_0, x_1, \ldots \},
\end{equation*}
which we shall call as our set of \hlnotea{variables}\sidenote{This is not to be confused with the \hlnotea{variance} in probability theory.}.

\begin{defn}[$\mathcal{L}$-terms]\index{$\mathcal{L}$-terms}\label{defn:l_terms}
  Let $\mathcal{L}$ be a language. The set of \hlnoteb{$\mathcal{L}$-terms} is the smallest set of strings of symbols from
  \begin{equation*}
    \mathcal{L} \cup \Var \cup \{ (, ) \} \cup \{ , \} \quad \footnotemark
  \end{equation*}
  \footnotetext{By $\{ (, ) \}$ and $\{ , \}$, we mean the punctuation symbols ``('', ``,'', ``)''.} satisfying
  \begin{itemize}
    \item every variable is an $\mathcal{L}$-term;
    \item every constant of $\mathcal{L}^{\con}$ is also an $\mathcal{L}$-term;
    \item \sidenote{This is a recursive formula.}if $t_1, t_2, \ldots, t_n$ are $\mathcal{L}$-terms and $f \in \mathcal{L}^{\fun}$ is $n$-ary, then $f(t_1, \ldots, t_n)$ is also an $\mathcal{L}$-term.
  \end{itemize}
  We often write a term $t$ as
  \begin{equation*}
    t = t(x_1, \ldots, x_n)
  \end{equation*}
  to mean that the variables in $t$ come from $\{ x_1, \ldots, x_n \}$.
\end{defn}

\begin{remark}
  All $x_1, \ldots, x_n$ need not always appear in $t$.
\end{remark}

We shall use the following example to show another abuse of notation that we shall gladly do in this course:

\begin{eg}
  Let $\mathcal{L} = \{ 0, 1, +, -, \times \}$. The following is an $\mathcal{L}$-term:
  \begin{equation*}
    \times ( + ( x_0, - (x_1) ), \times ( 1, x_2 ) ).
  \end{equation*}
  It is fairly straightforward to verify that the above is indeed an $\mathcal{L}$-term: using items $(1)$, $(2)$ and $(3)$ in our \hyperref[defn:l_terms]{definition above}, by the given order,
  \begin{enumerate}
    \item all $x_0, x_1, 1, x_2$ are $\mathcal{L}$-terms by $(1)$ and $(2)$;
    \item $-$ is a unary function, and so by $(3)$, we have that $-(x_1)$ is an $\mathcal{L}$-term;
    \item $+$ is a binary function, and by $(3)$, we have that $+ ( x_0, - (x_1) )$ is an $\mathcal{L}$-term;
    \item $\times$ is a binary function, and so by $(3)$, we have that $\times (1, x_2)$ is an $\mathcal{L}$-term;
    \item finally, by $(3)$, $\times( + ( x_0, - (x_1) ), \times ( 1, x_2 ) )$ is an $\mathcal{L}$-term.
  \end{enumerate}
  We shall ``informally'' write this as
  \begin{equation*}
    (x_0 + (- x_1))(1 x_2).
  \end{equation*}
  Note that we do not simply write $x_2 = 1 x_2$, since we may not have that $1$ acts as a ``multiplicative identity'' of sorts, as we would have in a ring.
\end{eg}

\begin{defn}[Interpretation]\index{Interpretation}\label{defn:interpretation}
  Suppose $\mathcal{M}$ is an $\mathcal{L}$-structure, and $t = t(x_1, \ldots, x_n)$ is an $\mathcal{L}$-term. We define the \hlnoteb{itnerpretation} of $t$ in $\mathcal{M}$ to be the function
  \begin{equation*}
    t^\mathcal{M} : M^n \to M,
  \end{equation*}
  defined recursively by
  \begin{itemize}
    \item If $t$ is $x_i$ for some $1 \leq i \leq n$, then
      \begin{equation*}
        t^\mathcal{M} : M^n \to M \quad (a_1, \ldots, a_n) \mapsto a_i.
      \end{equation*}
    \item If $t$ is $c$ for some $c \in \mathcal{L}^{\con}$, then
      \begin{equation*}
        t^\mathcal{M} : M^n \to M \quad (a_1, \ldots, a_n) \mapsto c^\mathcal{M}.
      \end{equation*}
    \item If $t$ is $f(t_1, \ldots, t_l)$, where $t_1, \ldots, t_l$ are $\mathcal{L}$-terms and $f$ is an $l$-ary function symbol, then $t^\mathcal{M} : M^n \to M$
      \begin{equation*}
        (a_1, \ldots, a_n) \mapsto f( t_1^\mathcal{M}(a_1, \ldots, a_n), t_2^\mathcal{M}(a_1, \ldots, a_n), \ldots, t_l^\mathcal{M}(a_1, \ldots, a_n) )
      \end{equation*}
  \end{itemize}
\end{defn}

\begin{note}
  Note that the function $t^\mathcal{M}$ depends not just on $t$ but on its presentation $t = t(x_1, \ldots, x_n)$.
\end{note}

\begin{eg}
  Let $\mathcal{L} = \{ 0, +, - \}$ and $\mathcal{R} = (\mathbb{R}, 0, +, -)$ an $\mathcal{L}$-structure. Let $t$ be the term $x \in \Var$. Then for $y \in \Var$, the following are some interpretations of $t$ in $\mathcal{R}$:
  \begin{enumerate}
    \item if $t = t(x)$, then we may interpret $t^\mathcal{R} : \mathbb{R} \to \mathbb{R}$ as the identity map, i.e. $r \mapsto r$;
    \item if $t=  t(x, y)$, then we may interpret $t^\mathcal{R} : \mathbb{R}^2 \to \mathbb{R}$ as taking the first component of the tuple, i.e. $(a, b) \mapsto a$;
    \item if $t = t(x, y)$, then we may interpret $t^\mathcal{R} : \mathbb{R}^2 \to \mathbb{R}$ as taking the second component of the tuple, i.e. $(a, b) \mapsto b$.
  \end{enumerate}
\end{eg}

\begin{ex}
  Prove the following: suppose $\mathcal{M}$ is an $\mathcal{L}$-structure, and $A \subseteq M$ such that $A \neq \emptyset$, then $A$ is the universe of the substructure iff $\forall t = t(x_1, \ldots, x_n)$ that are $\mathcal{L}$-terms, we have $t^\mathcal{M} (A^n) \subseteq A$.
\end{ex}

\begin{eg}
  Let $\mathcal{L} = \{ 0, 1, +, -, \times \}$ and $\mathcal{Z} = (\mathbb{Z}, =, 1, + , -, \times)$. Let $P \in \mathbb{Z} [x]$ where $P$ is $x^2 +2y - 1$. Then let $t_P = t_P(x, y)$ be the $\mathcal{L}$-term
  \begin{equation*}
    x^2 + (y + y) + (-1).
  \end{equation*}
  Then the interpretation of $t_P$ is
  \begin{equation*}
    t_P^\mathcal{Z} : \mathbb{Z}^2 \to \mathbb{Z} \quad (a, b) \mapsto a^2 + 2b + 1.
  \end{equation*}
\end{eg}

\begin{defn}[Atomic $\mathcal{L}$-Formulas]\index{Atomic $\mathcal{L}$-Formulas}\label{defn:atomic_l_formulas}
  An \hlnoteb{atomic $\mathcal{L}$-formula} is a (finite) string of symbols from
  \begin{equation*}
    \mathcal{L} \cup \Var \cup \{ (, ) \} \cup \{ , \} \cup \{ = \}
  \end{equation*}
  of the form:
  \begin{enumerate}
    \item $(t = s)$ where $t, s$ are $\mathcal{L}$-terms;
    \item $R(t_1, \ldots, t_l)$ where $t_1, \ldots, t_l$ are $\mathcal{L}$-terms, and $R \in \mathcal{L}^{\rel}$ with arity $l \in \omega$.
  \end{enumerate}
\end{defn}

\begin{defn}[$\mathcal{L}$-formulas]\index{$\mathcal{L}$-formulas}\label{defn:l_formulas}
  The set of \hlnotea{$\mathcal{L}$-formulas} is the smallest set of (finite) strings of symbols from
  \begin{equation*}
    \mathcal{L} \cup \Var \cup \{ (, ) \} \cup \{ , \} \cup \{ = \} \cup \{ \land, \lor, \neg, \exists, \forall \}
  \end{equation*}
  satisfying:
  \begin{enumerate}
    \item every atomic $\mathcal{L}$-formula is an $\mathcal{L}$-formula;
    \item if $\phi, \psi$ are $\mathcal{L}$-formulae, then so is $(\phi \land \psi)$, $\neg \phi$, and $(\phi \lor \psi)$;
    \item if $\phi$ is an $\mathcal{L}$-formula and $x \in \Var$, then $\exists x \phi$ and $\forall x \phi$ are $\mathcal{L}$-formulae.
  \end{enumerate}
\end{defn}

\begin{remark}
  \begin{enumerate}
    \item We shall use the following abbreviations:
      \begin{itemize}
        \item $\phi \rarrow \psi$ for $(\neg \phi \lor \psi)$;
        \item $\phi \lrarrow \psi$ for $(\phi \rarrow \psi) \land (\psi \rarrow \phi)$.
      \end{itemize}

    \item We shall gleefully make the following abuse of notation: for the language $\mathcal{L} = \{ \times, < \}$, we write $x < y^2$ instead of $< ( x, \times (y, y) )$.
  \end{enumerate}
\end{remark}

\begin{defn}[Bound and Free Variables]\index{Bound}\index{Free Variables}\label{defn:bound_and_free_variables}
  Suppose $\phi$ is an $\mathcal{L}$-formula. An occurrence of a variable $x$ in $\phi$ is called \hlnoteb{bound} if it appears inside the scope of a quantifer (i.e. in the existence of $\exists$ and $\forall$). Otherwise, they are called \hlnoteb{free}.
\end{defn}

\begin{eg}
  Let $\mathcal{L} = \{ \in \}$, and $x, y, z \in \Var$. The following is an $\mathcal{L}$-formula:
  \begin{equation*}
    (x \in y) \land \forall z \Big( ( z \in y ) \rarrow \big( ( z \in x ) \lor (z = x) \big) \Big)
  \end{equation*}
  We have that $x, y$ are the free variables while $z$ is bound.
\end{eg}

We write $\phi = \phi(x_1, \ldots, x_n)$ to mean that the free variables of $\phi$ come from $\{ x_1, \ldots, x_n \}$, but it is not necessary that all of the variables appear in the $\mathcal{L}$-formula.

For the sake of convenience, we hall assume that no variable can be simultaneously bound and free in an $\mathcal{L}$-formula.

% subsection terms_n_formulas (end)

% section first_order_logic_continued (end)

% chapter lecture_12_oct_18th (end)

\chapter{Lecture 13 Oct 23rd}%
\label{chp:lecture_13_oct_23rd}
% chapter lecture_13_oct_23rd

\section{First-order Logic (Continued 2)}%
\label{sec:first_order_logic_continued_2}
% section first_order_logic_continued_2

\subsection{Terms \& Formulas (Continued)}%
\label{sub:terms_n_formulas_continued}
% subsection terms_n_formulas_continued

\begin{eg}
  Let $\mathcal{L} = \{ 0, 1, +, -, \cdot \}$, and $x, y \in \Var$. We have that $x^2 = \cdot ( x, x )$ and $y$ are $\mathcal{L}$-terms. Given $\mathcal{R} = (\mathbb{R}, 0, 1, + , - , \cdot)$, we can interpret $x^2$, using $(x, y)$ as
  \begin{equation*}
    \left( x^2 \right)^{\mathcal{R}} : \mathbb{R} \to \mathbb{R} \text{ such that } (r, s) \mapsto r^2
  \end{equation*}
  and interpret $y$, using $(x, y)$ as
  \begin{equation*}
    y^\mathcal{R} : \mathbb{R} \to \mathbb{R} \text{ such that } (r, s) \mapsto s.
  \end{equation*}
  Now since $x^2$ and $y$ are $\mathcal{L}$-terms, we have that $x^2 = y$ is an \hlnotea{atomic formula}\sidenote{Atomic formulas are quantifier-free and so all the variables are free.}. In the $\mathcal{L}$-formula $\exists x (x^2 = y)$, the only free variable is $y$, which is not ``specified'' by a quantifier.\marginnote{
  \begin{remark}
    Notice that an $\mathcal{L}$-formula with free variable say something about the free variable. In our example of $\exists x (x^2 = y)$, the $\mathcal{L}$-formula ``says'' that $y$ has a square root.

    In the $\mathcal{L}$-formula $\forall y \; \exists x (x^2 = y)$, the meaning is different: it ``says'' that every element (in $\mathbb{R}$) has a square root. This is an important observation for the next definition.
  \end{remark}}

  On the other hand, for the $\mathcal{L}$-formula $\forall y ; \exists x (x^2 = y)$, both $x$ and $y$ are bound.
\end{eg}

\begin{defn}[$\mathcal{L}$-Sentences]\index{$\mathcal{L}$-Sentences}\label{defn:;_sentences}
  An $\mathcal{L}$-formula with no free variable is called an \hlnoteb{$\mathcal{L}$-sentence}.\marginnote{
\begin{mnote}
  An $\mathcal{L}$-sentence has a truth value.
\end{mnote}}
\end{defn}

\begin{defn}[Satisfaction / Realization]\index{Satisfaction}\index{Realization}\label{defn:satisfaction_realization}
  Given a language $\mathcal{L}$ and an $\mathcal{L}$-structure $\mathcal{M}$, for some $n < \omega$, let
  \begin{equation*}
    \phi = \phi(x_1, \ldots, x_n)
  \end{equation*}
  be an $\mathcal{L}$-formula\sidenote{If $n = 0$, then $\phi$ is simply an $\mathcal{L}$-sentence.}, $\bar{a} = (a_1, \ldots, a_n) \in M^n$ and $\bar{x} = (x_1, \ldots x_n)$.

  We define that $\bar{a}$ \hlnoteb{satisfies} (or \hlnoteb{realizes}) the formula $\phi(\bar{x})$ in $\mathcal{M}$ \sidenote{We may also say that $\phi(\bar{a})$ is true in $\mathcal{M}$.}, of which we denote by $\mathcal{M} \models \phi(\bar{a})$, through the following recursive definition, which we iterate on the complexity of the formula $\phi(\bar{x})$:\marginnote{Notice that in the recursive definition, we start with \hlnotea{atomic $\mathcal{L}$-formulas} first before going to the \hlnotea{$\mathcal{L}$-formulas}.}
  \begin{enumerate}
    % for basic atomic formulas
    \item If $\phi(\bar{x})$ is of the form $t_1 = t_2$, where
      \begin{equation*}
        t_1 = t_1(\bar{x}) \text{ and } t_2 = t_2(\bar{x})
      \end{equation*}
      are $\mathcal{L}$-terms, then
      \begin{equation*}
        \mathcal{M} \models \phi(\bar{a}) \text{ if } t_1^\mathcal{M} (\bar{a}) = t_2^\mathcal{M} (\bar{a}),
      \end{equation*}
      where $t_1^\mathcal{M}$ and $t_2^\mathcal{M}$ are realizations of $t_1$ and $t_2$ in $\mathcal{M}$, respectively.

    % for atomic formulas that uses a relation symbol
    \item If $\phi(\bar{x})$ is of the form
      \begin{equation*}
        R(t_1, \ldots, t_l), \text{ where } t_i = t_i(\bar{x}) \text{ are } \mathcal{L}\text{-terms}, \; R \in \mathcal{L}^{\rel}
      \end{equation*}
      with arity $l < \omega$, then we define $\mathcal{M} \models \phi(\bar{a})$ if
      \begin{equation*}
        \big(t_1^\mathcal{M} (\bar{a}), \, t_2^\mathcal{M} (\bar{a}), \, \ldots, \, t_l^\mathcal{M} (\bar{a}) \big) \in R^\mathcal{M} \subseteq \mathcal{M}^l
      \end{equation*}

    % for formulas with the logic operator and
    \item If $\phi(\bar{x})$ is of the form
      \begin{equation*}
        \phi_1(\bar{x}) \land \phi_2(\bar{x}),
      \end{equation*}
      where $\phi_1(\bar{x}), \phi_2(\bar{x})$ are known $\mathcal{L}$-formulas, then we define
      \begin{equation*}
        \mathcal{M} \models \phi(\bar{a}) \iff \mathcal{M} \models \phi_1(\bar{a}) \land \mathcal{M} \models \phi_2(\bar{a}).
      \end{equation*}

    % for formulas with the logic operator or
    \item If $\phi(\bar{x})$ is of the form
      \begin{equation*}
        \phi_1(\bar{x}) \lor \phi_2(\bar{x}),
      \end{equation*}
      where $\phi_1(\bar{x}), \phi_2(\bar{x})$ are known $\mathcal{L}$-formulas, then we define
      \begin{equation*}
        \mathcal{M} \models \phi(\bar{a}) \iff \mathcal{M} \models \phi_1(\bar{a}) \lor \mathcal{M} \models \phi_2(\bar{a}).
      \end{equation*}

    % for formulas with the negation operator
    \item If $\phi(\bar{x})$ is of the form
      \begin{equation*}
        \neg \psi(\bar{x}),
      \end{equation*}
      where $\psi(\bar{x})$ is a known $\mathcal{L}$-formula, then we define\sidenote{Here, we conveniently assumed the \href{https://en.wikipedia.org/wiki/Law_of_excluded_middle}{Law of Excluded Middle}.}
      \begin{equation*}
        \mathcal{M} \models \phi(\bar{a}) \iff \text{ it is not the case that } \mathcal{M} \models \phi(\bar{a}),
      \end{equation*}
      of which the latter shall be denoted as $\mathcal{M} \not\models \psi(\bar{a})$.

    % for formulas with the existential quantifier
    \item If $\phi(\bar{x})$ is of the form
      \begin{equation*}
        \exists y \psi(\bar{x}, y),
      \end{equation*}
      where $\psi(\bar{x}, y)$ is an $\mathcal{L}$-formula, and $y$ a (single) variable, then we define
      \begin{equation*}
        \mathcal{M} \models \phi(\bar{a}) \iff \text{ there exists } b \in M \text{ such that } \mathcal{M} \models \psi(\bar{a}, b).
      \end{equation*}

    % for formulas with the universal quantifier
    \item If $\phi(\bar{x})$ is of the form
      \begin{equation*}
        \forall y \psi(\bar{x}, y),
      \end{equation*}
      where $\psi(\bar{x}, y)$ is an $\mathcal{L}$-formula, and $y$ a (single) variable, then we define
      \begin{equation*}
        \mathcal{M} \models \phi(\bar{a}) \iff \text{ for every} b \in M \text{ such that } \mathcal{M} \models \psi(\bar{a}, b).
      \end{equation*}
  \end{enumerate}
\end{defn}

\begin{note}
  The \hlnotea{set of all realizations} of an $\mathcal{L}$-formula $\phi$ in the $\mathcal{L}$-structure $\mathcal{M}$ is denoted as
  \begin{equation*}
    \phi^\mathcal{M} := \{ \bar{a} \in M^n : \mathcal{M} \models \phi(\bar{a}) \}.
  \end{equation*}
  We may also call this set the \hlnotea{subset of $M^n$ defined by $\phi$}. 
\end{note}

Finally, we can define \hlnotea{definability}.

\begin{defn}[$\mathcal{L}$-Definable]\index{$\mathcal{L}$-Definable}\label{defn:l_definable}
  A subset $S \subset M^n$ is said to be \hlnoteb{$\mathcal{L}$-definable} if $S = \phi^\mathcal{M}$ for some $\mathcal{L}$-formula $\phi = \phi(\bar{x}) = \phi(x_1, \ldots, x_n)$.
\end{defn}

\begin{remark}
  If $n = 0$, we have that $\phi$ is an $\mathcal{L}$-sentence, and since $M^0 = 1 = \{ 0 \}$, there are two possible scenarios and that is
  \begin{equation*}
    \text{ either } \mathcal{M} \models \phi \text{ or } \mathcal{M} \models \neg \phi.
  \end{equation*}
  Notice that $\phi^\mathcal{M}$ is either $1 = \{ 0 \}$ or $0 = \emptyset$.
\end{remark}

\begin{eg}
  Let $\mathcal{L} = \{ 0, 1, +, -, \times \}$, $\psi(x, y)$ be the atomic $\mathcal{L}$-formula $x^2 = y$, and $\phi(y)$ be the $\mathcal{L}$-formula $\exists x (x^2 = y)$. It is clear that we can also write $\phi(y) = \exists x \psi(x, y)$.

  Let $\mathcal{R} = (\mathbb{R}, 0, 1, +, -, \times)$. We have that
  \begin{equation*}
    \mathcal{R} \models \neg \phi(-1) \text{ and } \mathcal{R} \models \phi(2).
  \end{equation*}
  In fact, $\phi^\mathcal{R} = \mathbb{R}_{\geq 0} \subseteq \mathbb{R}$.

  On the other hand, for the $\mathcal{L}$-structure $\mathcal{Q} = (\mathbb{Q}, 0, 1, +, -, \times)$, we have that
  \begin{equation*}
    \mathcal{Q} \models \neg \phi(-1) \text{ and } \mathcal{Q} \models \neg \phi(2).
  \end{equation*}
  It is worth noting that
  \begin{equation*}
    \phi^\mathcal{Q} = \left\{ \frac{n^2}{m^2} : n, m < \omega, \, m \neq 0 \right\} \subseteq \mathbb{Q}.
  \end{equation*}

  For the $\mathcal{L}$-structure $\mathcal{C} = (\mathbb{C}, 0, 1, +, -, \times)$, we have that $\phi^\mathcal{C} = \mathbb{C}$, or we may also write that $\mathcal{C} \models \forall y \; \phi (y)$ \sidenote{We may further simplify our notations by letting
  \begin{equation*}
    \sigma = \forall y \exists x (x^2 = y),
  \end{equation*}
  which we can then simply write $\mathcal{C} \models \sigma$.}.
\end{eg}

\begin{eg}
  Consider the same language as in the last example, and let $\phi(y, z) = \exists x (x^2 = y - z)$. In the $\mathcal{L}$-structure $\mathcal{R} = (\mathbb{R}, 0, 1, +, -, \times)$, it is clear that
  \begin{equation*}
    \phi^\mathcal{R} = \left\{ (a, b) \in \mathbb{R}^2 : b \leq a \right\} \subseteq \mathbb{R}^2,
  \end{equation*}
  and we observe that the set of solutions is also the binary relation $\geq$, i.e. $\geq$ is definable in the $\mathcal{L}$-structure $\mathcal{R}$.

  Similarly so, we can show that $\leq$ is $\mathcal{L}$-definable in $\mathcal{R}$. \sidenote{In other words, this example shows to us that we can define $\leq$ and $\geq$ using just the symbols $=$ and $-$.}
\end{eg}

\begin{propo}[Structure Traversal with respect to Quantifiers]\label{propo:structure_traversal_with_respect_to_quantifiers}
  Let $\mathcal{M} \subseteq \mathcal{N}$ be $\mathcal{L}$-structures, where $\mathcal{M}$ is the $\mathcal{L}$-substructure, and variables $\bar{x} = (x_1, \ldots, x_n)$. Let $\phi(\bar{x})$ be an $\mathcal{L}$-formula, and $\bar{a} = (a_1, \ldots, a_n) \in M^n$.
  Then
  \begin{enumerate}
    \item if $\phi$ is a \hlnotea{quantifier-free} formula, then
      \begin{equation*}
        \mathcal{M} \models \phi(\bar{a}) \iff \mathcal{N} \models \phi(\bar{a}).
      \end{equation*}
    \item if $\phi$ is \hlnotea{universal}, i.e. $\phi(\bar{x})$ is of the form
      \begin{equation*}
        \forall y_1 \forall y_2 \hdots \forall y_m \psi(\bar{x}, y_1, y_2, \ldots, y_m),
      \end{equation*}
      where $\psi$ is quantifier-free, then
      \begin{equation*}
        \mathcal{M} \models \phi(\bar{a}) \impliedby \mathcal{N} \models \phi(\bar{a}).
      \end{equation*}
    \item if $\phi$ is \hlnotea{existential}, i.e. $\phi(\bar{x})$ is of the form
      \begin{equation*}
        \exists y-1 \exists y_2 \hdots \exists y_m \psi(\bar{x}, y_1, y-2, \ldots, y_m),
      \end{equation*}
      where $\psi$ is quantifer-free, then
      \begin{equation*}
        \mathcal{M} \models \phi(\bar{a}) \implies \mathcal{N} \models \phi(\bar{a}).
      \end{equation*}
  \end{enumerate}
\end{propo}

\begin{proof}
  \marginnote{I shall directly quote from the course notes from Professor \citeauthor{rahim}:

  \begin{quotebox}{be-magenta}{light}
    This proposition has a very typical proof. In order to prove something about all
formulas one usually has to begin by proving something about terms and then proceeding by
induction on the complexity of the formula. The result about terms is itself usually proved
by induction on the complexity of the term.
  \end{quotebox}}
  \begin{enumerate}
    \item \hlbnoted{Claim}: We shall first show that if $t(\bar{x})$ is an $\mathcal{L}$-term, then $t^\mathcal{M} = t^\mathcal{N} \restriction_{M^n}$. We shall prove this claim by using induction on the complexity of $t$.
      \begin{itemize}
        \item If $t$ is a variable $x_i$, then we have
          \begin{gather}
            t^\mathcal{M} : M^n \to M \text{ given by } (a_1, \ldots, a_n) \mapsto a_i \label{eq:strcttrav_qf_1}\\
            t^\mathcal{N} : N^n \to N \text{ given by } (b_1, \ldots, b_n) \mapsto b_i \nonumber
          \end{gather}
          Since $M^n \subseteq N^n$, we have that the restriction of $t^\mathcal{N}$ to $M^n$ will give us \eqref{eq:strcttrav_qf_1}.
        \item If $t$ is a constant symbol, i.e. some $c \in \mathcal{L}^{\con}$, then we simply have $c^\mathcal{M} = c^\mathcal{N}$, for $M \subseteq N$.
        \item If $t$ is $f(t_1, \ldots t_l)$, where $f \in \mathcal{L}^{\fun}$, where $t_1, \ldots, t_l$ are $\mathcal{L}$-terms, then
          \begin{align*}
            t^\mathcal{M}(\bar{a}) &= f^\mathcal{M} \big( t_1^\mathcal{M}(\bar{a}), \ldots, t_l^\mathcal{M}(\bar{a}) \big) \\
                                   &= f^\mathcal{M} \big( t_1^\mathcal{N}(\bar{a}), \ldots, t_l^\mathcal{N}(\bar{a}) \big) \quad \because \text{ IH } \\
                                   &= f^\mathcal{N} \big( t_1^\mathcal{N}(\bar{a}), \ldots, t_l^\mathcal{N}(\bar{a}) \big) \quad \because \text{ note on page } \pageref{note:interpretations_in_substructs} \\
                                   &= t^\mathcal{N} (\bar{a}).
          \end{align*}
          Therefore $t^\mathcal{N} \restriction_{M^n} = t^\mathcal{M}$ as claimed $\dashv$.

          Now to prove our original statement. We shall prove the statement by performing induction on $\phi$.
          \begin{itemize}
            \item \hlbnotea{$\phi(\bar{x})$ is $t_1 = t_2$}: We have
              \begin{align*}
                \mathcal{M} \models \phi(\bar{a}) &\overset{\text{defn}}{\iff} t_1^\mathcal{M} (\bar{a}) = t_2^\mathcal{M} (\bar{a}) \\
                                                  &\overset{\text{claim}}{\iff} t_1^\mathcal{N} (\bar{a}) = t_2^\mathcal{N} (\bar{a}) \\
                                                  &\overset{\text{defn}}{\iff} \mathcal{N} \models \phi(\bar{a}).
              \end{align*}

            \item \hlbnotea{$\phi(\bar{x})$ is $R(t_1, \ldots t_l)$}: Observe that
              \begin{align*}
                \mathcal{M} \models \phi(\bar{a}) &\overset{\text{defn}}{\iff} \big( t_1^\mathcal{M} (\bar{a}), \ldots, t_l^\mathcal{M} (\bar{a}) \big) \in R^\mathcal{M} \\
                                                  &\overset{\text{claim}}{\iff} \big( t_1^\mathcal{N} (\bar{a}), \ldots, t_l^\mathcal{N} (\bar{a}) \big) \in R^\mathcal{M} \\
                                                  &\iff \big( t_1^\mathcal{N} (\bar{a}), \ldots, t_l^\mathcal{N} (\bar{a}) \big) \in R^\mathcal{N} \enspace \because R^\mathcal{M} = R^\mathcal{N} \cap M^l \\
                                                  &\overset{\text{defn}}{\iff} \mathcal{N} \models \phi(\bar{a}).
              \end{align*}
            From this part onwards, suppose $\phi_1, \phi_2$ are quantifier-free $\mathcal{L}$-formulas.

            \item \hlbnotea{$\phi(\bar{x}) = \phi_1(\bar{x}) \lor \phi_2(\bar{x})$}: We have
              \begin{align*}
                \mathcal{M} \models \phi(\bar{a}) &\iff \mathcal{M} \models \phi(\bar{a}) \text{ or } \mathcal{M} \models \phi_2(\bar{a}) \\
                                                  &\iff \mathcal{N} \models \phi(\bar{a}) \text{ or } \mathcal{N} \models \phi_2(\bar{a}) \enspace \because \text{ IH } \\
                                                  &\iff \mathcal{N} \models \phi(\bar{a}).
              \end{align*}

            \item \hlbnotea{$\phi(\bar{x}) = \phi_1(\bar{x}) \land \phi_2(\bar{x})$}: We have
              \begin{align*}
                \mathcal{M} \models \phi(\bar{a}) &\iff \mathcal{M} \models \phi_1(\bar{a}) \text{ and } \mathcal{M} \models \phi_2(\bar{a}) \\
                                                  &\iff \mathcal{N} \models \phi_1(\bar{a}) \text{ and } \mathcal{N} \models \phi_2(\bar{a}) \enspace \because \text{ IH } \\
                                                  &\iff \mathcal{N} \models \phi(\bar{a}).
              \end{align*}

            \item \hlbnotea{$\phi(\bar{x}) = \neg \phi_1(\bar{x})$}: We have
              \begin{align*}
                \mathcal{M} \models \phi(\bar{a}) &\iff \mathcal{M} \not\models \phi_1(\bar{a}) \\
                                                  &\iff \mathcal{N} \not\models \phi_1(\bar{a}) \quad \because \text{ IH } \\
                                                  &\iff \mathcal{N} \models \phi(\bar{a}).
              \end{align*}
          \end{itemize}
          There is no need to check for cases where $\phi$ is universal or existential, since our assumption is that $\phi$ is quantifier-free. This completes the proof.
      \end{itemize}
  \end{enumerate}\qed\
\end{proof}

\begin{ex}
  Prove (2) and (3) of \cref{propo:structure_traversal_with_respect_to_quantifiers}.
\end{ex}

% subsection terms_n_formulas_continued (end)

% section first_order_logic_continued_2 (end)

% chapter lecture_13_oct_23rd (end)

\chapter{Lecture 14 Oct 25th}%
\label{chp:lecture_14_oct_25th}
% chapter lecture_14_oct_25th

\section{First-order Logic (Continued 3)}%
\label{sec:first_order_logic_continued_3}
% section first_order_logic_continued_3

\subsection{Terms \& Formulas (Continued 2)}%
\label{sub:terms_n_formulas_continued_2}
% subsection terms_n_formulas_continued_2

\begin{eg}
  Let $\mathcal{L}$ be the language of rings\sidenote{From hereon, for the sake of simplicity, I shall gleefully use such declarations for a language wherever it is convenient, and when the context is clear that I am merely using the common symbols that are used in the said theory.}. We have that in $\mathcal{Z}$, where
  \begin{equation*}
    (\mathbb{Z}, 0, 1, +, -, \times) = \mathcal{Z} \subseteq \mathcal{Q} = (\mathbb{Q}, 0, 1, +, -, \times),
  \end{equation*}
  for the $\mathcal{L}$-formula $\phi(x) = \exists y (x = 2y)$, we observe that
  \begin{equation*}
    \mathcal{Z} \models \neg \phi(1) \text{ but } \mathcal{Q} \models \phi(1).
  \end{equation*}
\end{eg}

This shows to us that existential formulas that 
\begin{itemize}
  \item are satisfied in an extension may not be satisfied in the substructure;
  \item is not satisfied in the substructure may be satisfied in the extension.
\end{itemize}

% subsection terms_n_formulas_continued_2 (end)

\subsection{Elementary Embeddings}%
\label{sub:elementary_embeddings}
% subsection elementary_embeddings

Considering \cref{propo:structure_traversal_with_respect_to_quantifiers}, it is interesting for us to consider substructures that satisfies all the formulas of its extension, including formulas that are either universal or existential.

\begin{defn}[Elementary Embeddings]\index{Elementary Embeddings}\label{defn:elementary_embeddings}
  Suppose $\mathcal{M} \subseteq \mathcal{N}$ are $\mathcal{L}$-structures, and $\mathcal{M}$ is a substructure of $\mathcal{N}$. An $\mathcal{L}$-embedding $j : \mathcal{M} \to \mathcal{N}$ is an \hlnoteb{elementary embedding} if for any $\mathcal{L}$-formula $\phi$ and $\bar{a} \in M^n$,
  \begin{equation*}
    \mathcal{M} \models \phi(\bar{a}) \iff \mathcal{N} \models \phi(j( \bar{a} )).
  \end{equation*}
  We call such an $\mathcal{M}$ an \hldefn{elementary substructure} of $\mathcal{N}$, and we denote $\mathcal{M} \preceq \mathcal{N}$.
\end{defn}

In simpler words, any formula that is true in $\mathcal{N}$ is true in its elementary substructure $\mathcal{M}$,

\begin{crly}[Isomorphisms are Elementary Embeddings]\label{crly:isomorphisms_are_elementary_embeddings}
  Every isomorphism is an elementary embedding.
\end{crly}

\begin{proof}
  We already know the result for quantifier-free statements from \cref{propo:structure_traversal_with_respect_to_quantifiers}, and so it suffices to prove this statement by induction on the number of quantifiers, which we shall call $n$. In fact, it suffices to prove for the case of an existential $\mathcal{L}$-formula, since we can write $\forall$ as $\neg \exists \neg$.

  Suppose $g : \mathcal{M} \to \mathcal{N}$ is an $\mathcal{L}$-isomorphism, where $\mathcal{M} \subseteq \mathcal{N}$. There is nothing to show for $n = 0$. Suppose that the statement holds for $n = m$. Consider an $\mathcal{L}$-formula of the form $\phi(\bar{x}) = \exists y \psi(\bar{x}, y)$, where $\bar{x} \in M^{m + 1}$, and $\psi$ an $\mathcal{L}$-formula with lower complexity than $\phi$. Then for $a \in M^{m + 1}$,
  \begin{align*}
    \mathcal{M} \models \phi(\bar{a}) &\iff \mathcal{M} \models \exists b \psi (\bar{a}, b) \\
                                      &\iff \mathcal{N} \models \exists b \psi (g(\bar{a}), g(b)) \quad \because \text{ IH } \\
                                      &\iff \mathcal{N} \models \exists c \psi (g(\bar{a}), c) \quad \because f \text{ is bijective } \\
                                      &\iff \mathcal{N} \models \phi(g(\bar{a})).
  \end{align*}
  This completes the proof.\qed\
\end{proof}

\begin{eg}
  Let $\mathcal{Q} = (\mathbb{Q}, <, 0)$ be an $\mathcal{L} = \{ <, 0 \}$-structure. Show that the graph of addition is not definable in $\mathcal{L}$.
\end{eg}

\begin{solution}
  \sidenote{Question: why did we look at the automorphisms?}We need make this inference from automorphisms on $\mathcal{Q}$. Let $\sigma : \mathbb{Q} \to \mathbb{Q}$ be an automorphism. Then we have that
  \begin{gather*}
    x < y \iff \sigma(x) < \sigma(y) \\
    \sigma(0) = 0 \\
    \text{ and } \sigma \text{ is a bijection }
  \end{gather*}
  For example, the map $x \mapsto ax$, for some $a > 0$, is an automorphism on $\mathbb{Q}$.

  \hlwarn{Clarification required.}
\end{solution}

\begin{propo}[\imponote\ Tarski-Vaught Test]\index{Tarski-Vaught Test}\label{propo:tarski_vaught_test}
  Suppose $\mathcal{M} \subseteq \mathcal{N}$. TFAE
  \begin{enumerate}
    \item $\mathcal{M} \preceq \mathcal{N}$
    \item For every $\mathcal{L}$-formula $\phi(\bar{x}, y)$ and all $n$-tuples $\bar{a} \in M^n$, if $\mathcal{N} \models \exists y \phi(\bar{a}, y)$, then there exists $b \in M$ such that $\mathcal{N} \models \phi(\bar{a}, b)$.
  \end{enumerate}
\end{propo}

\begin{proof}
  \hlbnotea{$(1) \implies (2)$}: Suppose $\mathcal{M} \preceq \mathcal{N}$. Then $\exists j : \mathcal{M} \to \mathcal{N}$ an elementary embedding such that for all $\mathcal{L}$-formula $\phi$ and $\bar{a} \in M^n$, 
  \begin{equation*}
    \mathcal{M} \models \phi(\bar{a}) \iff \mathcal{N} \models \phi(j(\bar{a})).
  \end{equation*}
  In particular, the identity map is such an embedding. Let $\psi(x) = \exists y \phi(\bar{x}, y)$. Then
  \begin{align*}
    \mathcal{N} \models \psi(\bar{a}) &\overset{\text{defn }\ref{defn:elementary_embeddings}}{\iff} \mathcal{M} \models \psi(\bar{a}) \\
                                      &\iff \mathcal{M} \models \exists b \phi(\bar{a}, b) \\
                                      &\overset{\text{defn }\ref{defn:elementary_embeddings}}{\iff} \mathcal{N} \models \exists b \phi(\bar{a}, b)
  \end{align*}
  This completes $(\implies)$. $\dashv$

  \noindent\hlbnotea{$(2) \implies (1)$}: We shall use induction on the complexity of the $\mathcal{L}$-formula $\phi$. 
  \begin{itemize}
    \item If $\phi(\bar{a})$ is quantifier-free, then since $\mathcal{M} \subseteq \mathcal{N}$, by \cref{propo:structure_traversal_with_respect_to_quantifiers}, we have $\mathcal{M} \models \phi(\bar{a}) \iff \mathcal{N} \models \phi(\bar{a})$. This case also covers the atomic formulas.
      \item If $\phi(\bar{a})$ is of the form $\phi_1(\bar{x}) \lor \phi_2(\bar{x})$, where $\phi_1(\bar{x}), \phi_2(\bar{x})$ are $\mathcal{L}$-formulas whose results are known, then
        \begin{align*}
          \mathcal{M} \models \phi(\bar{a}) &\iff \mathcal{M} \models \phi_1(\bar{a}) \text{ or } \mathcal{M} \models \phi_2(\bar{a}) \\
                                            &\iff \mathcal{N} \models \phi_1(\bar{a}) \text{ or } \mathcal{N} \models \phi_2(\bar{a}) \enspace \because \text{ IH } \\
                                            &\iff \mathcal{N} \models \phi(\bar{a}).
        \end{align*}

      \item If $\phi(\bar{x})$ is of the form $\phi_1(\bar{x}) \land \phi_2(\bar{x})$, the proof is the same as the previous item.
      \item If $\phi(\bar{x})$ is of the form $\neg \psi(\bar{x})$ for some $\mathcal{L}$-formula $\psi$, then
        \begin{align*}
          \mathcal{M} \models \phi(\bar{a}) &\iff \mathcal{M} \models \neg \psi(\bar{a}) \\
                                            &\iff \mathcal{N} \models \neg \psi(\bar{a}) \enspace \because \text{ IH } \\
                                            &\iff \mathcal{N} \models \phi(\bar{a}).
        \end{align*}

      \item As stated before in another proof, it suffices to prove for the existential case, since $\forall$ can be written as $\neg \exists \neg$. Suppose $\phi(\bar{x})$ is of the form $\exists y \psi(\bar{x}, y)$, for some $\mathcal{L}$-formula $\psi(\bar{x}, y)$ whose result we already know. We know that $\mathcal{M} \models \phi(\bar{a}) \implies \mathcal{N} \models \phi(\bar{a})$ by \cref{propo:structure_traversal_with_respect_to_quantifiers}. For the converse,
        \begin{align*}
          \mathcal{N} \models \phi(\bar{a}) &\iff \mathcal{N} \models \exists y \psi(\bar{a}, y) \\
                                            &\implies \text{ there exists } b \in M \; \mathcal{N} \models \psi(\bar{a}, b) \\
                                            &\overset{\text{IH}}{\implies} \text{ there exists } b \in M \; \mathcal{M} \models \psi(\bar{a}, b) \\
                                            &\implies \mathcal{M} \models \exists y \psi(\bar{a}, y) \\
                                            &\iff \mathcal{M} \models \phi(\bar{a}).
        \end{align*}
    \end{itemize}

    This completes the proof.\qed\
\end{proof}

\begin{remark}
  The Tarski-Vaught Test gives us an alternate mechanism to check if a substructure is elementary.
\end{remark}

\begin{thm}[Downward L\"{o}wenhein-Skolem]\index{Downward L\"{o}wenhein-Skolem}\label{thm:downward_lowenhein_skolem}
  Suppose $\mathcal{M}$ is an $\mathcal{L}$-structure, and $A \subseteq M$. Then there exists an elementary substructure of $\mathcal{M}$ that contains $A$ and is of cardinality at most $\max\{ \abs{A}, \abs{\mathcal{L}}, \aleph_0 \}$.

  In particular, if $\mathcal{L}$ is countable, then every $\mathcal{L}$-structure has a countable elementary substructure.
\end{thm}

\begin{proof}
  Let $\kappa = \max \{ \abs{ A }, \abs{ \mathcal{L} }, \aleph_0 \}$. Define, recursively so, a countable chain of subsets of $M$,
  \begin{equation*}
    A = A_0 \subseteq A_1 \subseteq \hdots \subseteq A_n \subseteq \hdots,
  \end{equation*}
  such that each of their cardinality is less than $\kappa$, such that for each $n \geq 0$, if $\phi(\bar{x}, y)$ is an $\mathcal{L}$-formula, and $\bar{a} \in A_n$ such that $\mathcal{M} \models \exists y \phi(\bar{a}, y)$, then it is clear that there exists $b \in A_{n + 1}$ with $\mathcal{M} \models \phi(\bar{a}, b)$.

  Given an $A_n$, we shall show a way to construct $A_{n + 1}$. \hlwarn{Requires clarification} 
\end{proof}

\begin{eg}
  Consider the language $\mathcal{L}$ of rings and the $\mathcal{L}$-structure $\mathcal{C} = (\mathbb{C}, 0, 1, +, -, \times)$. We know that $\mathcal{Q} = (\mathbb{Q}, 0, 1, +, -, \times)$ is an $\mathcal{L}$-substructure of $\mathcal{C}$. It can be shown that the structure that is the \hlnotea{algebraic closure} of $\mathbb{Q}$ is an elementary $\mathcal{L}$-substructure of $\mathcal{C}$.\sidenote{\hlwarn{Why? How can we show this?}}
\end{eg}

% subsection elementary_embeddings (end)

% section first_order_logic_continued_3 (end)

% chapter lecture_14_oct_25th (end)

\chapter{Lecture 15 Oct 30th}%
\label{chp:lecture_15_oct_30th}
% chapter lecture_15_oct_30th

\section{First-order Logic (Continued 5)}%
\label{sec:first_order_logic_continued_5}
% section first_order_logic_continued_5

\subsection{Elementary Embeddings (Continued)}%
\label{sub:elementary_embeddings_continued}
% subsection elementary_embeddings_continued

\begin{eg}
  $\mathcal{Q} = (\mathbb{Q}, 0, +, -)$ has no proper elementary subgroups.
\end{eg}

\begin{proof}
  Let $G \preceq \mathcal{Q}$. For a fixed $n > 0$, we know that
  \begin{gather*}
    \mathcal{Q} \models \forall x \; \forall y \; ( \underbrace{y + y + \hdots + y}_{n \text{ times }} = x ) \\
    \mathcal{Q} \models \exists x \; ( x \neq 0 )
  \end{gather*}
  So $G$ must be some non-trivial divisible subgroup of $\mathcal{Q}$. Let $\frac{n}{m} \in G$, with $n \neq 0$. WMA\sidenote{Short for \hlnotea{We May Assume}. We may indeed assume that both $n$ and $m$ are strictly positive, or we can just factor out $-1$.} $n, m > 0$. Then $n \in G$ by $n$ divisibility in $G$. Thus $1 \in G$ Thus $\mathbb{Z} \leq G \leq \mathbb{Q}$, and so\sidenote{\hlwarn{How does this follow?}} $G = \mathbb{Q}$ by divisibility.
\end{proof}

\begin{remark}
  By \cref{thm:downward_lowenhein_skolem}, $(\mathbb{R}, 0, +, -)$ has many proper elementary subgroups, e.g. $\mathbb{Q}$.\sidenote{\hlwarn{How so? Is it simply by taking $q + r$ for $q \in \mathbb{Q}$ and $r \in \mathbb{R} \setminus \mathbb{Q}$.}}
\end{remark}

% subsection elementary_embeddings_continued (end)

\subsection{Parameters and Definable Sets}%
\label{sub:parameters_and_definable_sets}
% subsection parameters_and_definable_sets

\begin{eg}
  In $(\mathbb{R}, <)$, the subset $(0, 1)$ is not $\mathcal{L}$-definable: we could have said that $(0 < x) \land (x < 1)$, but $0, 1 \notin \mathcal{L}$.
\end{eg}

We would now like to rid ourselves of such a restriction.

\begin{defn}[Parameters]\index{Parameters}\label{defn:parameters}
  Suppose $\mathcal{L}$ is a language, $\mathcal{M}$ an $\mathcal{L}$-structure, and $B \subseteq M$. Let
  \begin{equation*}
    \mathcal{L}_B := \mathcal{L} \cup \{ \bar{b} : b \in B \}
  \end{equation*}
  be the language $\mathcal{L}$ extended with new constant symbols $\bar{b} \in B$. These additional symbols are called \hlnotea{parameters}.
\end{defn}

We can consequently talk about $\mathcal{L}_B$-structures,
\begin{equation*}
  \mathcal{M}_B = (\mathcal{M}, \bar{b}^\mathcal{M} = b)_{b \in B}.
\end{equation*}

\begin{remark}
  Since each of the $\bar{b}^\mathcal{M} = b \in M$, we will often just write $\mathcal{M}$ instead of putting a subscript of $B$ for the $\mathcal{L}_B$-structure.\sidenote{Is this saying that from hereon, we will somewhat be more loose on the constants of the language, in that we can use any of the constants from the underlying universe?}
\end{remark}

\begin{eg}
  With parameters, in $(\mathbb{R}, <)_{\{ 0, 1 \}}$, we can use the $\mathcal{L}_\{0, 1\}$-formula
  \begin{equation*}
    (\bar{0} < x) \land (x < \bar{1}),
  \end{equation*}
  or more easily written as
  \begin{equation*}
    (0 < x) \land (x < 1),
  \end{equation*}
  to define the interval $(0, 1)$.
\end{eg}

\begin{remark}
  \begin{enumerate}
    \item If $\phi(x_1, \ldots, x_n)$ is an $\mathcal{L}_B$-formula, then there exists an $\mathcal{L}$-formula
      \begin{equation*}
        \psi(x_1, \ldots, x_n, y_1, \ldots, y_m)
      \end{equation*}
      for some $m < \omega$, and $b_1, \ldots, b_m \in B$ such that
      \begin{equation*}
        \phi(x_1, \ldots, x_n) = \psi(x_1, \ldots, x_n, \bar{b}_1, \ldots \bar{b}_m).
      \end{equation*}
      Moreover, given $a_1, \ldots, a_n \in M$,
      \begin{equation*}
        \mathcal{M} \models \phi(a_1, \ldots, a_n) \iff \mathcal{M} \models \psi(a_1, \ldots, a_n, b_1, \ldots, b_m).
      \end{equation*}
      As mentioned in an earlier comment, we will often write
      \begin{equation*}
        \psi(\vec{x}, \vec{\bar{b}}) \text{ as } \psi(\vec{x}, \vec{b}).
      \end{equation*}

    \item Suppose $\mathcal{N} \subseteq \mathcal{M}$. Then $\mathcal{N} \preceq \mathcal{M}$ iff for every $\mathcal{L}_N$-sentence $\sigma = \phi(\bar{b}_1, \ldots, \bar{b}_m)$, for some $b_1, \ldots, b_m \in N$,
      \begin{equation*}
        \mathcal{N} \models \sigma \iff \mathcal{M} \models \sigma.
      \end{equation*}
      In particular, notice that
      \begin{gather*}
        \mathcal{N} \models \sigma \iff \mathcal{N}_N \models \sigma \iff \mathcal{N}_N \models \phi(b_1, \ldots, b_m) \\
          \mathcal{M} \models \sigma \iff \mathcal{M} \models \phi(b_1, \ldots, b_m).
      \end{gather*}
  \end{enumerate}
\end{remark}

\begin{defn}[$B$-Definable]\index{$B$-Definable}\label{defn:_b_definable}
  Let $\mathcal{M}$ be an $\mathcal{L}$-structure for some language $\mathcal{L}$, and $B \subseteq M$ a subset. A let $X \subseteq M^n$, for some $n < \omega$, is \hlnoteb{$D$-definable} (or \hlnoteb{definable over $B$}) if there is an $\mathcal{L}_B$-formula $\phi(x_1, \ldots, x_n)$ such that
  \begin{equation*}
    X = \{ (a_1, \ldots, a_n) \in M^n : \mathcal{M}_B \models \phi(a_1, \ldots, a_n) \}.
  \end{equation*}
  We say that $X$ is \hldefn{$0$-definable} if it is \hldefn{$\emptyset$-definable}. We say that $X$ is definable if it is \hldefn{$M$-definable}, i.e. definable with parameters from anywhere in the universe. We say that $X$ is \hldefn{quantifier-free definable} (respectively \hldefn{existentially definable} or \hldefn{universally definable}) if there is a quantifier-free (respectively existential or universal) formula $\phi$ such that $X = \phi^\mathcal{M}$.
\end{defn}

\begin{note}
  \begin{itemize}
    \item If $X$ is definable, then it is $B$-definable for some $B \subseteq M$.
    \item A function $f : X \to Y$ is $B$-definable if $X \subseteq M^n, \, Y \subseteq M^m$ are $B$-definable, and
      \begin{equation*}
        \Gamma(f) \subseteq X \times Y \subseteq M^{n + m}
      \end{equation*}
      is $B$-definable.
  \end{itemize}
\end{note}

\begin{eg}
  Let $\mathcal{L} = \{ 0, 1, +, -, \times \}$, and $\mathcal{R} = ( \mathbb{R}, 0, 1, +, -, \times ))$. We shall assume (in this course, ``perversely'' so) that a ring is commutative and unitary. What are the definable sets in $\mathcal{R}$?
\end{eg}

\begin{eg}[Zero Sets of Polynomials]
  Suppose $\mathcal{M} = (F, 0, 1, +, -, \times)$ where $R$ is a field. Suppose $P_1, \ldots, P_l \in R[X_1, \ldots, X_n]$. The zero set of $\{ P_1, \ldots, P_l \}$
  \begin{equation*}
    V ( P_1, \ldots, P_l ) = \{ a \in R^n : P_i(a) = 0, i = 1, \ldots, l \}
  \end{equation*}
  is called a \hldefn{variety}. Such sets are called \hlnotea{algebraic sets} of $R^n$. They form the closed sets of a topology on $R^n$, called a \hldefn{Zariski} topology, and the closed sets are called \hlnotea{Zariski's closed subsets}. We can define such a set using the $\mathcal{L}_R$-formula
  \begin{equation*}
    \bigwedge_{i=1}^{l} \left( P_i (x_1, \ldots, x_n) = 0 \right).
  \end{equation*}
  It is clear that Zariski's closed subsets of $R^n$ are quantifier-free definable in $\mathcal{R}$, with parameters from $R$.

  More generally, any finnite \hlnotea{boolean combination}\sidenote{Boolean combinations include taking unions, intersections, and complements.} of Zariski's closed subsets are quantifier-free definable. Sets that can be expressible as such are said to be \hldefn{Zariski-constructible}.
\end{eg}

In fact, Zariski's closed subsets are exactly all of the quantifier-free definable sets.

\begin{ex}
  Let $B \subseteq R$ and $S$ a subring generated by $B$. The $\mathcal{L}_B$-terms of $\mathcal{R}$ are precisely the polynomial functions over $S$, i.e. for any $\mathcal{L}_B$-term, $t(x_1, \ldots, x_n)$, there is $P_t \in S[ X_1, \ldots, X_n ]$ such that $t^\mathcal{R} = P_t$, as functions on $R^n$.

  In fact, for any ring $A \supseteq S$, $t^\mathcal{A} = P_t$, where $\mathcal{A} = (A, 0, 1, +, -, \times)$.
\end{ex}

Suppoer $\phi$ is an atomic $\mathcal{L}_R$-formula. Then $\phi$ can be
\begin{equation*}
  t (x_1, \ldots, x_n) = s (x_1, \ldots, x_n),
\end{equation*}
where $t, s$ are $\mathcal{L}_R$-terms. Then by the exercise above, we have that
\begin{equation*}
  \phi^\mathcal{R} = \bigvee ( P_t - P_s ),
\end{equation*}
i.e. it is Zariski closed (or Z-closed). We see that quantifier-free formulas are Zariski-constructible (Z-constructible).

The following is a ``fact'' of which we shall see again later on.

\begin{thmnonum}
  If $R = F$ is an algebraically closed field, then every definable set in $(F, 0, 1, +, -, \times)$ is Z-constructible.
\end{thmnonum}

This is a \hlnotea{quantifier-elimination theorem}, of which we shall study slightly later on in the course.

\begin{remark}
  With regards to the unnumbered theorem above, the only definable subsetes of $F$ are the finite and cofinite\sidenote{
  \begin{margindefn}[Cofinite]\index{Cofinite}\label{defn:cofinite}
    A cofinite set is a set whose complement is a finite set.
  \end{margindefn}
  } sets.
\end{remark}

\begin{eg}
  In $(\mathbb{R}, 0, 1, +, -, \times)$, $(0, 1)$ is definable by $(0 < x) \land (x < 1)$ and $<$ is definable in the structure. However, we have that $<$ is not a quantifier-free definable set. This is because $\mathbb{R}$ as a field is not algebraically closed.
\end{eg}

% % subsection parameters_and_definable_sets (end)

% % section first_order_logic_continued_5 (end)

% % chapter lecture_15_oct_30th (end)

\appendix

\backmatter\

\pagestyle{plain}

\bibliography{references}

\printindex

\end{document}
