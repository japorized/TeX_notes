\documentclass[notoc,notitlepage]{tufte-book}
% \nonstopmode % uncomment to enable nonstopmode

\usepackage{classnotetitle}

\title{ACTSC 431 --- Loss Model I}
\author{Johnson Ng}
\subtitle{Classnotes for Fall 2018}
\credentials{BMath (Hons), Pure Mathematics major, Actuarial Science Minor}
\institution{University of Waterloo}

\input{latex-classnotes-preamble.tex}
\input{probnotation.tex}

\setsidenotefont{\color{light}\footnotesize}
\setmarginnotefont{\color{light}\footnotesize}

\DeclareMathOperator{\VaR}{VaR}
\DeclareMathOperator{\TVaR}{TVaR}
\DeclareMathOperator{\LER}{LER }

\begin{document}
\hypersetup{pageanchor=false}
\maketitle
\hypersetup{pageanchor=true}
\begin{fullwidth}
\tableofcontents
\end{fullwidth}

\chapter*{\faBook\ \enspace\ List of Definitions}
\addcontentsline{toc}{chapter}{List of Definitions}
\theoremlisttype{all}
\begin{fullwidth}
\listtheorems{defn}
\end{fullwidth}

\chapter*{\faCoffee\ \enspace\ List of Theorems}
\addcontentsline{toc}{chapter}{List of Theorems}
\theoremlisttype{allname}
\begin{fullwidth}
\listtheorems{axiom,lemma,thm,crly,propo}
\end{fullwidth}

\chapter{Lecture 1 Sep 06}%
\label{chp:lecture_1_sep_06}
% chapter lecture_1_sep_06

\section{Introduction and Overview}%
\label{sec:introduction_and_overview}
% section introduction_and_overview

\paragraph{Course Objective} In Loss Model I, the focus of our study is to learn the basic methods which are used by insurers to quantify risk from mathematical/statistical models, in order for insurers to make various decisions\sidenote{e.g.\ setting premiums, control expenses, deciding for reinsurance, etc.}. By quantifying risk, it helps us monitor underlying risks so that not only are we aware of them, but also so that we can take actions or preventive measures against them.

Our main interest of this course is:
\begin{itemize}
  \item to quantify and seek protection against the loss of funds due either to \hlnoteb{too many claims} or \hlnoteb{a few large claims};
  \item to reduce adverse financial impact of random events that prevent the realization of reasonable expectations.
\end{itemize}

\newthought{The main model that shall be the focus} of this course is \hlnoteb{models for liability risk}.

\begin{defn}[Liability Risk]\index{Liability Risk}\label{defn:liability_risk}
  A \hlnoteb{liability risk} is a risk that insurance companies assume by selling insurance contracts.
\end{defn}

In particular, the liability that we shall focus on is \hlnotea{insurance claims}.\marginnote{Many of the models that we shall see later in the course are also applied for other types of risks, e.g.\ investment risk, credit risk, liquidity risk, and operational risk.}

\newthought{We are interested} in modelling the total amount of claims, i.e.\ the \hldefn{aggregate claim amount}, of a group fo insurance policies over a given period of time. In the actuarial literature, there are two main approaches that have been proposed to model the aggrement claim amount of an insurance portfolio, namely:
\begin{itemize}
  \item individual risk model;
  \item collective risk model.
\end{itemize}

\subsection{Individual Risk Model}%
\label{sub:individual_risk_model}
% subsection individual_risk_model

\begin{defn}[Individual Risk Model]\index{Individual Risk Model}\label{defn:individual_risk_model}
  In an \hlnoteb{individual risk model}, the aggregate claim is modeled by
  \begin{equation*}
    S = \sum_{i=1}^{n} Z_i
  \end{equation*}
  where $n$ is a \hlnotea{deterministic}\sidenote{i.e.\ fixed} integer that represents the \hlnotec{total number of insurance policies}, and $Z_i$ is a random variable for the \hlnotec{potential loss of the $i$\textsuperscript{th} insurance policy.}
\end{defn}

\begin{note}
  Since a policy may or may not incur a loss\sidenote{Since a claim may or may not be made!}, we have that
  \begin{equation*}
    P(Z_i = 0) > 0.
  \end{equation*}
  Thus, in an individual risk model, we may also express the aggregate claim amount as
  \begin{equation*}
    S = \sum_{i=1}^{n} X_i I_i
  \end{equation*}
  where $I_i$ is the indicator function about the claimant of policy $i$, while $X_i$ represents the size of the claim(s) for the $i$\textsuperscript{th} policy provided that there is a claim.\sidenote{\hlimpo{This is actually incorrect, despite being in the recommended textbook. See \cref{sec:individual_risk_model_an_alternate_view}.}}
\end{note}

However, in an individual risk model, according to Dhaene and Vyncke (2010)\cite{DhaeneVyncke2010},

\begin{quotebox}{be-red}{light}
  A third type of error that may arise when computing aggregate claims follows from the fact that the assumption of mutual independency of the individual claim amounts may be violated in practice.
\end{quotebox}

Due to complications such as this, the individual risk model will not be the focus of our studies.

% subsection individual_risk_model (end)

\subsection{Collective Risk Model}%
\label{sub:collective_risk_model}
% subsection collective_risk_model

\begin{defn}[Collective Risk Model]\index{Collective Risk Model}\label{defn:collective_risk_model}
  In a \hlnoteb{collective risk model}, the aggregate claim is modeled by
  \begin{equation*}
    S = \sum_{i=1}^{N} X_i, \end{equation*}
  where $N$ is a non-negative integer-valued random variable that denotes \hlnotec{the number of claims among a given set of policies}, while $X_i$ denotes the \hlnotec{size of the $i$\textsuperscript{th} policy.}
\end{defn}

\begin{note}
  In a collective risk model, we need to determine:
  \begin{itemize}
    \item the distribution of the total number of claims for the entire portfolio, i.e.\ the distribution of $N$; and
    \item the distribution of the loss amount per claim, i.e.\ the distribution of $X_i$.
  \end{itemize}
\end{note}

% subsection collective_risk_model (end)

In this course, the primary focus of our studies will be on \hlnotea{collective risk models}.

\paragraph{Terminologies} To end today's lecture, the following terminologies are introduced:

\begin{defn}[Severity Distribution]\index{Severity Distribution}\label{defn:severity_distribution}
  The \hlnoteb{severity distribution} is the distribution of the loss amount of the amount paid by the insurer on a given loss/claim.
\end{defn}

\begin{defn}[Frequency Distribution]\index{Frequency Distribution}\label{defn:frequency_distribution}
  The \hlnoteb{frequency distribution} is the distributino fo the number of losses/claims paid by the insurer over a given period of time.
\end{defn}

\begin{note}
  The frequency distribution is typically a discrete distribution.
\end{note}

\begin{defn}[Aggrement Payment / Loss]\index{Aggrement Payment}\index{Aggregate Loss}\label{defn:aggrement_payment_loss}
  The \hlnoteb{aggregate payment (loss)} is the total amout of all claim payments (losses) over a given period of time.
\end{defn}

\begin{note}
  There is a distinction between an aggregate payment and an aggregate loss, since an aggregate payment is ``essentially'' an aggregate loss after certain claim adjustments, such as deductibles, limits, and coinsurance.
\end{note}

% section introduction_and_overview (end)

% chapter lecture_1_sep_06 (end)

\chapter{Lecture 2 Sep 11th}%
\label{chp:lecture_2_sep_11th}
% chapter lecture_2_sep_11th

\section{Review of Probability Theory}%
\label{sec:review_of_probability_theory}
% section review_of_probability_theory

Firstly, we shall review the definition of a random variable.

\begin{defn}[Random Variable]\index{Random Variable}\label{defn:random_variable}
  Let $\Omega$ be a sample space and $\mathcal{F}$ its $\sigma$-algebra\sidenote{For definitions of $\Omega$ and $\mathcal{F}$, see notes on STAT330.}. A \hlnoteb{random variable} (rv) $X : \Omega \to (\Omega, \mathcal{F})$ is a function from a possible set of outcomes to a measurable space $(\Omega, \mathcal{F})$. Within the context of our interest, $X$ is real-valued, i.e. $(\Omega, \mathcal{F}) = \mathbb{R}$.
\end{defn}

\subsection{Discrete Random Variables}%
\label{sub:discrete_random_variables}
% subsection discrete_random_variables

\begin{defn}[Discrete Random Variable]\index{Discrete Random Variable}\label{defn:discrete_random_variable}
  A \hlnoteb{discrete random variable} (drv) is an rv $X$ that takes only countable (finite) real values.
\end{defn}

\begin{note}
  Let $X$ be a drv.
  \begin{itemize}
    \item The \hlnotea{probability mass function} (pmf) of $X$ is: for $i \in \mathbb{N}$,
      \begin{equation*}
        p(x_i) = P(X = x_i)
      \end{equation*}

    \item The \hlnotea{cumulative distribution function} (cdf) of $X$ is
      \begin{equation*}
        F(x) = P(X \leq x) = \sum_{x_i \leq x} p(x_i).
      \end{equation*}

    \item The $k$th \hldefn{moment} of $X$ is\sidenote{This implicitly uses the \href{https://en.wikipedia.org/wiki/Law_of_the_unconscious_statistician}{Law of the Unconcious Statistician}.}
      \begin{equation*}
        E[X^k] = \sum_{i \in \mathbb{N}} x_i^k p(x_i)
      \end{equation*}
      if $E[X^k]$ is finite.

    \item Some commonly seen/introduced discrete distributions are: Poisson, Binomial, Negative Binomial
  \end{itemize}
\end{note}

\begin{eg}
  Let $X$ take values from $\{x_1, x_2, x_3, x_4\}$, and
  \begin{equation*}
    p(x_i) = P(X = x_i) \text{ for } i = 1, 2, 3, 4.
  \end{equation*}
  The cdf of $X$ is\marginnote{
    It is recommended to visualize the cdf first before putting it down in pencil.
    \resizebox{4.5cm}{!}{
    \begin{tikzpicture}
      % axes
      \draw[->] (0, 0) -- (0, 5) node[above] {$F(x)$};
      \draw[->] (0, 0) -- (5, 0) node[right] {$x$};
      \node[below=1.5mm] at (1, 0) {$x_1$};
      \node[below=1.5mm] at (2, 0) {$x_2$};
      \node[below=1.5mm] at (3, 0) {$x_3$};
      \node[below=1.5mm] at (4, 0) {$x_4$};

      % cdf
      \draw[-,line width=0.5mm] (0, 0) -- (1, 0);
      \draw[-,line width=0.5mm] (1, 1) -- (2, 1);
      \draw[-,line width=0.5mm] (2, 2) -- (3, 2);
      \draw[-,line width=0.5mm] (3, 3) -- (4, 3);
      \draw[->,line width=0.5mm] (4, 4) -- (5, 4);
      \node[circle,inner sep=2pt,draw] at (1, 0) {};
      \node[circle,inner sep=2pt,draw] at (2, 1) {};
      \node[circle,inner sep=2pt,draw] at (3, 2) {};
      \node[circle,inner sep=2pt,draw] at (4, 3) {};
      \node[circle,inner sep=2pt,fill] at (1, 1) {};
      \node[circle,inner sep=2pt,fill] at (2, 2) {};
      \node[circle,inner sep=2pt,fill] at (3, 3) {};
      \node[circle,inner sep=2pt,fill] at (4, 4) {};
      \draw[dotted] (4, 4) -- (0, 4) node[left] {$1$};

      % jumps
      \draw[dotted] (1, 1) -- (1, 0) node[midway,left] {$p(x_1)$};
      \draw[dotted] (2, 2) -- (2, 1) node[midway,left] {$p(x_2)$};
      \draw[dotted] (3, 3) -- (3, 2) node[midway,left] {$p(x_3)$};
      \draw[dotted] (4, 4) -- (4, 3) node[midway,left] {$p(x_4)$};
    \end{tikzpicture}
    }
  }
  \begin{equation*}
    F(x) = \begin{cases}
      0               & x < x_1 \\
      p(x_1)          & x_1 \leq x < x_2 \\
      p(x_1) + p(x_2) & x_2 \leq x < x_3 \\
      1 - p(x_4)      & x_3 \leq x < x_4 \\
      1               & x \geq x_4
    \end{cases}
  \end{equation*}
\end{eg}

\begin{note}
  \begin{itemize}
    \item It is important that we stress the need for showing \hlnotea{right continuity} in the graph.
    \item Note that the cdf always sums to $1$.
    \item The ``\hlnotea{jumps}'' at $x_i$ correspond to $p(x_i)$, for $i = 1, 2 ,3, 4$.
  \end{itemize}
\end{note}

\begin{defn}[Probability Generating Function]\index{Probability Generating Function}\label{defn:probability_generating_function}
  Suppose a drv $X$ only takes \hlimpo{non-negative integer values}. The \hlnoteb{probability generating function} (pgf) of $X$ is defined as
  \begin{equation*}
    G(z) = E\left[ z^X \right] = \sum_{k=1}^{\infty} z^k p(k)
  \end{equation*}
  where we note that if $\max X = n$, then $p(m) = 0$ for all $m > n$.
\end{defn}

\begin{note}
  \begin{itemize}
    \item The pgf uniquely identifies the distribution of the drv\sidenote{\faHandPaperO\ This was given as is without proof, and I cannot find any resources that proves this.}.
    \item To get the probability for $k \in \{0, 1, 2, \ldots\}$, we simply need to do
      \begin{equation*}
        p(k) = \frac{1}{k!} G^{(k)}(x) \at{x = 0}{}.
      \end{equation*}
  \end{itemize}
\end{note}

\begin{eg}[Lecture Slides: Example 1]
  Consider a drv $X$ with pmf
  \begin{equation*}
    p(x) = P(X = x) = \begin{cases}
      0.5 & x = 0 \\
      0.4 & x = 1 \\
      0.1 & x = 2
    \end{cases}
  \end{equation*}
  Its cdf is\marginnote{
    \resizebox{4.5cm}{!}{
    \begin{tikzpicture}
      % axes
      \draw[->] (0, 0) -- (0, 5) node[above] {$F(x)$};
      \draw[->] (0, 0) -- (3.5, 0) node[right] {$x$};
      \node[below=1.5mm] at (1, 0) {$0$};
      \node[below=1.5mm] at (2, 0) {$1$};
      \node[below=1.5mm] at (3, 0) {$2$};

      % cdf
      \draw[-,line width=0.5mm] (0, 2) -- (1, 2);
      \draw[-,line width=0.5mm] (1, 3.6) -- (2, 3.6);
      \draw[->,line width=0.5mm] (2, 4) -- (3.5, 4);
      \node[circle,inner sep=2pt,draw] at (1, 2) {};
      \node[circle,inner sep=2pt,draw] at (2, 3.6) {};
      \node[circle,inner sep=2pt,fill] at (0, 2) {};
      \node[circle,inner sep=2pt,fill] at (1, 3.6) {};
      \node[circle,inner sep=2pt,fill] at (2, 4) {};
      \draw[dotted] (3, 4) -- (0, 4) node[left] {$1$};

      % jumps
      \draw[dotted] (0, 0) -- (0, 2) node[midway,left] {$0.5$};
      \draw[dotted] (1, 2) -- (1, 3.6) node[midway,left] {$0.4$};
      \draw[dotted] (2, 3.6) -- (2, 4) node[midway,left] {$0.1$};
    \end{tikzpicture}
    }
  }
  \begin{equation*}
    F(x) = P(X \leq x) \begin{cases}
      0   & x < 0 \\
      0.5 & 0 \leq x < 1 \\
      0.9 & 1 \leq x < 2 \\
      1   & x \geq 2
    \end{cases}
  \end{equation*}
  and its pgf is
  \begin{equation*}
    G(z) = E\left[ z^X \right] = 0.5 + 0.4z + 0.1z^2.
  \end{equation*}
\end{eg}

% subsection discrete_random_variables (end)

\subsection{Continuous Random Variables}%
\label{sub:continuous_random_variables}
% subsection continuous_random_variables

\begin{defn}[Continuous Random Variable]\index{Continuous Random Variable}\label{defn:continuous_random_variable}
  A \hlnoteb{continuous random variable} (crv) takes on a continuum of values.
\end{defn}

\begin{note}
  Let $X$ be a crv.
  \begin{itemize}
    \item $\exists f : X \to \mathbb{R}$ called a \hlnotea{probability density function} (pdf) such that its cdf is
      \begin{equation*}
        F(x) = \int_{-\infty}^{x} f(y) \dif{y},
      \end{equation*}
      and consequently by the \hlnotea{Fundamental Theorem of Calculus}, we have
      \begin{equation*}
        f(x) = F'(x).
      \end{equation*}

    \item The $k$th moment of $X$ is
      \begin{equation*}
        E[X^k] = \int_{x} x^k f(x) \dif{x} 
      \end{equation*}
      so long that $E[X^k]$ is defined.
      
    \item Some commonly introduced distributions are: Uniform, Exponential, Gamma, Weibull, and Normal.
  \end{itemize}
\end{note}

\begin{defn}[Moment Generating Function]\index{Moment Generating Function}\label{defn:moment_generating_function}
Let $X$ be an rv. The \hlnoteb{moment generating function} (mgf)\marginnote{The mgf is also defined for drvs.} of $X$ is, for $t \in \mathbb{R}$ (appropriately so),
  \begin{equation*}
    M_X(t) = E\left[e^{tX}\right] = \int_{x} e^{tx} f(x) \dif{x}
  \end{equation*}
  provided that the integral is well-defined.
\end{defn}

\begin{note}
  \begin{itemize}
    \item The mgf uniquely determines the distribution of its rv\sidenote{\faHandPaperO\ This shall, also, not be proven in this course.}

    \item With the mgf, we can obtain the $k$th moment of an rv $X$ by
      \begin{equation*}
        E\left[X^k\right] = \frac{d^k}{dt^k} M_X(t) \at{t = 0}{}
      \end{equation*}
  \end{itemize}
\end{note}

\begin{eg}[Lecture Notes: Example 2]
  Consider an exponential rv $X$ with pdf\sidenote{When not explicitly stated, it shall be assumed that domains at which we did not specify $x$ shall have probability $0$.}
  \begin{equation*}
    f(x) = 0.1e^{-0.1x}, \; x > 0.
  \end{equation*}
  Its cdf is
  \begin{equation*}
    F(x) = \int_{-\infty}^{x} f(y) \dif{y} = \begin{cases}
      1 - e^{-0.1 x} & x \geq 0 \\
      0              & \text{otherwise}
    \end{cases}
  \end{equation*}
  and its mgf is
  \begin{align*}
    M_X(t) &= E\left[ e^{tX} \right] = \int_{0}^{\infty} e^{tx} 0.1 e^{-0.1x} \dif{x} \\
           &= 0.1 \int_{0}^{\infty} e^{( t - 0.1 )x} \dif{x} \\
           &= \frac{0.1}{0.1 - t}, \enspace t < 0.1,
  \end{align*}
  where we note that we must have $t < 0.1$, for otherwise the value of the exponent would render the integral undefined.
\end{eg}

\begin{defn}[Hazard Rate Function]\index{Hazard Rate Function}\label{defn:hazard_rate_function}
  For a crv $X$, the \hlnoteb{hazard rate function} (aka \hldefn{failure rate}) of $X$ is defined as
  \begin{equation*}
    h(x) = \frac{f(x)}{\bar{F}(x)} = - \frac{d}{dx} \ln \bar{F}(x),
  \end{equation*}
  where $\bar{F}(x) = 1 - F(x)$ is the \hlnotea{survival function}\sidenote{You should be familiar with this if you have studied for Exam P.}
\end{defn}

\begin{note}
  \begin{itemize}
    \item We may also express the survival function in terms of the hazard rate by
      \begin{equation*}
        \bar{F}(x) = e^{- \int_{-\infty}^{x} h(y) \dif{y}}.
      \end{equation*}

    \item In terms of limits, we can express the hazard rate function, for small enough $\delta > 0$, as
      \begin{align*}
        h(x) &= \frac{f(x)}{\bar{F}(x)} = \frac{F'(x)}{\bar{F}(x)} \\
             &\approx \frac{F(x + \delta) - F(x)}{\delta \bar{F}(x)} \\
             &= \frac{P(x < X \leq x + \delta)}{\delta F(X > x)} \\
             &= \frac{1}{\delta} P(x < X \leq x + \delta \mid X > x).
      \end{align*}
      We can make sense of this expression by recalling the notion of the probability of survival from Exam MLC\sidenote{This also tells us that the hazard rate gets its name from life insurance.}, where if a life has survived over $x$, the hazard rate is the probability that the life does not survive beyond another $\delta$ \sidenote{From the perspective of life insurance, the greater the probability, the more likely the claim is going to happen.}.
  \end{itemize}
\end{note}

% subsection continuous_random_variables (end)

% section review_of_probability_theory (end)

% chapter lecture_2_sep_11th (end)

\chapter{Lecture 3 Sep 13th}%
\label{chp:lecture_3_sep_13th}
% chapter lecture_3_sep_13th

\section{Review of Probability Theory (Continued)}%
\label{sec:review_of_probability_theory_continued}
% section review_of_probability_theory_continued

\subsection{Continuous Random Variables (Continued)}%
\label{sub:continuous_random_variables_continued}
% subsection continuous_random_variables_continued

\begin{eg}[Lecture Notes: Example 3 --- Hazard Rate of Weibull Distribution]\label{eg:weibull_hazard_rate}
  Suppose $X \sim \Wei(\theta, \tau)$ with pdf
  \begin{equation*}
    f(x) = \frac{\tau {\left( \frac{x}{\theta} \right)}^\tau e^{-{\left( \frac{x}{\theta} \right)}^\tau}}{x}, \quad x > 0,
  \end{equation*}
  where $\theta, \tau > 0$. Find its hazard rate function.
\end{eg}

\begin{solution}
  We first require the survival function\sidenote{\hlnotea{Weibull Survival Function}\label{note:weibull_survival_function}}:
  \begin{align*}
    \bar{F}(x) &= \int_{x}^{\infty} \frac{1}{y} \tau {\left( \frac{y}{\theta} \right)}^\tau e^{-{\left( \frac{y}{\theta} \right)}^\tau} \dif{y} \\
               &= \int_{\frac{x}{\theta}}^{\infty} \frac{1}{u} \tau u^\tau e^{-u^\tau} \dif{u} \qquad \text{ where } u = \frac{y}{\theta} \\
               &= \int_{\frac{x}{\theta}}^{\infty} \tau u^{\tau - 1} e^{-u^\tau} \dif{u} \\
               &= -e^{-u^\tau} \at{\frac{x}{\theta}}{\infty} = e^{-{\left( \frac{x}{\theta} \right)}^\tau}
  \end{align*}
  The hazard rate is therefore
  \begin{equation*}
    h(x) = \frac{f(x)}{\bar{F}(x)} = \frac{\tau}{x} {\left( \frac{x}{\theta} \right)}^\tau
  \end{equation*}
\end{solution}

% subsection continuous_random_variables_continued (end)

\subsection{Mixed Random Variable}%
\label{sub:mixed_random_variable}
% subsection mixed_random_variable

\begin{defn}[Mixed Random Variable]\index{Mixed Random Variable}\label{defn:mixed_random_variable}
  We call $X$ a \hlnoteb{mixed random variable} (mixed rv) if it has both discrete and continuous components.
\end{defn}

\begin{note}
  \begin{itemize}
    \item Mixed rvs are important in modeling insurance claims, e.g., the loss amount is usually a continuous random variable with a probability mass at $0$.
  \end{itemize}
\end{note}

The following is a type of mixed random variable:

\begin{defn}[Deductibles]\index{Deductibles}\label{defn:deductibles}
  Let $X$ be an rv and $d$ be a fixed value.
  \begin{equation*}
    {[ X - d ]}_+ = \begin{cases}
      X - d & x \geq d \\
      0     & \text{ otherwise }
    \end{cases}
  \end{equation*}
\end{defn}

\begin{note}
  If $X$ be an rv and $d$ a fixed value, the deductible ${[X - d]}_+$ has a mass point at $0$ since
  \begin{equation*}
    P( {[ X - d ]}_+ = 0 ) = P(X < d) > 0
  \end{equation*}
\end{note}

\begin{note}
  Let $\{ x_1, x_2, \ldots \}$ be a sequence of real numbers in an increasing order. Suppose $X$ is a rv that takes on values on the real, and has a \hlnotea{density function} $f$ on each interval $(x_i, x_{i + 1})$, and has \hlnotea{discrete mass points} at the boundaries of these intervals, i.e.\marginnote{In other words, we treat the discrete and continuous part of a mixed rv separately.}
  \begin{equation*}
    P(X = x_i) = p(x_i) > 0 \quad i \in \mathbb{N}.
  \end{equation*}
  Since $X$ is an rv, it must be the case that
  \begin{equation*}
    \sum_{i \in \mathbb{N}} p(x_i) + \sum_{i \in \mathbb{N}} \int_{x_i}^{x_{i + 1}} f(x) \dif{x}  = 1.
  \end{equation*}
  The cdf of a mixed rv $X$ is
  \begin{equation*}
    F(x) = P(X \leq x) = \sum_{i \in \mathbb{N}} p(x_i) \mathbb{1}_{\{x_i \leq x\}} + \sum_{i \in \mathbb{N}} \int_{x_i}^{x_{i + 1}} f(y) \mathbb{1}_{\{ y \leq x \} } \dif{y}.
  \end{equation*}
  The $k$th moment of $X$ is
  \begin{equation*}
    E\left[X^k\right] = \sum_{i \in \mathbb{N}} {(x_i)}^k p(x_i) + \sum_{i \in \mathbb{N}} \int_{x_i}^{x_{i + 1}} x^k f(x) \dif{x}.
  \end{equation*}
  The mgf of $X$ is
  \begin{equation*}
    M_X(t) = E\left[ e^{tX} \right] = \sum_{i \in \mathbb{N}} e^{tx_i} p(x_i) + \sum_{i \in \mathbb{N}} \int_{x_i}^{x_{i + 1}} e^{tx} f(x) \dif{x}.
  \end{equation*}
\end{note}

\begin{eg}[Lecture Notes: Example 4]
  Assume a claim amount of an insurance policy is modeled by a non-negative rv $X$ which has probability mass of $p$ and $0$, and otherwise continuous with a pdf $f$ over $(0, \infty)$. Find its cdf, $k$th moment, and mgf.
\end{eg}

\begin{solution}
  The cdf of $X$ is
  \begin{equation*}
    F(x) = \begin{cases}
      p + \int_{0}^{x} f(y) \dif{y} & x \geq 0 \\
      0                             & \text{ otherwise }
    \end{cases}
  \end{equation*}
  The $k$th moment of $X$ is
  \begin{equation*}
    E\left[ X^k \right] = \int_{0}^{\infty} x^k f(x) \dif{x}.
  \end{equation*}
  The mgf of $X$ is
  \begin{equation*}
    M_X(t) = p + \int_{0}^{\infty} e^{tx} f(x) \dif{x}.
  \end{equation*}
\end{solution}

% subsection mixed_random_variable (end)

% section review_of_probability_theory_continued (end)

\section{Distributional Quantities and Risk Measures}%
\label{sec:distributional_quantities_and_risk_measures}
% section distributional_quantities_and_risk_measures

\newthought{This chapter} introduces us to some \hlnotea{distributional quantities} for a given rv $X$. These distributional quantities are informative values to describe the characteristics of a risk.

\subsection{Distributional Quantities}%
\label{sub:distributional_quantities}
% subsection distributional_quantities

\begin{defn}[Central Moment]\index{Central Moment}\label{defn:central_moment}
  The \hlnoteb{$k$th central moment} of an rv $X$ is defined as
  \begin{equation*}
    E\left[ {(X - E(X))}^k \right].
  \end{equation*}
\end{defn}

\begin{note}
  The second central moment is the \hldefn{variance}. The square root of the variance is the \hldefn{standard deviation}.
\end{note}

\begin{eg}[Lecture Notes: Example 5]
  Consider an rv $Y = \begin{cases} Y_1 & U = 1 \\ Y_2 & U = 2 \end{cases} \; $\sidenote{This notation is just syntatic sugar for saying $Y_1 = Y \mid ( U = 1 )$ and $Y_2 = Y \mid ( U = 2 )$.}, where $Y_1 = 0$, $Y_2 \sim \Exp(10)$, and $P(U = 1) = P(U = 2) = 0.5$.
  \begin{enumerate}
    \item Find the cdf of $Y$.
    \item Find the mean and variance of $Y$.
    \item Let $Z = \frac{1}{2} Y_1 + \frac{1}{2} Y_2$. Does $Z$ have the same distribution as $Y$? Answer this by solving the mean and variance of $Z$.
  \end{enumerate}
\end{eg}

\begin{solution}
  \begin{enumerate}
    \item Note that
      \begin{equation*}
        F(y) = P( Y_1 \leq y \mid U = 1 ) P(U = 1) + P( Y_2 \leq y \mid U = 2 ) P(U = 2).
      \end{equation*}
      Observe that
      \begin{equation*}
        P(Y_1 \leq y \mid U = 1) = \begin{cases}
          1 & y \geq 0 \\
          0 & y < 0
        \end{cases}
      \end{equation*}
      and
      \begin{equation*}
        P(Y_2 \leq y \mid U = 2) = \begin{cases}
          1 - e^{-10y} & y \geq 0 \\
          0            & y < 0
        \end{cases}
      \end{equation*}
      Therefore
      \begin{equation*}
        F(y) = \begin{cases}
          1 - \frac{1}{2} e^{-10 y} & y \geq 0 \\
          0                         & y < 0
        \end{cases}
      \end{equation*}

    \item The mean of $Y$ is
      \begin{equation*}
        E(Y) = E(Y \mid U = 1) P(U = 1) + E(Y \mid U = 2) P(U = 2) = 10 \cdot \frac{1}{2} = 5.
      \end{equation*}
      To calculate the variance of $Y$, we require
      \begin{align*}
        E\left[Y^2\right] &= E\left[Y^2 \mid U = 1\right] P(U = 1) + E\left[Y^2 \mid U = 2\right] P(U = 2) \\
                          &= ( \Var(Y_2) + E{(Y_2)}^2 ) \cdot \frac{1}{2} = 100.
      \end{align*}
      Therefore
      \begin{equation*}
        \Var(Y) = 100 - 5^2 = 75.
      \end{equation*}

    \item The mean of $Z$ is
      \begin{equation*}
        E[Z] = E[ \frac{1}{2} Y_1 + \frac{1}{2} Y_2 ] = 5.
      \end{equation*}
      The variance of $Z$ is
      \begin{equation*}
        \Var(Z) = \frac{1}{4} \Var(Y_1) + \frac{1}{4} \Var(Y_2) = 25.
      \end{equation*}
      Therefore, $Z$ does not have the same distribution as $Y$.
  \end{enumerate}
\end{solution}

\begin{defn}[Quantiles]\index{Quantiles}\label{defn:quantiles}
  The \hlnoteb{$100p\%$ quantile} (or \hldefn{percentile}) of an rv $X$ is a set $\pi_p$ such that\marginnote{This definition may also be presented as: any number $\pi_p$ such that
  \begin{equation*}
    P(X < \pi_p) \leq p \leq P(X \leq \pi_p).
  \end{equation*}}
  \begin{equation*}
    \pi_p = \{ x \in X \mid P(X < x) \leq p \leq P(X \leq x) \}.
  \end{equation*}
\end{defn}

\begin{note}
  \begin{itemize}
    \item If $X$ is a continuous random variable, we have that $P(X < \pi_p) = P(X \leq \pi_p)$ and so we have to define the quantile as
      \begin{equation*}
        \pi_p = F^{-1} (p)
      \end{equation*}
      where $F^{-1}$ is the inverse function of $F$, the cdf of $X$.

    \item A quantile \hlimpo{can be a set of numbers}.
    \item $\pi_{0.5}$ is called the \hldefn{median} of $X$.
  \end{itemize}
\end{note}

\marginnote{Graphical method to interpret this notion will be included.}

\begin{eg}[Lecture Notes: Example 1]
  Find the $100p\%$ quantile of the loss distribution $F(x) = 1 - e^{-\frac{x}{\theta}}$, $x > 0$.
\end{eg}

\begin{solution}
  Note that $F$ is the cdf of an exponential distribution, which is a continuous distribution. Therefore,
  \begin{equation*}
    F(\pi_p) = 1 - e^{-\frac{\pi_p}{\theta}} = p \implies \pi_p = - \theta \ln (1 - p).
  \end{equation*}
\end{solution}

\begin{eg}[Lecture Notes: Example 2]
  Find the median $\pi_{0.5}$ for the following cdf
  \begin{equation*}
    F(x) = \begin{cases}
      0                                & x < 0 \\
      0.6 + 0.4 (1 - e^{-\frac{x}{3}}) & x \geq 0
    \end{cases}
  \end{equation*}
\end{eg}

\begin{solution}
  Since $F(0) = 0.6$ and $F$ is an increasing function, we have that $F(x) = 0$ for all $x < 0$. Therefore
  \begin{equation*}
    \pi_{0.5} = 0.
  \end{equation*}
\end{solution}

\begin{eg}[Lecture Notes: Example 3]
  Find the median $\pi_{0.5}$ for a loss $X$ with pmf
  \begin{equation*}
    p(0) = 0.25, \, p(1) = 0.25, \, p(2) = 0.5.
  \end{equation*}
\end{eg}

\begin{solution}
  The cdf of $X$ is
  \begin{equation*}
    F(x) = \begin{cases}
      0    & x < 0 \\
      0.25 & 0 \leq x < 1 \\
      0.5  & 1 \leq x < 2 \\
      1    & x \geq 2
    \end{cases}
  \end{equation*}
  since $F(x) = 0.5$ when $1 \leq x < 2$, we have that
  \begin{equation*}
    \pi_{0.5} = [1, 2].
  \end{equation*}
\end{solution}

% subsection distributional_quantities (end)

% section distributional_quantities_and_risk_measures (end)

% chapter lecture_3_sep_13th (end)

\chapter{Lecture 4 Sep 18th}%
\label{chp:lecture_4_sep_18th}
% chapter lecture_4_sep_18th

\section{Distributional Quantities and Risk Measures (Continued)}%
\label{sec:distributional_quantities_and_risk_measures_continued}
% section distributional_quantities_and_risk_measures_continued

\subsection{Risk Measures}%
\label{sub:risk_measures}
% subsection risk_measures

\begin{defn}[Risk Measure]\index{Risk Measure}\label{defn:risk_measure}
  A \hlnoteb{risk measure} is a mapping from the loss rv to the real line $\mathbb{R}$.
\end{defn}

Klugman, Panjer \& Wilmot (2012)~\cite{KlugmanPanjerWillmot2012} on risk measure:

\begin{quotebox}{be-yellow}{light}
  The level of exposure to risk is often described by one number, or at least a small set of numbers. These numbers are necessarily functions of the model and are often called ‘key risk indicators’. Such key risk indicators indicate to risk managers the degree to which the company is subject to particular aspects of risk.
\end{quotebox}

To ensure its solvency, insurers will have to charge on these risks, i.e.\ we have to \hlnotea{price these exposures to risks}.

\begin{defn}[Premium Principle]\index{Premium Principle}\label{defn:premium_principle}
  A \hlnoteb{premium principle} (or \hldefn{insurance pricing}) is a rule for assigning a premium to an insurance risk.
\end{defn}

\begin{note}
  The following are some of the common principles used by insurers:
  \begin{itemize}
    \item \hldefn{Expectation Principle}
      \begin{equation*}
        \Pi(X) = ( 1 + \theta ) E(X), \quad \theta > 0
      \end{equation*}
    \item \hldefn{Standard Deviation Principle}
      \begin{equation*}
        \Pi(X) = E(X) + \theta \sqrt{\Var(X)}, \quad \theta > 0
      \end{equation*}
    \item \hldefn{Dutch Principle}
      \begin{equation*}
        \Pi(X) = E(X) + \theta E( {[ X - E(X) ]}_+ ), \quad \theta > 0
      \end{equation*}
  \end{itemize}
\end{note}

One particular measure is known as the \hlnotea{Value-at-Risk} (VaR).

\subsubsection{Value-At-Risk}\label{ssub:Value-At-Risk}

\begin{defn}[Value-at-Risk (VaR)]\index{Value-at-Risk}\index{VaR}\label{defn:value_at_risk}
The \hlnoteb{Value-at-Risk (VaR)} is a \hlnotea{quantile} of the distribution of aggregate losses, i.e.\ the $VaR$ of a risk $X$ at the $100\%p$ level is defined as\sidenote{I must find out why we define using $\inf$ instead of $\min$ (see following remark), and I will not take ``safe definition'' as an answer without full justification.}
  \begin{align*}
    \pi_p = \VaR_p (X) &= \inf \{ x \in \mathbb{R} : P (X > x) \leq 1 - p \} \\
               &= \inf \{ x \in \mathbb{R} : P (X \leq x) \geq p \}.
  \end{align*}
\end{defn}

\begin{note}
  \begin{itemize}
    \item $\VaR$ is often called a \hldefn{quantile risk measure}.
    \item $\VaR$ is the standard risk measure used to evaluate exposure to risks.
    \item $\VaR$ measures the amount of capital required by the insurer to remain solvent, with high certainty, in the face of large claims.
    \item In practice, $p$ is generally high: $99.95\%$ or as low as $95\%$.
  \end{itemize}
\end{note}

\begin{remark}
  Observe that\marginnote{This remark basically points out that the left endpoint of the interval $B$ is always included, which should be quite clear by right-continuity of $F$.}
  \begin{equation*}
    B = \{ x \in \mathbb{R} \mid F_X(x) \geq p \} = (A, \infty) \text{ or } [A, \infty)
  \end{equation*}
  for some $A \in \mathbb{R}$, since $F$ is an increasing function. Now let $x_0 \in B$ such that
  \begin{equation*}
    F(x_0) = P(X \leq x_0) \geq p \quad \land \quad F(x_0-) = P(X < x_0) \leq p,
  \end{equation*}
  i.e.\ it is not necessary that $P(X = x_0) = p$ (see the two example graphs on the margin).
  \begin{marginfigure}
    \begin{tikzpicture}
      \draw[->] (0, 0) -- (4, 0) node[right] {$x$};
      \draw[->] (0, 0) -- (0, 4) node[above] {$F(x)$};
      \draw (0, 1) -- (1, 1);
      \draw (1, 2) -- (2, 2);
      \draw[->] (2, 3) -- (4, 3);
      \node[circle,fill,inner sep=1pt] at (1, 2) {};
      \node[circle,fill,inner sep=1pt] at (2, 3) {};
      \node[circle,draw,inner sep=1pt] at (1, 1) {};
      \node[circle,draw,inner sep=1pt] at (2, 2) {};
      \draw[dotted] (4, 1.5) -- (0, 1.5) node[left] {$p$};
      \draw[dotted] (1, 2) -- (1, 0) node[below] {$x_0$};
    \end{tikzpicture}
    \caption{Discrete cdf}
  \end{marginfigure}
  \begin{marginfigure}
    \begin{tikzpicture}
      \draw[->] (0, 0) -- (4, 0) node[right] {$x$};
      \draw[->] (0, 0) -- (0, 4) node[above] {$F(x)$};
      \draw[->,smooth,domain=0:4] plot (\x,{sqrt(\x)});
      \draw[dotted] (4, 1.5) -- (0, 1.5) node[left] {$p$};
      \draw[dotted] (2.25, 2) -- (2.25, 0) node[below] {$x_0$};
      \node[circle,fill,inner sep=1pt] at (2.25,1.5) {};
    \end{tikzpicture}
    \caption{Continuous cdf}
  \end{marginfigure}
  Let ${\{ x_n \}}_{n \in \mathbb{N}}$ be a decreasing sequence of points on $\mathbb{R}$ such that $x_n \to x_0$ as $n \to \infty$. Since $F$ is right-continuous, we have that $F(x_n) \to F(x_0)$ as $n \to \infty$. Therefore,
  \begin{equation*}
    B = [ x_0 , \infty )
  \end{equation*}\marginnote{The lecturer asserts that we can really define $\VaR$ using $\min$ instead of $\inf$, but even with this, I am not completely satisfied or convinced.}
  This justifies the definition of $\pi_p$.
\end{remark}

\begin{note}
  \begin{itemize}
    \item Note that by definition, we have
      \begin{equation*}
        P(X < \pi_p) \leq p \leq P(X \leq \pi_p)
      \end{equation*}
    \item If $X$ is a crv whose cdf is strictly increasing, i.e.\ no constant points, then
      \begin{equation*}
        \pi_p = F^{-1}(p)
      \end{equation*}
      since $P(X < \pi_p) = P(X \leq \pi_p)$.
  \end{itemize}
\end{note}

\begin{warning}[Shortcomings of $\VaR$]
  \begin{itemize}
    \item $\VaR$ cannot tell us the size of the potential loss in the $100(1 - p)\%$ cases, making it difficult for us to prepare the right amount in order to safeguard against insolvency.
    \item $\VaR$ actually fails to satisfy properties to be a \hlnotea{coherent risk measure}\sidenote{See \cref{sec:coherent_risk_measure}.}, for example, \hlnotea{subadditivity}.
    \item $\VaR$ is extensively used in financial risk management of trading risk over a fixed (usually short) time period, which are usually normally distributed, and $\VaR$ satisfies all coherency requirements.
    \item In insurance losses, instead of normal distributions, in general, skewed distributions are used, and in this cases, $\VaR$ is flawed as it lacks subadditivity.
  \end{itemize}
\end{warning}

\begin{eg}\label{eg:varp_pareto}
  Suppose that $X$ has a Pareto distribution with cdf
  \begin{equation*}
    F(x) = 1 - {\left( \frac{\theta}{x + \theta} \right)}^\alpha , \quad x > 0
  \end{equation*}
  where $\alpha, \theta > 0$. Find $\VaR_p(X)$.
\end{eg}

\begin{solution}
  Since $F$ is continuous and strictly increasing, we have that
  \begin{equation*}
    \pi_p = F^{-1}(p) = \theta \left[ {(1 - p)}^{-\frac{1}{\alpha}} - 1 \right]
  \end{equation*}
\end{solution}

\begin{eg}
  Find $\VaR_{0.95}(X)$, $\VaR_{0.5}(X)$, and $\VaR_{0.3}(X)$ for a random loss with pmf
  \begin{equation*}
    p(0) = 0.25, \, p(1) = 0.25, \, \text{ and } p(2) = 0.5.
  \end{equation*}
\end{eg}

\begin{solution}
  Note that the cdf of $X$ is
  \begin{equation*}
    F(x) = \begin{cases}
      0    & x < 0 \\
      0.25 & 0 \leq x < 1 \\
      0.5  & 1 \leq x < 2 \\
      1    & x \geq 2
    \end{cases}.
  \end{equation*}
  Therefore,
  \begin{equation*}
    \VaR_{0.95}(X) = 2, \, \VaR_{0.5}(X) = 1, \, \text{ and } \VaR_{0.3}(X) = 1.
  \end{equation*}
\end{solution}

\subsubsection{Tail-Value-at-Risk}\label{ssub:Tail-Value-at-Risk}

To compensate for the weakness of $\VaR$ at giving us the size of the loss $X$ of which we cannot measure, we use the \hlnotea{Tail-Value-at-Risk}.

\begin{defn}[Tail-Value-at-Risk (TVaR)]\index{Tail-Value-at-Risk}\label{defn:tail_value_at_risk}
Let $X$ be an rv. The \hlnoteb{Tail-Value-at-Risk (TVaR)} of $X$ at the $100p\%$ level, denoted as $\TVaR_p(X)$, is defined as the average of all $\VaR$ values above the level $p$, and expressed as\marginnote{TVaR also has the following names, used by different regions:
\begin{itemize}
  \item \hlnotea{Conditional Tail Expectation} (CTE) --- NA
  \item \hlnotea{Tail Conditional Expectation} (TCE)
  \item \hlnotea{Expected Shortfall} (ES) --- EU
\end{itemize}}
  \begin{equation*}
    \TVaR_p(X) = \frac{1}{1 - p} \int_{p}^{1} \VaR_\alpha(X) \dif{\alpha} = \frac{1}{1 - p} \int_{p}^{1} \pi_\alpha \dif{\alpha}
  \end{equation*}
\end{defn}

\begin{remark}
  By considering the average of $\VaR$ from $p$'s going up to $1$, we take into account even the extreme cases of which $\VaR$ fails to account for.
\end{remark}

Perhaps a clearer definition would be the following, although the expression is only sensible if $X$ is a crv:

\begin{defn}[Tail-Value-at-Risk (TVaR)]\index{Tail-Value-at-Risk}\label{defn:tail_value_at_risk_v2}
  Let $X$ be an rv. The \hlnoteb{Tail-Value-at-Risk (TVAR)} of $X$ at the $100p\%$ level, denoted $\TVaR_p(X)$, is the expected loss given that the loss exceeds the $100p$ percentile (or quantile) of the distribution of $X$, expressible as
  \begin{equation*}
    \TVaR_p(X) = E[ X \mid X > \pi_p ] = \frac{1}{\bar{F}(\pi_p)} \int_{\pi_p}^{\infty} x f(x) \dif{x}.
  \end{equation*}
\end{defn}

Note that the two definitions agree with one another:

\begin{align*}
  \frac{1}{1 - p} \int_{p}^{1} \pi_\alpha \dif{\alpha} &= \frac{1}{1 - F(\pi_p)} \int_{p}^{1} F^{-1}(\alpha) \dif{\alpha} \\
                                                       &= \frac{1}{\bar{F}(\pi_p)} \int_{\pi_p}^{1} x f(x) \dif{x}
\end{align*}
where we let $\alpha = F(x)$ as substitution.

\begin{note}
  While it is not difficult to notice that
  \begin{equation*}
    \TVaR_p(X) \geq \VaR_p(X),
  \end{equation*}
  the proof is also simple:
  \begin{align*}
    \TVaR_p(X) &= \frac{1}{1 - p} \int_{p}^{1} \pi_\alpha \dif{\alpha} \\
               &\geq \frac{1}{1 - p} \pi_p \int_{p}^{1} \dif{\alpha} = \pi_p = \VaR_p(X).
  \end{align*}
\end{note}

\begin{eg}
  Find $\TVaR_p(X)$ for $X \sim \Exp(\theta)$.
\end{eg}

\begin{solution}
  Since $X$ is a crv, and $F(x) = 1 - e^{- \frac{x}{\theta}}$, we have that
  \begin{equation*}
    \pi_p = F^{-1}(p) = - \theta \ln (1 - p).
  \end{equation*}
  Therefore,
  \begin{align*}
    \TVaR_p(X) &= \frac{1}{1 - p} \int_{p}^{1} \pi_\alpha \dif{\alpha} = \frac{- \theta}{1 - p} \int_{p}^{1} \ln (1 - \alpha) \dif{\alpha} \\
               &= \frac{- \theta}{1 - p} \int_{-\infty}^{\ln (1 - p)} ue^u \dif{u} \quad \text{ let } u = \ln ( 1 - \alpha ) \\
               &= \frac{-\theta}{1 - p} \left[ ue^u \at{-\infty}{\ln (1 - p)} - \int_{-\infty}^{\ln(1-p)} e^u \dif{u} \right] \text{ by IBP } \\
               &= \frac{-\theta}{1 - p} \left[ (1 - p) \ln (1 - p) - ( 1 - p ) \right]\\
               &= \theta [ 1 - \ln (1 - p) ]
  \end{align*}
\end{solution}

\begin{note}
  From the last example, by the memoryless property of $\Exp(\theta)$, notice that we may also do
  \begin{align}
    \TVaR_p(X) &= E[ X \mid X > \pi_p ] = E [ X - \pi_p + \pi_p \mid X > \pi_p ] \nonumber \\
               &= E[ X - \pi_p \mid X > \pi_p ] + E[ \pi_p \mid X > \pi_p ] \label{eq:tvar_memoryless_exp}\\
               &= E[ X ] + \pi_p \nonumber
  \end{align}
\end{note}

% subsection risk_measures (end)

% section distributional_quantities_and_risk_measures_continued (end)

% chapter lecture_4_sep_18th (end)

\chapter{Lecture 5 Sep 20th}%
\label{chp:lecture_5_sep_20th}
% chapter lecture_5_sep_20th

\section{Distrbutional Quantities and Risk Measures (Continued 2)}%
\label{sec:distrbutional_quantities_and_risk_measures_continued_2}
% section distrbutional_quantities_and_risk_measures_continued_2

\subsection{Risk Measures (Continued)}%
\label{sub:risk_measures_continued}
% subsection risk_measures_continued

Before ending this section, we introduce a notion that is related to $\TVaR$.

\begin{defn}[Mean Excess Loss]\index{Mean Excess Loss}\label{defn:mean_excess_loss}
  Let $X$ be an rv, and $d \in \mathbb{R}$. The \hlnoteb{mean excess loss}, denoted $e_X(d)$, is defined as
  \begin{equation*}
    e_X(d) = E[ X - d \mid X > d ]
  \end{equation*}
  and $e_X(d) = 0$ for those $d$ such that $P(X > d) = 0$.
\end{defn}

\begin{propo}[Relation of $\TVaR_p(X)$ and $e_X(d)$]\label{propo:relation_of_tvar_p_x_and_e_x_d_}
  For a crv $X$, we have
  \begin{equation*}
    \TVaR_p(X) = e_X(\pi_p) + \VaR_p(X)
  \end{equation*}
\end{propo}

\begin{proof}
  By \cref{eq:tvar_memoryless_exp}, we have that
  \begin{equation*}
    \TVaR_p(X) = E [ X - \pi_p \mid X > \pi_p ] + \pi_p = e_X(\pi_p) + \pi_p.
  \end{equation*}\qed\
\end{proof}

\begin{propo}[Expection from Survival Function]\label{propo:expection_from_survival_function}
  Let $X$ be a non-negative rv such that $E[X^k] < \infty$, for any $k \in \mathbb{N} \setminus \{ 0 \}$. Then\sidenote{Note that this works for the discrete case as well, by replacing $\int$ with $\sum$.}
  \begin{equation*}
    E\left[X^k\right] = k \int_{0}^{\infty} x^{k - 1} \bar{F}(x) \dif{x}
  \end{equation*}
\end{propo}

\begin{proof}
  Firstly, note that since $E[X^k] < \infty$ for all $k \in \mathbb{N} \setminus \{0\}$, we have that $\bar{F}(x)$ decays faster than $x^k$ as $x \to \infty$. Now
  \begin{align*}
    E\left[ X^k \right] &= \int_{0}^{\infty} x^k f(x) \dif{x} \quad \because \text{ Law of the Unconscious Statistician} \\
                        &= \int_{0}^{\infty} x^k \dif{F(x)} \quad \because \dif{F(x)} = f(x) \dif{x} \\
                        &= - \int_{0}^{\infty} x^k \dif{\bar{F}(x)} \\
                        &= - \left[ x^k \bar{F}(x) \at{0}{\infty} - \int_{0}^{\infty} kx^{k - 1} \bar{F}(x) \dif{x} \right] \quad \because \text{ IBP } \\
                        &= k \int_{0}^{\infty} x^{k - 1} \bar{F}(x) \dif{x}
  \end{align*}\qed\
\end{proof}

\begin{eg}
  Calculate $e_X(d)$ and $\TVaR_p(X)$ for a Pareto distribution $X$ with cdf
  \begin{equation*}
    F(x) = 1 - {\left( \frac{\theta}{x + \theta} \right)}^\alpha, \quad x > 0,
  \end{equation*}
  where $\alpha > 1$ and $\theta > 0$.
\end{eg}

\begin{solution}
  Using \cref{propo:expection_from_survival_function},
  \begin{align*}
    e_X(d) &= \int_{0}^{\infty} P(X - d > x \mid X > d) \dif{x} = \int_{0}^{\infty} \frac{P(X - d > x, X > d)}{P(X > d)} \dif{x} \\
           &= \int_{0}^{\infty} \frac{P(X > x + d)}{P(X > d)} \dif{x} = \int_{0}^{\infty} \frac{\bar{F}(x + d)}{\bar{F}(d)} \dif{x} \\
           &= \int_{0}^{\infty} {\left( \frac{d + \theta}{x + d + \theta} \right)}^\alpha \dif{x} = \frac{{( d + \theta )}^\alpha}{1 - \alpha} {\left( \frac{1}{x + d + \theta} \right)}^{ \alpha - 1 } \at{0}{\infty} \\
           &= \frac{d + \theta}{\alpha - 1}
  \end{align*}
  By \cref{eg:varp_pareto}, we have
  \begin{equation*}
    \pi_p = \theta \left[ {( 1 - p )}^{-\frac{1}{\alpha}} - 1 \right]
  \end{equation*}
  and so
  \begin{align*}
    \TVaR_p(X) &= e_X(\pi_p) + \pi_p \\
               &= \frac{\theta\left[ {(1 - p)}^{-\frac{1}{\alpha}} - 1 \right] + \theta}{\alpha - 1} + \theta\left[ {( 1 - p )}^{-\frac{1}{\alpha}} - 1 \right] \\
               &= \frac{\theta{(1 - p)}^{-\frac{1}{\alpha}}}{\alpha - 1} + \frac{\theta(\alpha - 1){(1 - p)}^{-\frac{1}{\alpha}}}{\alpha - 1} - \theta \\
               &= \frac{\theta \alpha {( 1 - p )}^{-\frac{1}{\alpha}}}{\alpha - 1} - \theta
  \end{align*}
\end{solution}

\begin{propo}[Expected Deductible]\label{propo:expected_deductible}
  We have
  \begin{equation*}
    E( {[ X - d ]}_+ ) = \int_{d}^{\infty} \bar{F}(x) \dif{x}
  \end{equation*}
\end{propo}

\begin{proof}
  By the Law of the Unconscious Statistician and IBP on the last step,
  \begin{equation*}
    E( {[ X - d ]}_+ ) = \int_{d}^{\infty} ( x - d ) \dif{F(x)} = - \int_{d}^{\infty} (x - d) \dif{\bar{F}(x)} = \int_{d}^{\infty} \bar{F}(x) \dif{x}
  \end{equation*}\qed\
\end{proof}

\begin{propo}[An Expression for Mean Excess Value]\label{propo:an_expression_for_mean_excess_value}
  If $\bar{F}(d) > 0$, we have
  \begin{equation*}
    e_X(d) = \frac{\int_{d}^{\infty} \bar{F}(x) \dif{x}}{\bar{F}(d)}
  \end{equation*}
\end{propo}

\begin{proof}
  Observe that by \cref{propo:expected_deductible}, we have
  \begin{align*}
    e_X(d) &= E[ X - d \mid X > d ] = \frac{E[ ( X - d ) \mathbb{1}_{X > d} ]}{P(X > d)} \\
           &= \frac{E( {[ X - d ]}_+ )}{\bar{F}(d)} = \frac{\int_{d}^{\infty} \bar{F}(x) \dif{x}}{\bar{F}(d)}
  \end{align*}\qed\
\end{proof}

% subsection risk_measures_continued (end)

% section distrbutional_quantities_and_risk_measures_continued_2 (end)

\section{Severity Distributions --- Creating Severity Distributions}%
\label{sec:severity_distributions_creating_severity_distributions}
% section severity_distributions_creating_severity_distributions

Recall the definition of a severity distribution.

\begin{defnnonum}[Severity Distribution]\index{Severity Distribution}
  A \hlnoteb{severity distribution} is a distribution used to describe single random losses in an insurance portfolio.
\end{defnnonum}

When a loss occurs, the full amount of the loss is not necessarily the amount paid by the insurer, since an insurance policy typically involves some form of adjustment (e.g. \hlnotea{deductible, limit, coinsurance}). A distinction needs to be made between the actual loss prior to any of the adjustments (aka \hldefn{ground-up loss}) and the amount ultimately paid by the insurer.

Our goal is to find a reasonable model for the \hlnotea{ground-up loss} rv $X$. The following are two desirable properties for $X$:
\begin{itemize}
  \item $\text{Im}(X) = \mathbb{R}_{> 0}$, since losses are positive;
  \item pf of $X$ is right-skewed, since we want the ``tail'' of the distribution to be not heavy.
    \begin{itemize}
      \item The motivation for this property is due to the \hlnotea{20-80 rule}: 20\% of the largest claims accountn for 80\% of the total claim amount.
    \end{itemize}
\end{itemize}

\newthought{There are} two approaches to constructing a severity distribution:
\begin{itemize}
  \item \hlnotea{Parametric approach}\sidenote{This approach shall be the focus of this course.}: specify a ``form'' for the distribution with a finite number of parameters.
  \item Nonparametric approach: no form is specified; the distribution is constructed directly from the empirical data.
\end{itemize}

A weakness of the \textbf{Nonparametric approach} is, if there is not enough data, such as in catasthropic risks, is becomes difficult to obtain reliable information. We shall look at one such example in this approach.

\begin{defn}[Empirical Distribution Function]\index{Empirical Distribution Function}\label{defn:empirical_distribution_function}
  Let $\{ X_1, \ldots, X_n \}$ be an iid sample of a risk $X$. Then its \hlnoteb{empricial distribution function (edf)} is defined as
  \begin{equation*}
    \hat{F}_n(x) = \frac{1}{n} \sum_{i=1}^{n}  \mathbb{1}_{\{X_i \leq x\}}, \quad x \in \mathbb{R}.
  \end{equation*}
\end{defn}

\begin{remark}
  Simply put, the edf assigns a probability of $\frac{1}{n}$ to each sample point $X_i$.
\end{remark}

\begin{eg}
  Consider a random sample of a risk with size $5$: $\{ 30, 80, 150, 150, 200 \}$. Find the edf of the risk.
\end{eg}

\begin{solution}
  The edf is given by
  \begin{equation*}
    \hat{F}_n(x) = \frac{1}{5} \sum_{i=1}^{5} \mathbb{1}_{\{ X_i \leq x_i \}} = \begin{cases}
      0           & x < 30 \\
      \frac{1}{5} & 30 \leq x < 80 \\
      \frac{2}{5} & 80 \leq x < 150 \\
      \frac{4}{5} & 150 \leq x < 200 \\
      1           & x \geq 200
    \end{cases}
  \end{equation*}
\end{solution}

% section severity_distributions_creating_severity_distributions (end)

% chapter lecture_5_sep_20th (end)

\chapter{Lecture 6 Sep 25th}%
\label{chp:lecture_6_sep_25th} % chapter lecture_6_sep_25th

\section{Severity Distributions --- Creating Severity Distributions (Continued)}%
\label{sec:severity_distributions_creating_severity_distributions_continued}
% section severity_distributions_creating_severity_distributions_continued

\paragraph{The Parametric Approach} The following is a graph showing the process of a parametric approach:

\begin{figure}[h]
  \begin{tikzpicture}[
    block/.style = {rectangle, draw, rounded corners,
               text width =15em, align=center,
               color=dark,fill=be-blue},
    sblock/.style = {rectangle, draw, rounded corners,
               text width =4em, align=center},
    ]
    \node [block] (selection) {\textbf{Model Selection}\\
      select a model based on prior knowledge of historical datasets};
    \node [block, below=of selection] (estimation) {\textbf{Model Estimation}\\
      estimate parameter values based on data};
    \node [block, below=of estimation] (validation) {\textbf{Model Validation} \\
      test for goodness-of-fit};
    \node [block, below=of validation] (decision) {Is model acceptable?};
    \node [sblock, left=of decision,color=dark,fill=be-red] (no) {\textbf{No}};
    \node [sblock, right=of decision,color=dark,fill=be-green] (yes) {\textbf{DONE!}};
    
    \draw[-latex'] (selection) -- (estimation);
    \draw[-latex'] (estimation) -- (validation);
    \draw[-latex'] (validation) -- (decision);
    \draw[-latex'] (decision) -- (no);
    \draw[-latex'] (no) |- (selection.west);
    \draw[-latex'] (decision) -- (yes);
  \end{tikzpicture}
  \caption{Process of a Parametric Approach}\label{fig:process_of_a_parametric_approach}
\end{figure}

\paragraph{Common Techniques in Creating New Parametric Distributions} Before diving into the topic, first, a definition:

\begin{defn}[Parametric Distribution]\index{Parametric Distribution}\label{defn:parametric_distribution}
  A \hlnoteb{parametric distribution} is a set of distribution functions, of which each member is determined by specifying one or more parameters.
\end{defn}

Some common techniques are the following:
\begin{itemize}
  \item Multiplication by a constant
  \item Raising to a power
  \item Exponentiation
  \item Mixture of distributions
\end{itemize}

\subsection{Multiplication By A Constant}%
\label{sub:multiplication_by_a_constant}
% subsection multiplication_by_a_constant

This transformation is equivalent to applying inflation uniformly across all loss levels, and is known as a change of scale.

\begin{propo}[Multiplication by a Constant]\label{propo:multiplication_by_a_constant}
  Let $X$ be a crv with cdf $F_X$ and pdf $f_X$. Let $Y = cX$ for some $c > 0$. Then
  \begin{equation*}
    F_Y(y) = F_X\left( \frac{y}{c} \right), \quad f_Y(y) = \frac{1}{c}f_X\left( \frac{y}{c} \right).
  \end{equation*}
\end{propo}

\begin{proof}
  \begin{gather*}
    F_Y(y) = P(Y \leq y) = P( cX \leq y ) = P\left( X \leq \frac{y}{c} \right) = F_X\left( \frac{y}{c} \right) \\
    f_Y(y) = \frac{d}{dy} F_Y(y) = \frac{d}{dy} F_X\left( \frac{y}{c} \right) = \frac{1}{c}f_X\left( \frac{y}{c} \right)
  \end{gather*}\qed\
\end{proof}

\begin{defn}[Scale Distribution]\index{Scale Distribution}\label{defn:scale_distribution}
  We say that a parametric distribution is a \hlnoteb{scale distribution} if $Y = cY$ for any positive constant $c$ is from the same set of distributions as $X$.
\end{defn}

It is clear that we have the following result:

\begin{crly}\label{crly:constant_multiplication_crly}
  The parameter $c$ in \cref{propo:multiplication_by_a_constant} is a scale parameter, and $Y$ is a scale distribution.
\end{crly}

\begin{eg}\label{eg:scale_distn_exp}
  Let $X \sim \Exp(\theta)$ with pdf
  \begin{equation*}
    f_X(x) = \frac{1}{\theta}e^{-\frac{x}{\theta}}, \quad x > 0.
  \end{equation*}
  Let $y = cX$ with $c > 0$, it follows that
  \begin{equation*}
    f_Y(y) = \frac{1}{c}f_X\left(\frac{y}{c}\right) = \frac{1}{c \theta} e^{- \frac{y}{c \theta}}, \quad y > 0.
  \end{equation*}
  Thus $Y \sim \Exp(c\theta)$ and so $Y$ is a scale distribution. In particular, the exponential distribution belongs to a family of scale distributions.
\end{eg}

\begin{defn}[Scale Parameter]\index{Scale Parameter}\label{defn:scale_parameter}
  A parameter $\theta$ is called a \hlnoteb{scale paramter} of a parametric distribution $X$ if it satisfies the following condition: the parametric value of $cX$ is $c \theta$ for any positive constant $c$, and other parameters (if any) remain unchanged.
\end{defn}

\begin{eg}
  From \cref{eg:scale_distn_exp}, we had that
  \begin{equation*}
    f_X(x) = \frac{1}{\theta}e^{-\frac{x}{\theta}}, \quad x > 0.
  \end{equation*}
  We showed that $Y = cX \sim \Exp(c\theta)$. Therefore, the parameter $\theta$ is a scale parameter.
\end{eg}

\begin{eg}
  Determine whether the lognormal distribution $X \sim \LogN(\mu, \sigma^2)$, i.e. $\ln(X) \sim \Nor(\mu, \sigma^2)$, is a scale distribution or not. If yes, determine whether it has any scale parameter.
\end{eg}

\begin{solution}
  Let $Y = cX$ for some $c > 0$. Observe that
  \begin{equation*}
    \ln Y = \ln cX = \ln c + \ln X \sim \Nor(\mu + \ln c, \sigma^2).
  \end{equation*}
  For the last equation, note that if we let $Z = \ln X \sim \Nor(\mu, \sigma^2)$
  \begin{align*}
    E\left[ e^{t( Z + \ln c )} \right] &= e^{t \ln c} e^{\mu t + \frac{\sigma^2 t^2}{2}} = e^{t ( \mu + \ln c ) + \frac{\sigma^2 t^2}{2}}
  \end{align*}
  we see that the above is the mgf of $\Nor(\mu + \ln c, \sigma^2)$. Thus we have that $Y$ has the same distribution as $X$ and so it is a scale distribution. However, we also see that it has no scale parameters.
\end{solution}

% subsection multiplication_by_a_constant (end)

\subsection{Raising to a Power}%
\label{sub:raising_to_a_power}
% subsection raising_to_a_power

\begin{propo}[Raising to a Power]\label{propo:raising_to_a_power}
  Let $X$ be a crv with pdf $f_X$ and cdf $F_X$ with $F_X(0) = 0$. Let $Y = X^{\frac{1}{\tau}}$. If $\tau > 0$, then
  \begin{equation*}
    F_Y(y) = F_X(y^\tau), \quad f_Y(y) = \tau y^{\tau - 1} f_X(y^\tau), \quad y > 0,
  \end{equation*}
  while if $\tau < 0$, then
  \begin{equation*}
    F_Y(y) = 1 - F_X(y^\tau), \quad f_Y(y) = - \tau y^{\tau - 1} f_X(y^\tau), \quad y > 0.
  \end{equation*}
\end{propo}

\begin{proof}
  When $\tau > 0$,
  \begin{equation*}
    F_Y(y) = P(Y \leq y) = P\left(X^{\frac{1}{\tau}}\right) = P\left(X \leq y^\tau\right) = F_X\left(y^\tau\right)
  \end{equation*}
  and
  \begin{equation*}
    f_Y(y) = \frac{d}{dy} F_Y(y) = \frac{d}{dy}f_X\left(y^\tau\right) = \tau y^{\tau - 1} f_X(y^\tau).
  \end{equation*}
  When $\tau < 0$,
  \begin{equation*}
    F_Y(y) = P(Y \leq y) = P\left(X^{\frac{1}{\tau}} \leq y\right) = P\left( X \geq y^\tau \right) = \bar{F}_X(y^\tau)
  \end{equation*}
  and
  \begin{equation*}
    f_Y(y) = \frac{d}{dy} F_Y(y) = \frac{d}{dy} (1 - F_X\left(y^\tau\right)) = - \tau y^{\tau - 1} f_X\left(y^\tau\right).
  \end{equation*}\qed\
\end{proof}

\begin{eg}
  Let $X \sim \Exp(\theta)$ and $Y = X^{\frac{1}{\tau}}$ for $\tau > 0$, we have
  \begin{equation*}
    F_Y(y) = F_X\left(t^{\tau}\right) = 1 - e^{ \frac{-y^\tau}{\theta} } = 1 - e^{-{\left( \frac{y}{\alpha} \right)}^\tau},
  \end{equation*}
  where $\alpha = \theta^{\frac{1}{\tau}}$. In particular, we have that $Y \sim \Wei(\alpha, \tau)$.
\end{eg}

% subsection raising_to_a_power (end)

\subsection{Exponentiation}%
\label{sub:exponentiation}
% subsection exponentiation

\begin{propo}[Exponentiation Method]\label{propo:exponentiation_method}
  Let $X$ be a crv with pdf $f_X$ and cdf $F_X$. Let $Y = e^X$. Then
  \begin{equation*}
    F_Y(y) = F_X(\ln y), \quad f_Y(y) = \frac{1}{y} f_X(\ln y).
  \end{equation*}
\end{propo}

\begin{proof}
  We have
  \begin{equation*}
    F_Y(y) = P\left( e^X \leq y \right) = P( X \leq \ln y ) = F_X(\ln y)
  \end{equation*}
  and
  \begin{equation*}
    f_Y(y) = \frac{d}{dy} F_Y(y) = \frac{d}{dy} F_X(\ln y) = \frac{1}{y} f_X(\ln y).
  \end{equation*}\qed\
\end{proof}

\begin{ex}[Lognormal Distribution]\label{eg:lognormal_distribution}
  Let $X \sim \Nor(\mu, \sigma^2)$. The cdf and pdf of $Y = e^X$ is
  \begin{gather*}
    F_Y(y) = F_X(\ln y) = \Phi\left( \frac{\ln y - \mu}{\sigma} \right) \\
    f_Y(y) = \frac{1}{y} f_X(\ln y) = \frac{1}{y} \frac{1}{\sqrt{2 \pi} \sigma} e^{-\frac{1}{2} \cdot {\left( \frac{\ln y - \mu}{\sigma} \right)}^2}
  \end{gather*}
\end{ex}

% subsection exponentiation (end)

\subsection{Mixing Distributions}%
\label{sub:mixing_distributions}
% subsection mixing_distributions

The rationale behind mixing distributions is to define an rv $X$ conditional on a second rv, say $\Theta$ (aka \hldefn{mixing rv}). The mixing rv $\Theta$ can either be discrete or be continuous, which leads to two types of mixtures:
\begin{itemize}
  \item \hlnotea{discrete mixture}: when $\Theta$ is discrete; and
  \item \hlnotea{continuous mixture}: when $\Theta$ is continuous.
\end{itemize}

\begin{defn}[Discrete Mixed Distribution]\index{Discrete Mixed Distribution}\label{defn:discrete_mixed_distribution}
  Let $\Theta$ be a drv taking values on $\{ \theta_1, \theta_2, \ldots, \theta_n \}$ with
  \begin{equation*}
    P(\Theta = \theta_i) = p_i > 0, \quad i = 1, \ldots, n,
  \end{equation*}
  and the rv $Y_i := X \mid \Theta = \theta_i$ has cdf
  \begin{equation*}
    F_{Y_i}(x) = P(X \leq x \mid \Theta = \theta_i), x \in \mathbb{R}.
  \end{equation*}
  Then $X$ is called a \hlnoteb{discrete mixed distribution} with cdf
  \begin{equation*}
  F_X(x) = \sum_{i=1}^{n} P(X \leq x \mid \Theta = \theta_i) P(\Theta = \theta_i) = \sum_{i=1}^{n} p_i F_{Y_i}(x).
  \end{equation*}
\end{defn}

Following the above definition, by the Law of the Unconscious Statistician, we have
\begin{equation*}
  E[g(X)] = \sum^{n}_{i=1} E[g(X) \mid \Theta = \theta_i] P(\Theta = \theta_i) = \sum_{i=1}^{n} p_i E[g(Y_i)],
\end{equation*}
for any function $g$ such that the expectation exists. In particular, we have
\begin{equation*}
  E[X] = \sum_{i=1}^{n} p_i E[Y_i] \text{ and } E\left[ X^2 \right] = \sum_{i=1}^{n} p_i E\left[Y_i^2\right].
\end{equation*}

\begin{eg}
  Let $Y_i \sim \Exp(i)$ for $i = 1, 2, 3$. Define $X$ to be an equal mixture of these three exponential rvs. Fidn the cdf, pdf, and mean of $X$.
\end{eg}

\begin{solution}
  The cdf of $X$ is
  \begin{align*}
    F_X(x) &= \sum_{i=1}^{3} \frac{1}{3}F_{Y_i}(x) = \frac{(1 - e^{-x}) + (1 - e^{- x / 2}) + (1 - e^{-x / 3})}{3} \\
           &= 1 - \frac{1}{3} \left( e^{-x} + e^{-\frac{x}{2}} + e^{-\frac{x}{3}} \right), x > 0.
  \end{align*}
  The pdf of $X$ is
  \begin{equation*}
    f_X(x) = \frac{1}{3} \left( e^{-x} + \frac{1}{2} e^{-\frac{x}{2}} + \frac{1}{3} e^{-\frac{x}{3}} \right), x > 0.
  \end{equation*}
  The mean of $X$ is therefore
  \begin{equation*}
    E[X] = \sum_{i=1}^{3} E[ Y_i ] = \frac{1}{3} ( 1 + 2 + 3 ) = 2.
  \end{equation*}
\end{solution}

% subsection mixing_distributions (end)

% section severity_distributions_creating_severity_distributions_continued (end)

% chapter lecture_6_sep_25th (end)

\chapter{Lecture 7 Sep 27th}%
\label{chp:lecture_7_sep_27th}
% chapter lecture_7_sep_27th

\section{Severity Distributions --- Creating Severity Distributions (Continued 2)}%
\label{sec:severity_distributions_creating_severity_distributions_continued_2}
% section severity_distributions_creating_severity_distributions_continued_2

\subsection{Mixing Distributions (Continued)}%
\label{sub:mixing_distributions_continued}
% subsection mixing_distributions_continued

\begin{defn}[Continuous Mixture]\index{Continuous Mixture}\label{defn:continuous_mixture}
  Let $\Theta$ be a crv with density $f_\Theta$, and the cdf and pdf of $X \mid \Theta = \theta$ are given by
  \begin{equation*}
    F_{X \mid \Theta}(x \mid \theta) = P(X \leq x \mid \Theta = \theta) \text{ and } f_{X \mid \Theta}(x \mid \theta) = P(X = x \mid \Theta = \theta).
  \end{equation*}
  The unconditional distribution of $X$ is said to be a \hlnoteb{continuous mixed distribution} with cdf and pdf
  \begin{align*}
    F_X(x) &= \int_{-\infty}^{\infty} F_{X \mid \Theta}(x\mid\theta) f_{\Theta}(\theta) \dif{\theta} \\
    f_X(x) &= \int_{-\infty}^{\infty} f_{X \mid \Theta}(x\mid\theta) f_{\Theta}(\theta) \dif{\theta}.
  \end{align*}
  Furthermore, for any function $H$,
  \begin{equation*}
    E[H(X)] = \int_{-\infty}^{\infty} E[H(X) \mid \Theta = \theta] f_{\Theta}(\theta) \dif{\theta}.
  \end{equation*}
\end{defn}

\begin{eg}
  Suppose that $X \mid \Lambda = \lambda$ is exponentially distributed with mean $\frac{1}{\lambda}$, and let $\Lambda$ be a gamma distributed rv with mean $\alpha / \theta$ and variance $\alpha / \theta^2$, i.e.
  \begin{equation*}
    f_{\Lambda}(\lambda) = \frac{\theta^\alpha \lambda^{\alpha - 1} e^{-\theta \lambda}}{\Gamma(\alpha)}, \lambda > 0,
  \end{equation*}
  where $\Gamma(\alpha) = \int_{0}^{\infty} t^{\alpha - 1} e^{-t} \dif{t}$ is the gamma function. Determine the conditional pdf of $X$.
\end{eg}

\begin{solution}
  We have
  \begin{align*}
    f_X(x) &= \int_{0}^{\infty} f_{X \mid \Lambda}(x \mid \lambda) f_{\Lambda}(\lambda) \dif{\lambda} \\
           &= \int_{0}^{\infty} \lambda e^{-x \lambda} \frac{\theta^{\alpha} \lambda^{\alpha - 1} e^{-\theta \lambda}}{\Gamma(\alpha)} \dif{\lambda} \\
           &= \frac{\theta^\alpha}{\Gamma(\alpha)} \int_{0}^{\infty} \lambda^\alpha e^{-\lambda ( x + \theta )} \dif{\lambda} \\
           &= \frac{\theta^\alpha}{\Gamma(\alpha) (x + \theta)} \int_{0}^{\infty} {\left( \frac{y}{x + \theta} \right)}^\alpha e^{-y} \dif{y} \enspace \text{ where } y = \lambda ( x + \theta ) \\
           &= \frac{\theta^\alpha}{\Gamma(\alpha) {( x + \theta )}^{\alpha + 1}} \int_{0}^{\infty} y^\alpha e^{-y} \dif{y} \\
           &= \frac{\theta^\alpha \Gamma(\alpha + 1)}{\Gamma(\alpha) {( x + \theta )}^{\alpha + 1}} = \frac{\alpha \theta^\alpha}{{(x + \theta)}^{\alpha + 1}}.
  \end{align*}
\end{solution}

\begin{propo}[Total Expectation and Total Variance]\index{Total Expectation}\index{Total Variance}\label{propo:total_expectation_and_total_variance}
  For any rvs $X$ and $\Theta$, provided that the repsective expectation and variance exist, we have
  \begin{gather*}
    E[X] = E[ E[ X \mid \Theta ] ] \\
    \Var(X) = E[ \Var(X \mid \Theta) ] + \Var( E[ X \mid \Theta ] )
  \end{gather*}
\end{propo}

\begin{proof}
  \begin{align*}
    E[X] &= E\left( \int_{X} xf_{X \mid \Theta}(x \mid \Theta) \dif{x} \right) \\
         &= \int_{\Theta} \int_{X} xf_{X \mid \Theta}( x \mid \theta ) f_{\Theta}(\theta) \dif{x} \dif{\theta} \\
         &= \int_{X} x \int_{\Theta} f_{X, \Theta}(x, \theta) \dif{\theta} \dif{x} \enspace \because \text{ Fubini's Theorem } \\
         &= \int_{X} xf_X(x) \dif{x} = E[X].
  \end{align*}
  Note that
  \begin{equation*}
    \Var(X \mid \Theta) = E[ X^2 \mid \Theta ] + E{[ X \mid \Theta ]}^2.
  \end{equation*}
  And so
  \begin{align*}
    &E[\Var(X \mid \Theta)] + \Var( E[ X \mid \Theta ] ) \\
    &= E[ E[ X^2 \mid \Theta ] ] - E \left[ E{[ X \mid \Theta ]}^2 \right] + E \left[ E {[ X \mid \Theta ]}^2 \right] - E{[ E [ X \mid \Theta ] ]}^2 \\
    &= E\left[X^2\right] - E{[X]}^2 = \Var(X)
  \end{align*}\qed\
\end{proof}

\begin{eg}
  Suppose that $X \mid \Theta = \theta \sim \Exp(\theta)$ and $p_{\Theta}(\theta) = \frac{1}{3}$ for $\theta = 1, 2, 3$. Find the mean and variance of $X$.
\end{eg}

\begin{solution}
  The mean of $X$ is
  \begin{equation*}
    E[X] = EE[X \mid \Theta] = E[\Theta] = \frac{1}{3} (1 + 2 + 3) = 2.
  \end{equation*}
  The variance of $X$ is
  \begin{align*}
    \Var(X) &= E[\Var(X \mid \Theta)] + \Var( E[X \mid \Theta] ) \\
            &= E[\Theta^2] + \Var(\Theta) = 2E[\Theta^2] - E{[\Theta]}^2 \\
            &= \frac{2}{3}(1 + 4 + 9) - 4 = \frac{28}{3} - \frac{12}{3} = \frac{16}{3}
  \end{align*}
\end{solution}

\begin{eg}
  Suppose that $X \mid \Lambda = \lambda \sim \Exp(\lambda)$ and $\Lambda \sim \Gam(\alpha, \theta)$ with mean $\alpha \theta$ and variance $\alpha \theta^2$. Find the mean and variance of $X$.
\end{eg}

\begin{solution}
  The mean of $X$ is
  \begin{equation*}
    E[X] = EE[X \mid \Lambda] = E[ \Lambda ] = \alpha\theta.
  \end{equation*}
  The variance of $X$ is
  \begin{align*}
    \Var(X) &= E[\Var(X \mid \Lambda)] + \Var( E[ X \mid \Lambda ] ) \\
            &= E[\Lambda^2] + \Var(\Lambda) = 2\Var(\Lambda) + E{[\Lambda]}^2 \\
            &= 2 \alpha \theta^2 + \alpha^2 \theta^2.
  \end{align*}
\end{solution}

% subsection mixing_distributions_continued (end)

% section severity_distributions_creating_severity_distributions_continued_2 (end)

\section{Severity Distributions --- Tail of Distributions}%
\label{sec:severity_distributions_tail_of_distributions}
% section severity_distributions_tail_of_distributions

\begin{defn}[Tail]\index{Tail}\label{defn:tail}
  The \hlnoteb{tail} of a distribution (usually the right tail) is the portion of the distribution corresponding to large values of the random variable.
\end{defn}

It is important that we understand large possible loss values as they have the greatest impact on the total losses that we may have to endure. In general, a loss rv is said to be \hldefn{heavy-tailed} if it has a large probability to take large values.

Two measurements of tail weight:
\begin{itemize}
  \item \textbf{relative}: comparing ``sizes'' of the tails of two distributions;
  \item \textbf{absolute}: classifying distributions as heavy or light-tailed.
\end{itemize}

The following is a set of criteria to measure or compare the heaviness of the tails of loss distributions:
\begin{itemize}
  \item Existence of moments
  \item Limiting ratios
  \item Hazard rate function
  \item Mean excess loss function
\end{itemize}

\subsection{Existence of Moments}%
\label{sub:existence_of_moments}
% subsection existence_of_moments

Recall that the $k$th moment of a loss $X$ is
\begin{equation*}
  E\left[X^k\right] = \int_{0}^{\infty} x^k f_X(x) \dif{x}.
\end{equation*}
Now if $f_X$ takes on large values for large $x$, we may have $E\left[X^k\right]$ blow up to infinity, and so it is desirable to find/use some distribution with a \hlnotea{decaying} probability function, one at which its rate of decay is faster than the growth of $x^{-(k + 1)}$.

% subsection existence_of_moments (end)

% section severity_distributions_tail_of_distributions (end)

% chapter lecture_7_sep_27th (end)

\chapter{Lecture 8 Oct 02nd}%
\label{chp:lecture_8_oct_02nd}
% chapter lecture_8_oct_02nd

\section{Severity Distributions --- Tail of Distributions (Continued)}%
\label{sec:severity_distributions_tail_of_distributions_continued}
% section severity_distributions_tail_of_distributions_continued

\subsection{Existence of Moments (Continued)}%
\label{sub:existence_of_moments_continued}
% subsection existence_of_moments_continued

\begin{eg}
  For a Pareto distribution, as $x \to \infty$, we have that $f_X(x) \sim x^{-(\alpha + 1)}$, so its moments are finite if and only if $k < \alpha$.

  We say that the Pareto distribution has a \hlnotea{power tail}.
\end{eg}

\begin{eg}
  Given the transformed Gamma distribution, with pdf
  \begin{equation*}
    f_X(x) = \frac{{\left( \frac{x}{\theta} \right)}^\alpha e^{- \frac{x}{\theta}}}{x \Gamma(\alpha)}.
  \end{equation*}
  Now as $x \to \infty$, we have
  \begin{equation*}
    f_X(x) \sim x^{\alpha - 1} e^{-\frac{x}{\theta}}
  \end{equation*}
  We see that the exponential term decays faster than the rate of growth of $x^{\alpha - 1}$ for any $\alpha > 0$. Thus all moments of the Gamma distribution exists.

  We say that the Gamma distribution has a \hlnotea{exponential tail}.
\end{eg}

\begin{ex}
  The Normal distribution has an exponential tail.
\end{ex}

\begin{defn}[Heavy-Tails Light-Tails]\index{Heavy-Tailed Distribution}\index{Light-Tailed Distribution}\label{defn:heavy_tails_light_tails}
  We say that a distribution is a \hlnoteb{heavy-tailed distribution} if \hlimpo{its moments only exist up to some $k \in \mathbb{N} \setminus \{ 0 \}$}.\marginnote{The actual definition, or should I say notion, of tail-heaviness comes from talking about the boundedness of the tail of the distribution, with reference to the exponential distribution. If a distribution has a tail that has greater value than the tail of the exponential distribution, then we say that the distribution has a heavy-tail.}

  We say that a distribution is a \hlnoteb{light-tail distribution} if \hlimpo{its moments exist for all $k \in \mathbb{N} \setminus \{ 0 \}$}.
\end{defn}

\begin{note}
  We may also use the mgf to determine if a distribution has a heavy or light tail; the inexistence of the $k$th moment implies the inexistence of the mgf, i.e.\ if the mgf does not exist, then the moments of the distribution is only finite up to some $k \in \mathbb{N} \setminus \{0\}$.
\end{note}

\subsubsection{Limiting Ratio: Survival Functions}%
\label{ssub:limiting_ratio_survival_functions}
% subsubsection limiting_ratio_survival_functions

\begin{defn}[Limiting Ratio]\index{Limiting Ratio}\label{defn:limiting_ratio}
  The \hlnoteb{limiting ratio} of \hlnoteb{two survival functions} is used to compare the heaviness of tails of the two losses. Consider two losses $X$ and $Y$, and consider the limit of the ratio
  \begin{equation*}
    \lim_{x \to \infty} \frac{\bar{F}_X(x)}{\bar{F}_Y(x)}.
  \end{equation*}
  If the limit does not exist, we say that the comparison is inconclusive. Otherwise, we have 3 cases:
  \begin{marginfigure}
    \centering
    \begin{tikzpicture}[yscale=2]
      \draw[->] (-0.5,-0.1) -- (3, -0.1) node[right] {$x$};
      \draw[->] (0,-0.5) -- (0, 1.5) node[above] {$y$};
      \draw[-,domain=0:3,color=be-blue,thick] plot ({\x},{ 0.5 * exp( -0.5 * \x )});
      \draw[-,domain=0:3,color=be-red,thick] plot ({\x},{ 1 * exp( -1 * \x )});
    \end{tikzpicture}
    \caption{Limiting Ratio}\label{fig:limiting_ratio}
  \end{marginfigure}
  \begin{itemize}
    \item If $c = 0$, then $\bar{F}_X(x)$ decays faster than $\bar{F}_Y(x)$ as $x \to \infty$, i.e. $Y$ has a heavier tail than $X$;
    \item If $0 < c < \infty$, then $\bar{F}_X(x)$ and $\bar{F}_Y(x)$ decays at the smae rate, as $x \to \infty$, i.e. $X$ and $Y$ have similar tails;
    \item If $c = \infty$, then $\bar{F}_X(x)$ decays slower than $\bar{F}_Y(x)$ as $x \to \infty$, i.e. $X$ has a heavier tail than $Y$;
  \end{itemize}
  where we let
  \begin{equation*}
    c := \lim_{x \to \infty} \frac{\bar{F}_X(x)}{\bar{F}_Y(x)}
  \end{equation*}
\end{defn}

\begin{note}
  Not all distributions have an explicit survival function, but they will always have a pdf/pmf. Fortunately, by \hlnotea{L'H\^{o}pital's Rule}, the above definition can be applied to the pdfs of $X$ and $Y$, i.e.
  \begin{equation*}
    c = \lim_{x \to \infty} \frac{\bar{F}_X(x)}{\bar{F}_Y(x)} = \lim_{x \to \infty} \frac{-f_X(x)}{-f_Y(x)} = \lim_{x \to \infty} \frac{f_X(x)}{f_Y(x)}
  \end{equation*}
\end{note}

\begin{eg}
  Show that the Pareto distribution has a heavier tail than the Gamma distribution using limiting ratio.
\end{eg}

\begin{solution}
  Let $X \sim \Pareto(\alpha, \theta)$ and $Y \sim \Gam(\tau, \lambda)$. We have
  \begin{align*}
    c = \lim_{x \to \infty} \frac{f_X(x)}{f_Y(x)} &= \lim_{x \to \infty} \frac{\frac{\alpha \theta^{\alpha}}{{( x + \theta )}^{\alpha + 1}}}{\frac{x^{\tau - 1} e^{-\frac{x}{\lambda}}}{\lambda^\tau \Gamma(\tau)}} = \alpha \theta^\alpha \lambda^\tau \Gamma(\tau) \lim_{x \to \infty} \frac{e^{\frac{x}{\lambda}}}{x^{\tau - 1} {(x + \theta)}^{\alpha + 1}}
  \end{align*}
  Since the exponential term grows faster than the term in the denominator, we have $c = \infty$, i.e. $X$ has a heavier tail than $Y$, as required.
\end{solution}

\begin{eg}
  For two losses $X$ and $Y$, suppose that $f_X(x) = \frac{2}{\pi (1 + x^2)}$ and $f_Y(x) = \frac{1}{(1 + x^2)}$ for $x > 0$. Compare the tail heaviness of the two losses.
\end{eg}

\begin{solution}
  Notice that
  \begin{equation*}
    c = \lim_{x \to \infty} \frac{f_X(x)}{f_Y(y)} = \lim_{x \to \infty} = \frac{2}{\pi} < \infty,
  \end{equation*}
  i.e. $X$ and $Y$ have similar tails.
\end{solution}

% subsubsection limiting_ratio_survival_functions (end)

\subsubsection{Hazard Rate}%
\label{ssub:hazard_rate}
% subsubsection hazard_rate

\newthought{Recall} \cref{defn:hazard_rate_function}. We had
\begin{gather*}
  h(x) = \frac{f(x)}{\bar{F}(x)} = - \frac{d}{dx} \ln \bar{F}(x), \\
  h_X(x) \Delta x \approx P(X \leq x + \Delta x \mid X > x)
\end{gather*}
and the hazard rate function relates to the survival function as
\begin{equation*}
  \bar{F}(x) = e^{-\int_{-\infty}^{x} h(y) \dif{y} }.
\end{equation*}

Notice that
\begin{itemize}
  \item if the hazard rate function is a \hlnotea{decreasing} function, that implies that the probability of the occurrence of $X \leq x + \Delta x$ decreases given $X > x$, as $x$ increases, i.e. it is more likely that we have $X > x + \Delta x \mid X > x$. So $X$ has a \hlnotea{heavy tail}.
  \item if the hazard rate function is a \hlnotea{increasing} function, that implies that the probability of the occurrence of $X \leq x + \Delta x$ increases given $X > x$, as $x$ increases, i.e. it is less likely that $X > x + \Delta x \mid X > x$. So $X$ has a \hlnotea{light tail}.
\end{itemize}

\begin{defn}[Decreasing and Increasing Failure Rates]\index{Decreasing Failure Rate}\index{Increasing Failure Rate}\label{defn:decreasing_and_increasing_failure_rates}
  Let $X$ be a loss with hazard rate function $h_X$. We say that\sidenote{The following source claims that the \hlnotea{failure rate} and hazard rate are, in fact, not always interchangable terms: \url{https://nomtbf.com/2013/11/difference-hazard-failure-rate/}. Perhaps this is worth looking into.}
  \begin{itemize}
    \item $X$ or $F_X$ has a \hlnoteb{decreasing failure rate (DFR)} if $h_X$ is decreasing;
    \item $X$ or $F_X$ has a \hlnoteb{increasing failure rate (IFR)} if $h_X$ is increasing.
  \end{itemize}
\end{defn}

\begin{note}
  Consequently,
  \begin{itemize}
    \item Distributions that have a DFR are heavy-tailed;
    \item Distributions that have an IFR are light-tailed.
  \end{itemize}
\end{note}

\begin{propo}[Exponential has Constant Hazard Rate]\label{propo:exponential_has_constant_hazard_rate}
  The exponential distribution has a constant hazard rate.
\end{propo}

\begin{proof}
  The pdf and survival function of $X \sim \Exp(\lambda)$ is
  \begin{equation*}
    f_X(x) = \lambda e^{-\lambda x} \text{ and } \bar{F}_X(x) = e^{-\lambda x},
  \end{equation*}
  respectively. Thus the hazard rate of $X$ is
  \begin{equation*}
    h(x) = \frac{f_X(x)}{\bar{F}_X(x)} = \lambda,
  \end{equation*}
  which is a fixed value.\qed\
\end{proof}

\begin{note}
  We say that the exponential distribution is the only distribution which is said to have both DFR and IFR.\sidenote{\hlwarn{Why?}}
\end{note}

\begin{eg}
  Let $X \sim \Pareto(\alpha, \theta)$ with $f_X(x) = \frac{\alpha \theta^\alpha}{{(x + \theta)}^{\alpha + 1}}$ and $\bar{F}_X(x) = \frac{\theta^\alpha}{{(x + \theta)}^\alpha}$. Determine whether $X$ has a DFR or IFR.
\end{eg}

\begin{solution}
  The hazard rate function of $X$ is
  \begin{equation*}
    h_X(x) = \frac{f_X(x)}{\bar{F}_X(x)} = \frac{\frac{\alpha \theta^\alpha}{{(x + \theta)}^{\alpha + 1}}}{\frac{\theta^\alpha}{{(x + \theta)}^\alpha}} = \frac{\alpha}{x + \theta}.
  \end{equation*}
  It is clear that $h_X$ is a decreasing function, and so $X \sim \Pareto(\alpha, \theta)$ has a DFR, i.e.\ it is heavy-tailed.
\end{solution}

It is not always easy to get the survival function. The following is an alternative approach to finding out if the hazard rate function is increasing or decreasing.

\begin{propo}[Ratio Comparison for DFR/IFR]\label{propo:ratio_comparison_for_dfr_ifr}
  Let $X$ be an rv, and\sidenote{\hlwarn{Any bounds on $y$?}}
  \begin{equation*}
    s(x) = \frac{f_X(x + y)}{f_X(x)}.
  \end{equation*}
  \begin{enumerate}
    \item If $s(x)$ is increasing in $x$ for every $y$, then $X$ has a DFR;
    \item If $s(x)$ is decreasing in $x$ for every $y$, then $X$ has an IFR.
  \end{enumerate}
\end{propo}

\begin{proof}
  We shall prove for one case as the other will follow analogously. Notice that
  \begin{equation*}
    h_X(x) = \frac{f_X(x)}{\bar{F}_X(x)} = \frac{f_X(x)}{\int_{x}^{\infty} f_X(y) \dif{y}} = \frac{1}{\int_{0}^{\infty} \frac{f_X(x + y)}{f_X(x)}\dif{y} }
  \end{equation*}
  by a change of variable in the last equality. We notice that if $\frac{f_X(x + y)}{f_X(x)}$ is increasing, then $h_X(x)$ will be decreasing, and so $X$ has a DFR.\qed\
\end{proof}

\begin{eg}
  Let $X \sim \Gam(\alpha, \theta)$ with $\alpha > 1$. Determine whether $X$ is a DFR or IFR distribution.
\end{eg}

\begin{solution}
  The cdf of $X$ is
  \begin{equation*}
    f_X(x) = \frac{x^{\alpha - 1} e^{-\frac{x}{\theta}}}{\theta^\alpha \Gamma(\alpha)}.
  \end{equation*}
  The survival function of $X$ is not explicit, and so we should use \cref{propo:ratio_comparison_for_dfr_ifr}. We have
  \begin{align*}
    \frac{f_X(x + y)}{f_X(x)} = = \frac{ \frac{(x + y)^{\alpha - 1} e^{- \frac{x + y}{\theta}}}{\theta^{\alpha} \Gamma(\alpha)} }{\frac{ x^{\alpha - 1} e^{-\frac{x}{\theta}} }{\theta^\alpha \Gamma(\alpha)}} = \left( \frac{x + y}{x} \right)^{\alpha - 1} e^{-\frac{y}{\theta}} = \left( 1 + \frac{y}{x} \right)^{\alpha - 1} e^{-\frac{y}{\theta}}.
  \end{align*}
  To try to determine if it is increasing or decreasing, we calculate the second derivative of the ratio:
  \begin{marginfigure}
    \centering
    \begin{tikzpicture}
      \draw[->] (-0.5,0) -- (4, 0) node[right] {$x$};
      \draw[->] (0,-0.5) -- (0, 4) node[above] {$f(x)$};
      \draw[->,domain=0.2:4] plot ({\x},{(1 + ( 1 / \x )) * exp(-0.5)});
    \end{tikzpicture}
    \caption{Graph of $\left( 1 + \frac{y}{x} \right)^{\alpha - 1} e^{-\frac{y}{\theta}}$ for $y > -x$ and $x > 0$.}\label{fig:graph_of_left_1_y_x_right_alpha_1_e_y_theta_}
  \end{marginfigure}
  \begin{equation*}
    \frac{d}{dx} \left( 1 + \frac{y}{x} \right)^{\alpha - 1} e^{-\frac{y}{\theta}} = y (\alpha - 1)\left( 1 + \frac{y}{x} \right)^{\alpha - 2} e^{ -\frac{y}{\theta} }.
  \end{equation*}
  It is important to note that $y$ is not completely free: it is bounded below by $-x$, as if $y < -x$, then $x + y < 0$, and $f$ is undefined at these values. Also, if $y = -x$, then the ratio is simply a constant, and we cannot use \cref{propo:ratio_comparison_for_dfr_ifr} to reach a conclusion. To be able to use \cref{propo:ratio_comparison_for_dfr_ifr}, we must have $y > -x$. In this case, it is clear that the ratio is increasing as $x$ increases. Thus $X$ has an IFR.
\end{solution}

% subsubsection hazard_rate (end)

% subsection existence_of_moments_continued (end)

% section severity_distributions_tail_of_distributions_continued (end)

% chapter lecture_8_oct_02nd (end)

\chapter{Lecture 9 Oct 11th}%
\label{chp:lecture_9_oct_11th}
% chapter lecture_9_oct_11th

\section{Severity Distributions --- Tail of Distributions (Continued 2)}%
\label{sec:severity_distributions_tail_of_distributions_continued_2}
% section severity_distributions_tail_of_distributions_continued_2

\subsection{Mean Excess Loss}%
\label{sub:mean_excess_loss}
% subsection mean_excess_loss

\begin{defn}[Excess Loss Random Variable]\index{Excess Loss Random Variable}\label{defn:excess_loss_random_variable}
  For a loss rv $X$, we define the \hlnoteb{excess loss rv} as
  \begin{equation*}
    T_d = X - d \mid X > d, \quad d > 0.
  \end{equation*}
  The survival function of $T_d$ is
  \begin{align*}
    \bar{F}_{T_d}(x) &= P(T_d > x) = P(X - d > x \mid X > d) \\
                     &= \frac{P(X > x + d)}{P(X > d)} = \frac{\bar{F}_X(x + d)}{\bar{F}_X(d)}.
  \end{align*}
\end{defn}

As defined before in \cref{defn:mean_excess_loss},

\begin{defnnonum}[Mean Excess Loss]\index{Mean Excess Loss}
  The \hlnoteb{mean excess loss} (or \hldefn{mean residual life}) function is defined as\marginnote{Essentially, the mean excess loss is the average payment in excess of the threshold $d$, given that the loss exceeds the threshold. }
  \begin{equation*}
    e_X(d) = E[T_d] = \int_{0}^{\infty} \bar{F}_{T_d}(x) \dif{x} = \frac{\int_{0}^{\infty} \bar{F}_X(x + d) \dif{x}}{\bar{F}_X(d)} = \frac{\int_{d}^{\infty} \bar{F}_X(y) \dif{y} }{\bar{F}_X(d)}
  \end{equation*}
\end{defnnonum}

\begin{defn}[Increasing and Decreasing Mean Residual Lifetime]\index{Increasing Mean Residual Lifetime}\index{Decreasing Mean Residual Lifetime}\index{IMRL}\index{DMRL}\label{defn:increasing_and_decreasing_mean_residual_lifetime}
  Given a loss rv $X$,
  \begin{enumerate}
    \item we say $X$ or $F_X$ is an \hlnoteb{increasing mean residual lifetime (IMRL)} if $e_X(x)$ is increasing in $x$;
    \item we say $X$ or $F_X$ is an \hlnoteb{decreasing mean residual lifetime (DMRL)} if $e_X(x)$ is decreasing in $x$.
  \end{enumerate}
\end{defn}

\begin{note}
  \begin{itemize}
    \item IMRL distributions are \hlnotec{heavy-tailed};
    \item DMRL distributions are \hlnotec{light-tailed}.
  \end{itemize}

  The reason of this claim should be rather clear from the context of $e_X(x)$: if $e_X(x)$ is increasing with $x$, then we expect that the survival probability of $T_d$ to be greater, and so the tail should be a heavy one. The following proposition clarifies this notion.
\end{note}

\begin{propo}[Relation between DFR/IFR and IMRL/DMRL]\label{propo:relation_between_dfr_ifr_and_imrl_dmrl}
  A DFR rv is IMRL, and an IFR rv is a DMRL.
\end{propo}

\begin{proof}
  Suppose $X$ has a DFR. The mean excess loss of $X$ is
  \begin{equation*}
    e_X(d) = \frac{\int_{0}^{\infty} \bar{F}_X(x + d) \dif{x} }{\bar{F}_X(d)} = \int_{0}^{\infty} \frac{\bar{F}_X(x + d)}{\bar{F}_X(d)} \dif{x}.
  \end{equation*}
  Note that by the relationship between the survival function and the hazard rate\sidenote{We use the hazard rate here because it is provided by the assumption.},
  \begin{equation*}
    \frac{\bar{F}_X(x + d)}{\bar{F}_X(d)} = \frac{e^{-\int_{0}^{x + d} h_X(y) \dif{y} }}{e^{-\int_{0}^{d} h_X(y) \dif{y} }} = e^{-\int_{d}^{x + d} h_X(y) \dif{y} } = e^{-\int_{0}^{x} h_X(z + d) \dif{z} }.
  \end{equation*}
  Since $X$ has a DFR, $h_X$ is decreasing, and thus $\frac{\bar{F}_X(x + d)}{\bar{F}_X(d)}$ is increasing. Thus $e_X(d)$ is increasing and so $X$ is a IMRL, as required. THe argument is similar for $IFL$ being a $DMRL$.\qed\
\end{proof}

\begin{eg}
  Let $X \sim \Wei(\theta, \tau)$. Determine whether $X$ is DMRL or IMRL.
\end{eg}

\begin{solution}
  Since
  \begin{equation*}
    f_X(x) = \frac{\tau x^{\tau - 1} e^{-{\left( \frac{x}{\theta} \right)}^\tau}}{\theta^\tau}
  \end{equation*}
  and from \hyperref[note:weibull_survival_function]{an earlier example}, we have
  \begin{equation*}
    \bar{F}_X(x) = e^{- {\left( \frac{x}{\theta} \right)}^\tau}
  \end{equation*}
  Then the hazard rate is
  \begin{equation*}
    h_X(x) = \frac{f_X(x)}{\bar{F}_X(x)} = \frac{\tau}{\theta^\tau} x^{\tau - 1}.
  \end{equation*}
  Now if $\tau \geq 1$, then $h_X(x)$ is an increasing function, and so $X$ has an IFR, i.e. $X$ is a DMRL. if $0 < \tau \leq 1$, then $h_X(x)$ is a decreasing function, and so $X$ has a DFR, i.e. $X$ is an IMRL.
\end{solution}

\begin{eg}
  Consider a loss $X$ with $f_X(x) = (1 + 2x^2) e^{-2x}$ for $x > 0$.
  \begin{enumerate}
    \item Determine $h_X(x)$.
    \item Determine $e_X(x)$.
    \item Find $\lim\limits_{x \to \infty} h_X(x)$ and $\lim\limits_{x \to \infty} e_X(x)$.
    \item Show that $X$ is DMRL but not IFR.
  \end{enumerate}
\end{eg}

\begin{solution}
  Since both $h_X(x)$ and $e_X(x)$ require the survival function, we shall first derive that. Observe that\sidenote{It is highly recommended that one gets really used to using integration by parts, to the point that you do not have to repeatedly write down what the $u$ and $dv$ are explicitly every time.}
  \begin{align*}
    \bar{F}_X(x) &= \int_{x}^{\infty} (1 + 2y^2) e^{-2y} \dif{y} = \frac{1}{2} e^{-2x} + 2 \left[ \int_{x}^{\infty} y^2 e^{-2y} \dif{y} \right] \\
                 &= \frac{1}{2}e^{-2x} + 2 \left[ -\frac{1}{2} y^2 e^{-2y} \at{x}{\infty} + \int_{x}^{\infty} ye^{-2y} \dif{y} \right] \\
                 &= \frac{1}{2}e^{-2x} + x^2 e^{-2x} + 2 \left[ -\frac{1}{2}ye^{-2y} \at{x}{\infty} + \frac{1}{2} \int_{x}^{\infty} e^{-2y} \dif{y} \right] \\
                 &= \frac{1}{2}e^{-2x} + x^2 e^{-2x} + xe^{-2x} + \frac{1}{2}e^{-2x} \\
                 &= (x^2 + x + 1) e^{-2x}.
  \end{align*}
  \begin{enumerate}
    \item It is clear that
      \begin{align*}
        h_X(x) &= \frac{1 + 2x^2}{1 + x + x^2}
      \end{align*}

    \item By its definition, we have that
      \begin{equation*}
        e_X(x) = \frac{\int_{x}^{\infty} \bar{F}_X(y) \dif{y} }{\bar{F}_X(x)},
      \end{equation*}
      and so we need to solve for the integral in the numerator. Using pieces from our derivation of $\bar{F}_X(x)$, we obtain
      \begin{align*}
        &\int_{x}^{\infty} (1 + y + y^2) e^{-2y} \dif{y} \\
        &= \frac{1}{2}e^{-2x} + \frac{1}{2}xe^{-2x} + \frac{1}{4}e^{-2x} + \frac{1}{2}x^2 e^{-2x} + \frac{1}{2}xe^{-2x} + \frac{1}{4}e^{-2x} \\
        &= \left( 1 + x + \frac{1}{2}x^2 \right) e^{-2x}.
      \end{align*}
      Thus
      \begin{equation*}
        e_X(x) = \frac{1 + x + \frac{1}{2}x^2}{1 + x + x^2}.
      \end{equation*}

    \item The answers are straightforward\sidenote{\hlwarn{Find out why did we calculate these values.}}
      \begin{gather*}
        \lim_{x \to \infty} h_X(x) = \lim_{x \to \infty} \frac{\frac{1}{x^2} + 2}{1 + \frac{1}{x} + \frac{1}{x^2}} = 2 \\
        \lim_{x \to \infty} e_X(x) = \lim_{x \to \infty} \frac{\frac{1}{x^2} + \frac{1}{x} + \frac{1}{2}}{\frac{1}{x^2} + \frac{1}{x} + 1} = \frac{1}{2}
      \end{gather*}

    \item First, observe that
      \begin{align*}
        e_X'(x) &= \frac{(1 + x)\left( 1 + x + x^2 \right) - (1 + 2x)\left( 1 + x + \frac{1}{2}x^2 \right)}{(1 + x + x^2)} \\
                &= - \frac{x + \frac{1}{2}x^2}{(1 + x + x^2)^2},
      \end{align*}
      and we see that $e_X'(x) < 0$ for $x > 0$. Thus $X$ has a DMRL. For $h_X(x)$,
      \begin{align*}
        h_X'(x) &= \frac{4x \left( 1 + x + x^2 \right) - (1 + 2x) \left( 1 + 2x^2 \right)}{\left(1 + x + x^2\right)^2} \\
                &= \frac{2x^2 + 2x - 1}{x^4 + 2x^3 + 3x^3 + 2x + 1}.
      \end{align*}
      It may appear as if $h_X'(x)$ is positive, seeing that $x^4$ should dominate. However, notice that the \href{https://en.wikipedia.org/wiki/Quadratic_equation\#Discriminant}{discriminant} is positive:\sidenote{Lecture notes simply threw the values $1$ and $\frac{1}{2}$ for $x$ almost out of nowhere. While the result seems harmless, firstly, $x \neq 0$, since $x > 0$. In fact, since the critical point is $\sqrt{\frac{3}{4}} - \frac{1}{2} \approx 0.366$, $\frac{1}{2}$ is a value that comes after the critical point, so we would not have been able to verify without trying and failing numerous times, especially since the critical point is an irrational value.
      
      Here, we are smart and equipped with the knowledge that by solving the first derivative for $x$ by equating to $0$ allows us to find these critical points, which is indicative of a change from positive to negative, or vice versa, slope for $h_X(x)$.}
      \begin{equation*}
        2^2 - 4(2)(-1) = 12 > 0,
      \end{equation*}
      and so the numerator has a root, i.e. there are critical points on $h_X(x)$. In fact, equating the said numerator to $0$, we can obtain that $x = - \frac{1}{2} + \sqrt{\frac{3}{4}}$ (the other case is ruled out as $x > 0$). Since $h_X'(x)$ looks as if it is increasing, let's try out some values of $x$ for $0 < x < \sqrt{\frac{3}{4}} - \frac{1}{2}$. In particular, notice that
      \begin{gather*}
        h_X \left( \frac{1}{10} \right) = \frac{102}{111} \approx 0.9198 \\
        h_X \left( \frac{1}{5} \right) = \frac{27}{31} \approx 0.8710
      \end{gather*}
      but $\frac{1}{10} < \frac{1}{5}$, and so we notice that $X$ is not IFR.
  \end{enumerate}
\end{solution}

% subsection mean_excess_loss (end)

% section severity_distributions_tail_of_distributions_continued_2 (end)

% chapter lecture_9_oct_11th (end)

\chapter{Lecture 10 Oct 16th}%
\label{chp:lecture_10_oct_16th}
% chapter lecture_10_oct_16th

\section{Severity Distributions --- Policy Adjustments (Continued)}%
\label{sec:severity_distributions_policy_adjustments_continued}
% section severity_distributions_policy_adjustments_continued

Insurance policies contain various \hlnotea{adjustments} to soften the amount that insurers have to pay, to minimize moral hazards, and for various other reasons. In this section, we shall introduce some common policy adjustments.

In the following definitions, suppose that $X$ is our ground-up loss rv, and $H$ a function incurred by the adjustment.

\begin{defn}[Policy Limit]\index{Policy Limit}\label{defn:policy_limit}
  A fixed level $u > 0$ is called a \hlnoteb{policy limit} if, provided that there are no other adjustments, the insurer shall pay\sidenote{Now that this definition uses the symbol $\land$ for denoting a policy limit, I shall refrain from using the same symbol in proofs, unless if the context is clear.}
  \begin{equation*}
    H(X) = \min \{ X, u \} := X \land u = \begin{cases}
      X & X \leq u \\
      u & X \geq u
    \end{cases}.
  \end{equation*}
  \begin{marginfigure}
    \centering
    \begin{tikzpicture}
      \draw[->] (-0.5,0) -- (4,0) node[right] {$x$};
      \draw[->] (0,-0.5) -- (0,4) node[above] {$F(x)$};
      \draw[->,thick] (0, 0) -- (2, 3) -- (4, 3);
      \draw[dashed] (2, 3) -- (0, 3) node[left] {$u$};
    \end{tikzpicture}
    \caption{Typical graph of a policy limit, without other adjustments.}\label{fig:typical_graph_of_a_policy_limit_}
  \end{marginfigure}
\end{defn}

\begin{note}
  \begin{itemize}
    \item A policy limit protects the insurer from overly large losses.
    \item This is \hlimpo{noteworthy}: in practice, a policy limit may refer to \hlnotea{the maximum amount paid} by the insurer, but in this course, it is the \hlnotea{maximum loss} coverred by the insurer.
  \end{itemize}
\end{note}

\begin{defn}[Ordinary Deductible]\index{Ordinary Deductible}\label{defn:ordinary_deductible}
  A fixed level $d > 0$ is called an \hlnoteb{ordinary deductible} if, given that there are no other adjustments, the insurer pays
  \begin{marginfigure}
    \begin{tikzpicture}
      \draw[->] (-0.5,0) -- (3,0) node[right] {$x$};
      \draw[->] (0,-0.5) -- (0,3) node[above] {$F(x)$};
      \draw[->,thick] (-0.5,0) -- (1, 0) -- (3, 2) node[right] {$H(X)$};
      \node[below] at (1, 0) {$d$};
    \end{tikzpicture}
    \caption{Graph of a policy with ordinary deductible without any other adjustments.}\label{fig:graph_of_a_policy_with_ordinary_deductible_without_any_other_adjustments}
  \end{marginfigure}
  \begin{equation*}
    Y = H(X) = {(X - d)}_+ = X \lor d = \begin{cases}
      0     & X < d \\
      X - d & X \geq d
    \end{cases}
  \end{equation*}
\end{defn}

\begin{note}
  \begin{itemize}
    \item For any given loss, the first $d$ dollars falls on the insured.
    \item It is a protection against frequent small claims.
  \end{itemize}
\end{note}

\begin{defn}[Franchise Deductible]\index{Franchise Deductible}\label{defn:franchise_deductible}
  A fixed level $d > 0$ is called a \hlnoteb{Franchise Deductible} if, given that there are no other adjustments, the insurer pays
  \begin{marginfigure}
    \begin{tikzpicture}
      \draw[->] (-0.5,0) -- (3,0) node[right] {$X$};
      \draw[->] (0,-0.5) -- (0,3) node[above] {$Y$};
      \draw[-,thick] (-0.5,0) -- (1, 0);
      \draw[->,thick] (1, 1) -- (2.7, 2.7) node[right] {$H(X)$};
      \draw[dotted] (1, 1) -- (1, 0) node[below] {$d$};
    \end{tikzpicture}
    \caption{Graph of a policy with Franchise deductible without any other adjustments.}\label{fig:graph_of_a_policy_with_franchise_deductible_without_any_other_adjustments}
  \end{marginfigure}
  \begin{align*}
    H(X) &= X \cdot \mathbb{1}_{\{ X > d \}} = \begin{cases}
      0 & X \leq d \\
      X & X > d
    \end{cases} \\
    &= (X - d) \mathbb{1}_{\{X > d\}} + d \cdot \mathbb{1}_{\{ X > d\}} \\
    &= {(X - d)}_+ + d \cdot \mathbb{1}_{\{X > d\}}
  \end{align*}
\end{defn}

\begin{note}
  \begin{itemize}
    \item This differs from the ordinary deductible in that twhen the loss exceeds $d$, the deductible is waived and the \hlnotec{full loss is paid} by the insurer.
    \item We are not concerned with whether the payment goes out or not at $X = d$ in this course.\sidenote{In the event that a problem of such a nature comes out in either exercises or exams, the point will be explicitly stated.}
  \end{itemize}
\end{note}

\begin{remark}
  This is not a good adjustment as it is prone to \hlnotea{moral hazard}.
\end{remark}

\begin{defn}[Coinsurance]\index{Coinsurance}\label{defn:coinsurance}
  A fixed rate $\alpha \in [0, 1]$ is called a \hlnoteb{coinsurance factor} if, given that there are no other adjustments, the insurer pays
  \begin{marginfigure}
    \begin{tikzpicture}
      \draw[->] (-0.5,0) -- (3,0) node[right] {$X$};
      \draw[->] (0,-0.5) -- (0,3) node[above] {$Y$};
      \draw[->,thick] (0, 0) -- (3, 3) node[right] {$H(X)$};
      \draw[latex'-] (1.2,1.5) -- (0.7,2) node[above] {slope $= \alpha$};
    \end{tikzpicture}
    \caption{Graph of a policy with coinsurance without any other adjustments.}\label{fig:graph_of_a_policy_with_coinsurance_without_any_other_adjustments}
  \end{marginfigure}
  \begin{equation*}
    H(X) = \alpha X.
  \end{equation*}
  For any given loss, the \hlnotec{insurer pays a proportion $100\alpha\%$} of the loss amount the remaining $100(1 - \alpha)\%$ falls on the insured.
\end{defn}

\subsection{Application Order for Multiple Adjustments}%
\label{sub:application_order_for_multiple_adjustments}
% subsection application_order_for_multiple_adjustments

\newthought{If an insurance policy} has more than one adjustment, we assume the adjustments in the following order:
\begin{itemize}
  \item Policy limit (if any)
  \item Policy/ordinary deductible (if any)
  \item Coninsurance (if any)
\end{itemize}

\begin{note}
  \begin{itemize}
    \item These transformations are not necessarily commutative, so the order must be obeyed.
    \item This ordering is optimal, i.e.\ it covers for all possible combinations, i.e.\ any other ways of adjustment can be expressed in this form.\sidenote{Claimed by lecturer. Require example.}
    \item If $d$ is a deductible and $u$ the policy limit, we must have that $d < u$, since if $u < d$, then the insurer will only pay the maximum amount $u$ if the loss exeeds $d$, which is absurd. Therefore, for all of the cases that we shall consider, we will always assume, and safely so, that $d < u$.
  \end{itemize}
\end{note}

Applying the ordering, we have
\begin{equation*}
  X \to X \land u \to {[ (X \land u) - d ]}_+ \to \alpha {[ ( X \land u ) - d ]}_+
\end{equation*}
\begin{marginfigure}
  \begin{tikzpicture}
    \draw[->] (-0.5,0) -- (3,0) node[right] {$X$};
    \draw[->] (0,-0.5) -- (0,3) node[above] {$Y$};
    \draw[-latex',thick] (-0.5,0) -- (1, 0) -- (2, 2) -- (3, 2) node[right] {$H(X)$};
    \draw[dotted] (2, 2) -- (0, 2) node[left] {$\alpha(u - d)$};
    \node[left] at (1.5,1) {slope $\alpha$};
    \node[below] at (1, 0) {$d$};
    \draw[dotted] (2, 2) -- (2, 0) node[below] {$u$};
  \end{tikzpicture}
  \caption{Graph of $H(X) = \alpha{[ (X \land u) - d ]}_+$.}\label{fig:graph_of_mutiple_adjustments}
\end{marginfigure}
and so
\begin{equation*}
  H(X) = \alpha {[ (X \land u) - d ]}_+ = \begin{cases}
    0               & X < d \\
    \alpha( X - d ) & d \leq X < u \\
    \alpha( u - d ) & X \geq u
  \end{cases}
\end{equation*}

For the case of applying \hlnotea{Franchise deductible} instead of ordinary deductible, we have
\begin{equation*}
  X \to X \land u \to ( X \land u ) \mathbb{1}_{\{X > d\}} \to \alpha(X \land u) \cdot \mathbb{1}_{\{X > d\}}
\end{equation*}
\begin{marginfigure}
  \begin{tikzpicture} \draw[->] (-0.5,0) -- (3,0) node[right] {$X$};
    \draw[->] (0,-0.5) -- (0,3) node[above] {$Y$};
    \draw[-latex',thick] (1,1) -- (2, 2) -- (3, 2) node[right] {$H(X)$};
    \draw[dotted] (0,0) -- (1,1);
    \draw[dotted] (2, 2) -- (0, 2) node[left] {$\alpha(u - d)$};
    \node[left] at (1.5,1.5) {slope $\alpha$};
    \draw[dotted] (1, 1) -- (1, 0) node[below] {$d$};
    \draw[dotted] (2, 2) -- (2, 0) node[below] {$u$};
  \end{tikzpicture}
  \caption{Graph of $H(X) = \alpha( X \land u ) \cdot \mathbb{1}_{\{X > d\}}$.}\label{fig:graph_of_mutiple_adjustments_with_franchise_deductible}
\end{marginfigure}
Notice that $X \land u \to (X \land u) \mathbb{1}_{\{X > d\}}$, since $X \land u > d$ is simply $X > d$ as $u > d$ by assumption. We have that for the case where we consider the Franchise deductible instead of an ordinary deductible,
\begin{equation*}\label{eq}
  H(X) = \alpha( X \land u ) \cdot \mathbb{1}_{\{X > d\}} = \begin{cases}
    0        & X < d \\
    \alpha X & d \leq X < u \\
    \alpha u & X \geq u
  \end{cases}
\end{equation*}

% subsection application_order_for_multiple_adjustments (end)

\subsection{\imponote\ Reporting Methods}%
\label{sub:reporting_methods}
% subsection reporting_methods

When we consider the amount paid by the insurer, we typically consider (and distinguish) between two types of reporting methods.
\begin{itemize}
  \item \hldefn{Loss basis}: $Y_L =$ amount paid per loss
  \item \hldefn{Payment basis}: $Y_P =$ amount paid per payment
\end{itemize}
It is sensible that
\begin{equation}\label{eq:relationship_of_YP_and_YL}
  Y_P = Y_L \mid Y_L > 0.
\end{equation}

The above relationship shows that we can retrieve $Y_P$ from $Y_L$, i.e. $Y_L$ holds more information than $Y_P$. This makes sense; a loss may occur, but the insurer may not have to pay for the loss. For example, if the incurred loss is below a given deductible level.

\subsubsection{Loss Basis}%
\label{ssub:loss_basis}
% subsubsection loss_basis

\begin{itemize}
  \item Each loss is recorded, i.e. each loss has an entry, even if the amount paid is $0$.
  \item For a policy limit $u$, ordinary deductible $d$ with $d < u$ \sidenote{It would be silly if $d > u$.}, and coinsurance factor $\alpha$, we have
    \begin{equation*}
      Y_L = \alpha [ ( X \land u ) - d ]_+.
    \end{equation*}
  \item For a policy with limit $u$, Franchise deductible $d$ with $d < u$, and coinsurance factor $\alpha$, we have
    \begin{equation*}
      Y_L = \alpha (X \land u) \mathbb{1}_{\{ X > d \}}.
    \end{equation*}
  \item Note that in the presence of a deductible $d$, it is \hlnotec{usually the case} that $Y_L$ has a probability mass at $0$, i.e.
    \begin{equation*}
      P(Y_L = 0) = P(X \leq d) = F_X(d) > 0.
    \end{equation*}
    In this case, $Y_P > 0$ almost surely.
\end{itemize}

% subsubsection loss_basis (end)

\subsubsection{Payment Basis}%
\label{ssub:payment_basis}
% subsubsection payment_basis

\begin{itemize}
  \item Only \hlnotea{non-zero} payments of the insurer are included, and so not every loss will have an entry. Here, we see that $Y_P$ leaves that information behind.\sidenote{It is still useful to reporting purely on the financial effects of the claims.}
  \item $Y_P$ does not have a probability mass at $0$ (\hlwarn{Why}?), i.e.
    \begin{equation*}
      P(Y_P = 0) = 0,
    \end{equation*}
    or equivalently,
    \begin{equation*}
      Y_P > 0.
    \end{equation*}
\end{itemize}

% subsubsection payment_basis (end)

\begin{eg}
  Let $X$ be the ground-up loss rv and assume that there is an ordinary deductible of $5$ applied to the loss. The following table is a typical example illustrating how $Y_L$ and $Y_P$ works.
  \begin{table}[ht]
    \centering
    \caption{Example illustrating the relationship between $Y_P$ and $Y_L$.}
    \label{tab:example_for_yp_and_yp}
    \begin{tabular}{c | c c c c c c}
    \toprule
    $X$   & 3  & 2  & 5  & 7 & 9 & 10 \\
    \midrule
    $Y_L$ & 0  & 0  & 0  & 2 & 4 & 5 \\
    $Y_P$ & NA & NA & NA & 2 & 4 & 5 \\
    \bottomrule
    \end{tabular}
  \end{table}
\end{eg}

% subsection reporting_methods (end)

% section severity_distributions_policy_adjustments_continued (end)

% chapter lecture_10_oct_16th (end)

\chapter{Lecture 11 Oct 18th}%
\label{chp:lecture_11_oct_18th}
% chapter lecture_11_oct_18th

\section{Severity Distribution --- Policy Adjustments (Continued 2)}%
\label{sec:severity_distribution_policy_adjustments_continued_2}
% section severity_distribution_policy_adjustments_continued_2

\subsection{Distribution \& Moments of $Y_P$ and $Y_L$}%
\label{sub:distribution_n_moments_of_y_p_and_y_l_}
% subsection distribution_n_moments_of_y_p_and_y_l_

It suffices for us to closely study $Y_L$ due to the following proposition:

\begin{propo}[$Y_P$ is completely determined by $Y_L$]\label{propo:_y_p_is_completely_determined_by_y_l_}
  The survival function and moments of $Y_P$ are given by
  \begin{equation*}
    \bar{F}_{Y_P}(y) = \begin{cases}
      1                                         & y < 0 \\
      \frac{\bar{F}_{Y_L}(y)}{\bar{F}_{Y_L}(0)} & y \geq 0
    \end{cases}
  \end{equation*}
  and
  \begin{equation*}
    E \left[ Y_P^k \right] = \frac{E \left[ Y_L^k \right]}{\bar{F}_{Y_L}(0)}, \quad k = 1, 2, \ldots .
  \end{equation*}
\end{propo}

\begin{proof}
  Using the definition of a survival function, we have
  \begin{align*}
    \bar{F}_{Y_P}(x) = P(Y_P > x) = P(Y_L > x \mid Y_L > 0) = \begin{cases}
      1                                         & x < 0 \\
      \frac{\bar{F}_{Y_L}(x)}{\bar{F}_{Y_L}(0)} & x \geq 0
    \end{cases}.
  \end{align*}
  Consequently,
  \begin{equation*}
    e \left[ Y_P^k \right] = k \int_{0}^{\infty} x^{k - 1} \bar{F}_{Y_P}(x) \dif{x} = k \int_{0}^{\infty} x^{k - 1} \frac{\bar{F}_{Y_L}(x)}{\bar{F}_{Y_L}(0)} \dif{x} = \frac{E \left[ Y_L^k \right]}{\bar{F}_{Y_L}(0)}.
  \end{equation*}\qed\
\end{proof}

\begin{note}
  \cref{propo:_y_p_is_completely_determined_by_y_l_} tells us that it suffices to discover the distribution of $Y_L$, since it completely determines $Y_P$,
\end{note}

\begin{remark}
  \begin{itemize}
    \item If there is a deductible $d > 0$, then the distributions of $Y_P$ and $Y_L$ are \hlnotea{usually}\sidenote{This depends on the distribution of $X$ and $Y_L$.} different.
    \item If $Y_L$ has no mass point at $0$, i.e. $\bar{F}_{Y_L}(0) = 1$, then $Y_P$ nand $Y_L$ have the same distribution.
  \end{itemize}
\end{remark}

% subsection distribution_n_moments_of_y_p_and_y_l_ (end)

\subsection{Some Important Identities}%
\label{sub:some_important_identities}
% subsection some_important_identities

The following proposition is important for us to venture forward.

\begin{propo}[\vimponote\ Expected Value of the Policy Adjustments]\label{propo:expected_value_of_the_policy_adjustments}
  Consider a non-negative rv $X$ and $d > 0$. Then
  \begin{enumerate}
    \item We have
      \begin{equation*}
        E[X] = E[ [ X - d ]_+ ] + E[ X \land d ].
      \end{equation*}
    \item For $k = 1, 2, \ldots$,\label{item:expected_value_of_policy_adjustment_base}
      \begin{equation*}
        E \left[ X^k \right] = \int_{0}^{\infty} x^{k - 1} \bar{F}_X(x) \dif{x}.
      \end{equation*}
    \item For $k = 1, 2, \ldots$,
      \begin{equation*}
        E\left[ ( X \land d )^k \right] = \int_{0}^{d} kx^{k - 1}\bar{F}_X(x) \dif{x} .
      \end{equation*}
    \item For $k = 1, 2, \ldots$,
      \begin{equation*}
        E \left[ [ X - d ]_+^k \right] = \int_{d}^{\infty} k ( x - d )^{k - 1} \bar{F}_X(x) \dif{x}.
      \end{equation*}
    \item For $k = 1, 2, \ldots$, and $\bar{F}_X(d) > 0$,
      \begin{equation*}
        E \left[ ( X - d )^k \mid X > d \right] = \frac{E \left[ [ X - d ]_+^k \right]}{\bar{F}_X(d)} = \frac{\int_{d}^{\infty} k( x -  d )^{k - 1} \bar{F}_X(x) \dif{x} }{\bar{F}_X(d)}.
      \end{equation*}
      In particular, we have an alternate way to derive the mean excess value
      \begin{equation*}
        e_X(d) = E \left[ X - d \mid X > d \right] = \frac{\int_{d}^{\infty} \bar{F}_X(x) \dif{x}}{\bar{F}_X(d)}.
      \end{equation*}
  \end{enumerate}
\end{propo}

\begin{proof}
  \begin{enumerate}
    \item For this identity, notice that
      \begin{equation*}
        [ X - d ]_+ + ( X \land d ) = \begin{cases}
          0 + X     & X \leq d \\
          X - d + d & X > d
        \end{cases} = X.
      \end{equation*}
      The result follows from linearity of $E$.

    \item We have proved this earlier on, but it shall be re-proved for exercise, variety, and ease of reference.\sidenote{\hlimpo{Important}: There are two rules that you must use, and it does not depend on any of your existing knowledge as an undergrad whatsoever.
      \begin{enumerate}
        \item Notice that $\frac{d}{dx}F_X(x) = f_X(x) \implies - d\bar{F}_X(x) = f_X(x) \dif{x}$;
        \item While using integration by parts, let $dv = d\bar{F}_X(x)$ so that $v = \bar{F}_X(x)$.
      \end{enumerate}
      Forget any one of these are prepare to be screwed over.}
      \begin{align*}
        E \left[ X^k \right] &= \int_{0}^{\infty} x^k f_X(x) \dif{x} = \int_{0}^{\infty} x^k \frac{d}{dx} F_X(x) \dif{x} \\
                             &= \int_{0}^{\infty} x^k d F_X(x) = \int_{0}^{\infty} x^k d( 1 - \bar{F}_X(x) ) \\
                             &= - \int_{0}^{\infty} x^k d \bar{F}_X(x) \\
                             &= - x^k \bar{F}_X(x) \at{0}{\infty} + k \int_{0}^{\infty} x^{k - 1} \bar{F}_X(x) \dif{x} \quad \because \text{ IBP } \\
                             &= k \int_{0}^{\infty} x^{k - 1} \bar{F}_X(x) \dif{x},
      \end{align*}
      under the assumption that $\bar{F}_X(x)$ decays faster than $x^k$ \sidenote{How unlikely is this, I do not know.}.

    \item Using a similar argument as in the earlier part of the last proof, and by the Law of the Unconscious Statistician, we can arrive at
      \begin{equation*}
        E \left[ ( X \land u )^k \right] = - \int_{0}^{\infty} (x \land u)^k \dif{\bar{F}_X(x)}.
      \end{equation*}
      To proceed, use integration by parts as follows\sidenote{This is hopeless. \hlimpo{If you can't remember this}, or somehow make some sense of this monster (without going through a few lectures on Lesbesgue or Riemann-Stieljes integration), \hlimpo{you're screwed.} }:
      \begin{gather*}
        u = ( x \land u )^k \quad v = \bar{F}_X(x) \\
        du = d(x \land u)^k \quad dv = d\bar{F}_X(x)
      \end{gather*}
      We get
      \begin{equation*}
        E \left[ ( X \land u )^k \right] = - (x \land u)^k \bar{F}_X(x) \at{0}{\infty} + \int_{0}^{\infty} \bar{F}_X(x) \dif{( x \land u )^k},
      \end{equation*}
      and $(x \land u)^k \bar{F}_X(x) \at{0}{\infty} = 0$. Next, it is a ``fact'' that
      \begin{equation*}
        d ( x \land u )^k = \begin{cases}
          k x^{k - 1} \dif{x} & x < u \\
          0                   & x \geq u
        \end{cases}
      \end{equation*}
      \sidenote{This is yet another monstrosity that makes no sense whatsoever for one that has only taken basic Calculus classes and introductory Analysis. \hlimpo{Remember this ``fact''} or \hlimpo{get screwed over}. The only ``sense'' that I can come up with right now is to consider the cases of when $x < u$ and when $x \geq u$, and determine what $x \land u$ should be in these cases, and provide some baseless rationalization.}Since $x > u$ gives us a $0$ term, we are left with
      \begin{equation*}
        E \left[ (X \land u)^k \right] = \int_{0}^{u} k x^{k-1} \bar{F}_X(x) \dif{x}.
      \end{equation*}
      
    \item Using the Law of the Unconscious Statistician and \cref{item:expected_value_of_policy_adjustment_base}, we have
      \begin{equation*}
        E \left[ [ X - d ]_+^k \right] = k \int_{0}^{\infty} (x - d)_+^k \bar{F}_X(x) \dif{x} = k \int_{d}^{\infty} (x - d)^k \bar{F}_X(x) \dif{x}.
      \end{equation*}

    \item Notice once and for all that
      \begin{align*}
        E \left[ (X - d)^k \mid X > d \right] &= \frac{E \left[ (X - d)^k \mathbb{1}_{\{ X > d \}} \right]}{\bar{F}_X(d)} \\
                                              &= \frac{E \left[ [ X - d ]_+^k \right]}{\bar{F}_X(d)} = \frac{\int_{d}^{\infty} k (x - d)^k \bar{F}_X(x) \dif{x}}{\bar{F}_X(d)}.
      \end{align*}
  \end{enumerate}\qed\
\end{proof}

\begin{eg}
  Consider a ground-up loss $X$ with pdf
  \begin{equation*}
    f_X(x) = 0.0005, \quad 0 \leq x \leq 20.
  \end{equation*}
  Solve for
  \begin{enumerate}
    \item $\bar{F}_X(x)$;
    \item $E [ X \land 10 ]$ and $E[ X \land 25 ]$;
    \item $\Var(X \land 10)$;
    \item $E \left[ [ X - 10 ]_+ \right]$;
    \item $E \left[ [ X - 10 ]_+^2 \right]$; and
    \item $e_X(10)$.
  \end{enumerate}
\end{eg}

\begin{solution}
  \begin{enumerate}
    \item We have
      \begin{equation*}
        F_X(x) = \int_{0}^{x} 0.005y \dif{y} = 0.0025x^2
      \end{equation*}
      and so
      \begin{equation*}
        \bar{F}_X(x) = \begin{cases}
          1             & x < 0 \\
          1 - 0.0025x^2 & 0 \leq x \leq 20 \\
          0             & x > 20
        \end{cases}.
      \end{equation*}

    \item Using our identities,
      \begin{equation*}
        E [ X \land 10 ] = \int_{0}^{10} \bar{F}_X(x) \dif{x} = 10 - \frac{5}{6000} (10)^3 = \frac{55}{6},
      \end{equation*}
      and
      \begin{equation*}
        E [ X \land 25 ] = \int_{0}^{20} \bar{F}_X(x) \dif{x} = 25 - \frac{5}{6000} (25)^3 = \frac{40}{3}.
      \end{equation*}
    \item To get $\Var(X \land 10)$, we first need the 2nd moment of $X \land 10$:
      \begin{align*}
        E \left[ \left( X \land 10 \right)^2 \right] &= 2 \int_{0}^{10} x \bar{F}_X(x) \dif{x} = 2 \left[ \frac{1}{2} x^2 - \frac{5}{8000} x^4 \right]_{0}^{10} \\
                                                     &= 100 - \frac{25}{2} = \frac{175}{2}.
      \end{align*}
      Thus
      \begin{equation*}
        \Var \left( X \land 10 \right) = \frac{175}{2} - \left( \frac{55}{6} \right)^2 = \frac{125}{36}.
      \end{equation*}

    \item We have that
      \begin{align*}
        E \left[ [ X - 10 ]_+ \right] &= \int_{10}^{20} 1 - \frac{1}{400}x^2 \dif{x} \\
                                      &= 10 - \frac{1}{1200} (8000 - 1000) = \frac{25}{6}.
      \end{align*}

    \item We have that
      \begin{align*}
        E \left[ [ X - 10 ]_+^2 \right] &= 2 \int_{10}^{20} ( x - 10 ) \left( 1 - \frac{1}{400}x^2 \right) \dif{x} \\
                                        &= 2 \int_{10}^{20} \left( -10 + x + \frac{1}{40} x^2 - \frac{1}{400} x^3 \right) \dif{x} \\
                                        &= 2 \left[ -100 + \frac{300}{2} + \frac{7000}{120} - \frac{150000}{1600} \right] \\
                                        &= \frac{175}{6}
      \end{align*}

    \item We have
      \begin{equation*}
        e_X(10) = \frac{\int_{10}^{20} \left( 1 - \frac{1}{400} x^2 \right) \dif{x}}{1 - \frac{1}{400} (10)^2} = \frac{10 - \frac{7000}{1200}}{\frac{3}{4}} = \frac{50}{9}
      \end{equation*}
  \end{enumerate}
\end{solution}

\subsubsection{Application of \cref{propo:expected_value_of_the_policy_adjustments}}%
\label{ssub:application_of_expected_value_of_the_policy_adjustments}
% subsubsection application_of_expected_value_of_the_policy_adjustments

\paragraph{Policy Limit} If a policy limit $u$ is the only adjustment in a contract, then
\begin{equation*}
  Y_L = X \land u \quad \text{ and } \quad Y_P = X \land u \mid X > 0.
\end{equation*}
Since in most cases $X > 0$, we have that $\bar{F}_X(0) = 1$, and so $Y_L = Y_P = X \land u$.
\begin{itemize}
  \item The survival function is
    \begin{equation*}
      \bar{F}_{Y_P} (y) = \bar{F}_{Y_L} (y) = P ( X \land u > y ) = \begin{cases}
        1            & y < 0 \\
        \bar{F}_X(y) & 0 \leq y < u \\
        0            & y \geq u
      \end{cases}
    \end{equation*}
  \item The expected value is
    \begin{equation*}
      E \left[ Y_P \right] = E \left[ Y_L \right] = E [ X \land u ] = \int_{0}^{u} \bar{F}_X(x) \dif{x}.
    \end{equation*}
  \item The second moment is
    \begin{equation*}
      E \left[ Y_P^2 \right] = E \left[ Y_L^2 \right] = E \left[ (X \land u)^2 \right] = 2 \int_{0}^{u} x \bar{F}_X(x) \dif{x}
    \end{equation*}
\end{itemize}

\paragraph{Ordinary Deductible} If an ordinary deductible $d$ is the only adjustmnet in a contract, then
\begin{equation*}
  Y_L = [ X - d ]_+ = (X - d) \mathbb{1}_{\{X > d\}}
\end{equation*}
and
\begin{equation*}
  Y_P = [ X - d ]_+ \mid [ X - d ]_+ > 0 = ( X - d ) \mathbb{1}_{\{X > d\}} \mid X > d = X - d \mid X > d
\end{equation*}
In most cases, since $\bar{F}_X(d) = P(X > d) < 1$ as it is $P(X < d) \neq 0$, the distribution of $Y_L$ and $Y_P$ differs.
\begin{itemize}
  \item The survival function is
    \begin{equation*}
      \bar{F}_{Y_L}(y) = P( [ X - d ]_+ > y ) = \begin{cases}
        1 & y < 0 \\
        \bar{F}_X(y + d) & y \geq 0
      \end{cases}
    \end{equation*}
    and
    \begin{equation*}
      \bar{F}_{Y_P}(y) = \frac{\bar{F}_{Y_L}(y)}{\bar{F}_{Y_L}(0)} = \begin{cases}
        1                                       & y < 0 \\
        \frac{\bar{F}_{X}(d + y)}{\bar{F}_X(d)} & y \geq 0
      \end{cases}
    \end{equation*}
    for $Y_L$ and $Y_P$ respectively.

  \item The mean is
    \begin{equation*}
      E \left[ Y_L \right] = E \left[ [ X - d ]_+ \right] = \int_{d}^{\infty} \bar{F}_X(x) \dif{x}
    \end{equation*}
    and
    \begin{equation*}
      E \left[ Y_P \right] = E \left[ X - d \mid X > d \right] = \frac{E [ (X - d) \mathbb{1}_{\{X > d\}} ]}{\bar{F}_X(d)} = \frac{\int_{d}^{\infty} \bar{F}_X(x) \dif{x}}{\bar{F}_X(d)}
    \end{equation*}
    for $Y_L$ and $Y_P$ respectively.

  \item The second moment is
    \begin{equation*}
      E \left[ Y_L^2 \right] = E \left[ [ X - d ]_+^2 \right] = 2 \int_{d}^{\infty} x \bar{F}_X(x) \dif{x}
    \end{equation*}
    and
    \begin{equation*}
      E \left[ Y_P^2 \right] = \frac{E \left[ Y_L^2 \right]}{\bar{F}_{Y_L}(0)} = \frac{2 \int_{d}^{\infty} x \bar{F}_X(x) \dif{x}}{\bar{F}_X(d)}
    \end{equation*}
    for $Y_L$ and $Y_P$ respectively.
\end{itemize}

% subsubsection application_of_expected_value_of_the_policy_adjustments (end)

% subsection some_important_identities (end)

% section severity_distribution_policy_adjustments_continued_2 (end)

% chapter lecture_11_oct_18th (end)

\chapter{Lecture 12 Oct 23rd}%
\label{chp:lecture_12_oct_23rd}
% chapter lecture_12_oct_23rd

\section{Severity Distribution --- Policy Adjustments (Continued 3)}%
\label{sec:severity_distribution_policy_adjustments_continued_3}
% section severity_distribution_policy_adjustments_continued_3

\subsection{Some Important Identities (Continued)}%
\label{sub:some_important_identities_continued}
% subsection some_important_identities_continued

\subsubsection{Application of \cref{propo:expected_value_of_the_policy_adjustments} (Continued)}%
\label{ssub:application_of_expected_value_of_the_policy_adjustments_continued}
% subsubsection application_of_expected_value_of_the_policy_adjustments_continued

\paragraph{Policy Limit + Ordinary Deductible} If there is a policy limit $u$ and an ordinary deductible $d$ with $u > d$, then
\begin{equation*}
  Y_L = [ ( X \land u ) - d ]_+ = \begin{cases}
    0 & X < d \\
    X - d & d \leq X < u \\
    u - d & X \geq u
  \end{cases}
\end{equation*}
and so its survival function is\sidenote{\hlimpo{Important}: Pay attention to the notion here: we are using the actual definition of a deductible to arrive at an explicit solution.}
\begin{align*}
  \bar{F}_{Y_L}(y) & = P ( Y_L > y ) = P ( [ (X \land u) - d ]_+ > y ) \\
                   & = P ( \max\{ 0, (X \land u) - d \} > y ) \\
                   & = \begin{cases}
                     1                        & y < 0 \\
                     P( (X \land u) - d > y ) & y \geq 0
                   \end{cases} \\
                   &= \begin{cases}
                     1            & y < 0 \\
                     P(X > y + d) & 0 \leq y < u - d \\
                     P(u > y + d) & y \geq u - d
                   \end{cases} \\
                   &= \begin{cases}
                     1                & y < 0 \\
                     \bar{F}_X(y + d) & 0 \leq y < u - d \\
                     0                & y \geq u - d
                   \end{cases}
\end{align*}
Consequently, its moments are
\begin{align*}
  E \left[ Y_L^k \right] &= \int_{0}^{\infty} k y^{k - 1} \bar{F}_{Y_L}(y) \dif{y} \\
                         &= \int_{0}^{u - d} k y^{k - 1} \bar{F}_X(y + d) \dif{y} \\
                         &= \int_{d}^{u} k ( y - d )^{k - 1} \bar{F}_X(y) \dif{y} 
\end{align*}
For $Y_P$, we have
\begin{align*}
  Y_P &= Y_L \mid Y_L > 0 = [ (X \land u) - d ]_+ \mid [ (X \land u) - d ]_+ > 0 \\
      &= (X \land u) - d \mid X > d.
\end{align*}
Thus by \cref{propo:_y_p_is_completely_determined_by_y_l_},
\begin{equation*}
  \bar{F}_{Y_P}(y) = \begin{cases}
      1 & y < 0 \\
      \frac{\bar{F}_{Y_L}(y)}{\bar{F}_{Y_L}(0)} & 0 \leq y < u - d \\
      0 & y \geq u - d
    \end{cases}
\end{equation*}
Using the same proposition, the moments of $Y_P$ are
\begin{equation*}
  E \left[ Y_P^k \right] = \frac{E \left[ Y_L^k \right]}{\bar{F}_X(d)} = \frac{\int_{d}^{u} k ( y - d )^{k - 1} \bar{F}_X(y) \dif{y}}{\bar{F}_X(d)}.
\end{equation*}

\paragraph{Franchise Deductible} Given a Franchise Deductible $d > 0$, we have
\begin{equation*}
  Y_L = X \cdot \mathbb{1}_{\{X > d\}}.
\end{equation*}
Its survival function is
\begin{align*}
  \bar{F}_{Y_L}(y) &= P ( X \cdot \mathbb{1}_{\{X > d\}} > y ) = \begin{cases}
                     1 & y < 0 \\
                     P ( X \cdot \mathbb{1}_{\{X > d\}} > y ) & y \geq 0
                   \end{cases} \\
                   &= \begin{cases}
                     1 & y < 0 \\
                     \bar{F}_X(d) & 0 \leq y < d \\
                     \bar{F}_X(y) & y \geq d
                   \end{cases}.
\end{align*}
For the case when $0 \leq y < d$, it is clear that in order for $X \cdot \mathbb{1}_{\{X > d\}} > y$, we first need $X > d$. Now the moments of $Y_L$ are
\begin{align*}
  E \left[ Y_L^k \right] &= \int_{0}^{\infty} ky^{k - 1} \bar{F}_{Y_L}(y) \dif{y} \\
                         &= \bar{F}_X(d) \int_{0}^{d} ky^{k - 1} \dif{y} + \int_{d}^{\infty} k y^{k - 1} \bar{F}_X(y) \dif{y} \\
                         &= d^k \bar{F}_X(d) + \int_{d}^{\infty} ky^{k - 1} \bar{F}_X(y) \dif{y}.
\end{align*}
Now observe that
\begin{equation*}
  Y_P = Y_L \mid Y_L > 0 = X \cdot \mathbb{1}_{\{X > d\}} \mid X \cdot \mathbb{1}_{\{X > d\}} > 0 = X \mid X > d
\end{equation*}
Again, using \cref{propo:_y_p_is_completely_determined_by_y_l_}, 
\begin{equation*}
  \bar{F}_{Y_P}(y) = \frac{\bar{F}_{Y_L}(y)}{\bar{F}_{Y_L}(0)} = \begin{cases}
    1                                 & y < d \\
    \frac{\bar{F}_X(y)}{\bar{F}_X(d)} & y \geq d
  \end{cases}
\end{equation*}
and its moments are
\begin{align*}
  E \left[ Y_P^k \right] &= \frac{E \left[ Y_L^k \right]}{\bar{F}_X(d)} = \frac{d^k \bar{F}_X(d) + \int_{d}^{\infty} ky^{k - 1} \bar{F}_X(y) \dif{y}}{\bar{F}_X(d)} \\
                         &= d^k + \frac{\int_{d}^{\infty} ky^{k - 1} \bar{F}_X(y) \dif{y}}{\bar{F}_X(d)}.
\end{align*}

\paragraph{Coinsurance} Let $\hat{Y_L}$ be the amount to-be-paid per loss without coinsurance. Let $\alpha \in (0, 1)$ be a coinsurance factor. Applying coinsurance for adjustment, we have that
\begin{equation*}
  Y_L = \alpha \hat{Y_L}.
\end{equation*}
The survival function of $Y_L$ is
\begin{equation*}
  \bar{F}_{Y_L}(y) = P\left( \alpha \hat{Y_L} > y \right) = P\left( \hat{Y_L} > \frac{y}{\alpha} \right) = \begin{cases}
    1 & y < 0 \\
    \bar{F}_{\hat{Y_L}} \left( \frac{y}{\alpha} \right) & y \geq 0
  \end{cases}
\end{equation*}
and its moments are
\begin{equation*}
  E \left[ Y_L^k \right] = E \left[ \alpha^k \hat{Y_L}^k \right] = \alpha^k E \left[ \hat{Y_L}^k \right].
\end{equation*}
Then for $Y_P$, we have that its survival function is
\begin{equation*}
  \bar{F}_{Y_P}(y) = \frac{\bar{F}_{Y_L}(y)}{\bar{F}_{Y_L}(0)} = \frac{\bar{F}_{\hat{Y_L}}\left( \frac{y}{\alpha} \right)}{\bar{F}_{\hat{Y_L}}(0)}, \quad y \geq 0,
\end{equation*}
and its moments
\begin{equation*}
  E \left[ Y_P^k \right] = \frac{E \left[ Y_L^k \right]}{\bar{F}_{\hat{Y_L}}(0)} = \frac{\alpha^k E \left[ \hat{Y_L}^k \right]}{\bar{F}_{\hat{Y_L}}(0)}.
\end{equation*}

\begin{eg}
  The cdf of a ground-up loss $X$ is given by
  \begin{equation*}
    F_X(x) = 1 - \left( 1 - \frac{x}{800} \right)^2, \quad 0 \leq x \leq 800.
  \end{equation*}
  Assuming a policy limit of $600$, an ordinary deductible of $200$, and a coinsurance facotr of $0.8$, determine the cdf of $Y_L$ and the expected amount paid per loss $E\left[ Y_L \right]$.
\end{eg}

\begin{solution}
  We are given
  \begin{equation*}
    Y_L = 0.8 [ (X \land 600) - 200 ]_+.
  \end{equation*}
  The survival function of $Y_L$ is
  \begin{align*}
    \bar{F}_{Y_L}(y) &= P \left( \max \{ 0, (X \land 600) - 200\} > \frac{y}{0.8} \right) \\
      &= \begin{cases}
        1 & y < 0 \\
        P \left( X \land 600 > \frac{5y}{4} + 200 \right) & y \geq 0
      \end{cases} \\
      &= \begin{cases}
        1 & y < 0 \\
        P \left( X > \frac{5y}{4} + 200 \right) & 0 \leq y < 0.8(600 - 200) = 320 \\
        0 & y \geq 320
      \end{cases} \\
      &= \begin{cases}
        1 & y < 0 \\
        \bar{F}_X \left( \frac{5y}{4} + 200 \right) & 0 \leq y < 320 \\
        0 & y \geq 320
      \end{cases}
  \end{align*}
  Thus the cdf of $Y_L$ is
  \begin{equation*}
    \bar{F}_{Y_L}(y) = \begin{cases}
      0 & y < 0 \\
      1 - \bar{F}_X \left( \frac{5y}{4} + 200 \right) & 0 \leq y < 320 \\
      1 & y \geq 320
    \end{cases}.
  \end{equation*}
  The expected amount paid per loss is
  \begin{equation*}
    E \left[ Y_L \right] = 0.8 \int_{200}^{600} \left( 1 - \frac{x}{800} \right)^2 \dif{x} = \frac{260}{3}
  \end{equation*}
\end{solution}

\begin{eg}
  Consider a ground-up loss $X$ with a Franchise deductible $d$. You are given that
  \begin{itemize}
    \item $15\%$ of the losses are below the Franchise deductible $d$,
    \item the mean excess loss $e_X(d) = 50$,
    \item the expected amount paid per loss is $51$.
  \end{itemize}
  Determine the value of $d$.
\end{eg}

\begin{solution}
  We are given
  \begin{gather*}
    Y_L = X \cdot \mathbb{1}_{\{X > d\}} \\
    P( X < d ) = 0.15
  \end{gather*}
  Thus $P(X > d) = 0.85$. We have
  \begin{equation*}
    \bar{F}_{Y_L}(y) = \begin{cases}
      1 & y < 0 \\
      \bar{F}_X(d) & 0 \leq y < d \\
      \bar{F}_X(y) & y \geq d
    \end{cases} = \begin{cases}
      1 & y < 0 \\
      0.85 & 0 \leq y < d \\
      \bar{F}_X(y) & y \geq d
    \end{cases}.
  \end{equation*}
  We are given
  \begin{equation*}
    50 = e_X(d) = \frac{\int_{d}^{\infty} \bar{F}_X(y) \dif{y}}{\bar{F}_X(d)},
  \end{equation*}
  and so
  \begin{equation*}
    \int_{d}^{\infty} \bar{F}_X(y) \dif{y} = 50 * 0.85 = 42.5.
  \end{equation*}
  We are given
  \begin{align*}
    51 &= E [ Y_L ] = \int_{0}^{\infty} \bar{F}_X(y) \dif{y} = d\bar{F}_X(d) + \int_{d}^{\infty} \bar{F}_X(y) \dif{y} \\
       &= 0.85d + 42.5.
  \end{align*}
  Thus
  \begin{equation*}
    d = \frac{8.5}{0.85} = 10.
  \end{equation*}
\end{solution}

% subsubsection application_of_expected_value_of_the_policy_adjustments_continued (end)

% subsection some_important_identities_continued (end)

% section severity_distribution_policy_adjustments_continued_3 (end)

% chapter lecture_12_oct_23rd (end)

\chapter{Lecture 13 Oct 25th}%
\label{chp:lecture_13_oct_25th}
% chapter lecture_13_oct_25th

\section{Severity Distribution --- Policy Adjustments (Continued 3)}%
\label{sec:severity_distribution_policy_adjustments_continued_3}
% section severity_distribution_policy_adjustments_continued_3

By introducing policy adjustments, it is within our interest to determine if the introduced adjustments have helped to eliminate the expected propotion of loss.

\begin{defn}[Loss Elimination Ratio]\index{Loss Elimination Ratio}\label{defn:loss_elimination_ratio}
  The \hlnoteb{loss elimination ratio}, denoted as \hldefn{$\LER$}, is the ratio of which loss has been mitigated, or eliminated, as a result of policy adjustments, and it is given by
  \begin{equation*}
    \LER = \frac{E[ X - Y_L ]}{E[X]} = 1 - \frac{E[Y_L]}{E[X]},
  \end{equation*}
  where $\frac{E[Y_L]}{E[X]}$ corresponds to the percentage of loss retained by the insurer.
\end{defn}

\begin{eg}
  For a policy that has only an ordinary deductible, i.e. $Y_L = {[X - d]}_+$, we have
  \begin{equation*}
    \LER = 1 - \frac{E( {[X - d]}_+ )}{E[X]} = 1 - \frac{E[X] - E[X \land d]}{E[X]} = \frac{E[X \land d]}{E[X]}.
  \end{equation*}
\end{eg}

\begin{eg}
  Consider a ground-up loss $X \sim \Pareto(\alpha, \theta)$ with $\alpha = 2$ and $\theta = 1000$.
  \begin{enumerate}
    \item Calculate the $\LER$ if an ordinary deductible of $500$ is applied.
    \item What is the required value of $d$ to eliminate $20\%$ of the loss?
  \end{enumerate}

  \begin{solution}
    \begin{enumerate}
      \item Note that
        \begin{equation*}
          \bar{F}_X(x) = \frac{\theta^\alpha}{(x + \theta)^\alpha}.
        \end{equation*}
        Now
        \begin{align*}
          E[X] &= \int_{0}^{\infty} \bar{F}_X(x) \dif{x} = \theta^\alpha \int_{0}^{\infty} \frac{1}{(x + \theta)^\alpha} \dif{x} \\
               &= \frac{\theta^\alpha}{1 - \alpha} \cdot \frac{1}{( x + \theta )^{ \alpha - 1 }} \at{0}{\infty} = \frac{\theta}{\alpha - 1}.
        \end{align*}
        and
        \begin{align*}
          E[X \land d] &= \int_{0}^{d} \bar{F}_X(x) \dif{x} = \frac{\theta^\alpha}{1 - \alpha}\cdot \frac{1}{(x + \theta)^{ \alpha - 1 }} \at{0}{d} \\
                       &= \frac{\theta^\alpha}{1 - \alpha} \left( \frac{1}{(d + \theta)^{ \alpha - 1 }} - \frac{1}{\theta^{\alpha - 1}} \right) \\
                       &= \frac{\theta}{\alpha - 1} \left( 1 - \left( \frac{\theta}{d + \theta} \right)^{\alpha - 1} \right).
        \end{align*}
        Thus
        \begin{equation*}
          \LER = \frac{E[X \land d]}{E[X]} = \left( 1 - \left( \frac{\theta}{d + \theta} \right)^{\alpha - 1} \right) = \frac{1}{3}.
        \end{equation*}

        In other words, $\frac{1}{3}$ is mitigated by setting an ordinary deductible of $500$.

      \item In this case, let $\LER = 0.2 = \frac{1}{5}$. Then
        \begin{equation*}
          \frac{1}{5} = 1 - \frac{1000}{d + 1000} \iff \frac{1000}{d + 1000} = \frac{4}{5} \iff d = 250
        \end{equation*}
    \end{enumerate}
  \end{solution}
\end{eg}

% section severity_distribution_policy_adjustments_continued_3 (end)

\section{Frequency Distributions --- Basic Frequency Distributions}%
\label{sec:frequency_distributions_basic_frequency_distributions}
% section frequency_distributions_basic_frequency_distributions

Recall from our \hyperref[defn:collective_risk_model]{Collective Risk Model} that
\begin{equation*}
  S = \sum_{i=1}^{N} X_i,
\end{equation*}
where
\begin{align*}
  X_i &\equiv \text{ size of the } i\text{\textsuperscript{th} claim, modelled by severity distributions} \\
N &\equiv \text{ a nonnegative integer-valued rv that represents the number of } \\
  &\quad\; \text{ claims, modelled by frequency distributions }
\end{align*}

\begin{defn}[Counting Distributions and RVs]\index{Counting Distribution}\index{Counting Random Variables}\label{defn:counting_distributions_and_rvs}
  A nonnegative rv, usually represented by $N$, is called a \hlnoteb{counting rv} and its distribution is called a \hlnoteb{counting distirbution}.
\end{defn}

\begin{note}
  For this section, the \hyperref[defn:probability_generating_function]{pgf} is important.
\end{note}

\paragraph{Importance of PGF} Given $G(t) = E\left[ t^N \right] = \sum_{k=0}^{\infty} t^K p_k$, provided that the moments exist, we have\marginnote{Also for $(*)$: The derivation is
\begin{align*}
  &G_N^{(n)}(t) = \frac{d^n}{dt^n} G_N(t) \\
  &= \sum_{k=0}^{\infty} \frac{d^n}{dt^n} t^k p_k \\
  &= \sum_{k=0}^{\infty} k(k - 1) \hdots (k - n + 1) t^{k - n} p_k \\
  &= E \left[ \prod_{k=1}^{n} ( N - k + 1 ) t^{N - n} \right]
\end{align*}}
\begin{align*}
  G^{(n)}(t) &= \frac{d^n}{dt^n} G(t) \overset{(*)}{=} E\left[ \prod_{i=1}^{n} (N - i + 1)t^{N - n} \right] \\
             &= \sum_{k=0}^{\infty} \prod_{i=1}^{n} (k - i + 1) t^{k - n} p_k \\
             &\overset{(**)}{=} \sum_{k=n}^{\infty} \prod_{i=1}^{n} (k - i + 1) t^{k - n} p_k
\end{align*}
where $(*)$ is because the moments exist, and $(**)$ is because for $k = 0, 1, \ldots, n - 1$, the product $\prod_{i=1}^{n} (k - i + 1) = 0$.

We can obtain the pmf of $N$ from the pgf by
\begin{align}
  G^{(n)}(0) &= \sum_{k=n}^{\infty} \prod_{i=1}^{n} (k - i + 1) t^{k - n} p_k \at{t = 0}{} \nonumber \\
             &= \prod_{i=1}^{n} ( n - i + 1 ) p_n = n! p_n \label{eq:pmf_from_pgf}
\end{align}
where we notice in \cref{eq:pmf_from_pgf} that only the $n$\textsuperscript{th} term survives as $t^{n - n} = 1$.

\hlnoteb{Factorial Moments}\sidenote{
  \begin{margindefn}[Factorial Moments from PGF]\label{defn:factorial_moments_from_PGF}
    We can obtain the \hlnoteb{factorial moments} of an rv $X$ from its pgf. In particular,
    \begin{equation*}
      G^{(n)}(1) = E \left[ \prod_{i=1}^{n} (X - i + 1) \right]
    \end{equation*}
    where $n \in \mathbb{N} \setminus \{ 0 \}$.
  \end{margindefn}
} can be obtained by
\begin{equation*}
  G^{(n)}(1) = E\left[ \prod_{i=1}^{n} ( N - i + 1 ) \right], \quad n = 1, 2, 3, \ldots.
\end{equation*}
In particular, we have that
\begin{equation*}
  G'(1) = E[N] \text{ and } G''(1) = E[N(N - 1)] = E(N^2) - E(N)
\end{equation*}
and so
\begin{equation*}
  \Var(N) = G''(1) + G'(1) - G'(1)^2.
\end{equation*}

\subsection{Frequency Distributions}%
\label{sub:frequency_distributions}
% subsection frequency_distributions

\subsubsection{Poisson Distribution}%
\label{ssub:poisson_distribution}
% subsubsection poisson_distribution

\begin{defn}[Poisson Distribution]\index{Poisson Distribution}\label{defn:poisson_distribution}
  A counting rv $N$ is said to have a \hlnoteb{Poisson distribution} with parameter $\lambda$, and denote $N \sim \Poi(\lambda)$, if it has the pmf
  \begin{equation*}
    p_k = P(N = k) = \frac{e^{-\lambda} \lambda^k}{k!}, \quad k = 0, 1, 2, \ldots.
  \end{equation*}
\end{defn}

\begin{remark}
  We can easily verify that the Poisson distribution is indeed a probability distribution, by noticing that
  \begin{equation*}
    \sum_{k=0}^{\infty} p_k = \sum_{k=0}^{\infty} \frac{e^{-\lambda} \lambda^k}{k!} = e^{-\lambda} e^{\lambda} = 1
  \end{equation*}
  where we used the \hlnotea{Taylor expansion} $e^{x} = \sum_{k=0}^{\infty} \frac{x^k}{k!}$.
\end{remark}

\begin{propo}[PGF, Mean, and Variance of Poisson Distribution]\label{propo:pgf_mean_and_variance_of_poisson_distribution}
  For $N \sim \Poi(\lambda)$, its pgf is
  \begin{equation*}
    G(t) = e^{\lambda (t - 1)},
  \end{equation*}
  and its mean and variance are
  \begin{equation*}
    E(N) = \Var(N) = \lambda.
  \end{equation*}
\end{propo}

\begin{proof}
  Notice that
  \begin{equation*}
    G(t) = E\left[ t^N \right] = \sum_{k=0}^{\infty} t^k p_k = \sum_{k=0}^{\infty} \frac{e^{-\lambda} (t \lambda)^k}{k!} = e^{-\lambda} e^{t \lambda} = e^{\lambda( t - 1 )}.
  \end{equation*}
  Thus
  \begin{equation*}
    E[N] = G'(1) = \lambda \text{ and } G''(1) = \lambda^2,
  \end{equation*}
  and so
  \begin{equation*}
    \Var(N) = \lambda^2 + \lambda - \lambda^2 = \lambda.
  \end{equation*}\qed\
\end{proof}

\begin{propo}[Sum of Independent Poisson RVs]\label{propo:sum_of_independent_poisson_rvs}
  If $N_1, N_2, \ldots, N_m$ are \hlnotea{independent} Poisson rvs with parameters $\lambda_1, \lambda_2,$ $\ldots, \lambda_m$ respectively, then
  \begin{equation*}
    N = \sum_{i=1}^{m} N_i \sim \Poi \left( \sum_{i=1}^{m} \lambda_i \right)
  \end{equation*}
\end{propo}

\begin{proof}
  Using the pgf method for $N$, we see that
  \begin{align*}
    G(t) &= e\left[ t^N \right] = E\left[ t^{\sum_{i=1}^{m} N_i} \right] = \prod_{i=1}^{m} E\left[t^{N_i}\right] \\
         &= \prod_{i=1}^{m} e^{\lambda_i ( t - 1 )} = e^{( t - 1 ) \sum_{i=1}^{m} \lambda_i}
  \end{align*}
  which is the pgf of $\Poi\left( \sum_{i=1}^{m} \lambda_i \right)$ as required.\qed\
\end{proof}

% subsubsection poisson_distribution (end)

% subsection frequency_distributions (end)

% section frequency_distributions_basic_frequency_distributions (end)

% chapter lecture_13_oct_25th (end)

\chapter{Lecture 14 Oct 30th}%
\label{chp:lecture_14_oct_30th}
% chapter lecture_14_oct_30th

\section{Frequency Distribution --- Basic Frequency Distributions (Continued)}%
\label{sec:frequency_distribution_basic_frequency_distributions_continued}
% section frequency_distribution_basic_frequency_distributions_continued

\subsection{Frequency Distributions (Continued)}%
\label{sub:frequency_distributions_continued}
% subsection frequency_distributions_continued

\subsubsection{Poisson Distribution (Continued)}%
\label{ssub:poisson_distribution_continued}
% subsubsection poisson_distribution_continued

\begin{propo}[Splitting a Poisson Distribution]\label{propo:splitting_a_poisson_distribution}
  Suppose that the total number of claim arrivals follows $N \sim \Poi(\lambda)$. There are $m$ distinct types of claims. Given a claim occurs, it is of type $i$ with probability $p_i$ such that
  \begin{equation*}
    p_1 + \hdots + p_m = 1.
  \end{equation*}
  Then, for each fixed $i = 1, \ldots, m$, the number of claims of type $i$, $N_i \sim \Poi(\lambda p_i)$. Furthermore, $N_1, N_2, \ldots, N_m$ are independent.
\end{propo}

\begin{note}
  The above proposition can be visualized using a tree.
  \begin{figure}[h]
    \centering
    \begin{tikzpicture}
      \node[label={180:{$N \sim \Poi(\lambda)$}}] at (0, 0) {};
      \node[draw,circle,fill,inner sep=1pt,label={180:{A claim}}] (A) at (0, 0.5) {};
      \node[draw,circle,fill,inner sep=1pt,label={0:{Type 1}}] (one) at (1, 2) {};
      \node[draw,circle,fill,inner sep=1pt,label={0:{Type 2}}] (two) at (1, 1) {};
      \node (vdots) at (1, 0) {$\vdots$};
      \node[draw,circle,fill,inner sep=1pt,label={0:{Type m}}] (m) at (1, -1) {};
      \draw[-latex'] (A) -- (one);
      \draw[-latex'] (A) -- (two);
      \draw[-latex'] (A) -- (vdots);
      \draw[-latex'] (A) -- (m);
      \node[label={0:{w/ $p_1 \quad \to N_1 \sim \Poi(\lambda p_1)$}}] at (3, 2) {};
      \node[label={0:{w/ $p_2 \quad \to N_2 \sim \Poi(\lambda p_2)$}}] at (3, 1) {};
      \node[label={0:{w/ $p_m \quad \to N_m \sim \Poi(\lambda p_m)$}}] at (3, -1) {};
    \end{tikzpicture}
    \caption{Visualization of \cref{propo:splitting_a_poisson_distribution}}
    \label{fig:visualization_of_splitting_a_poisson_distribution}
  \end{figure}
\end{note}

\begin{proof}
  We shall use \hlnotea{mathematical induction} on $m$, for the statement ``$N_1, N_2, \ldots, N_m$ are independent''. $N_i \sim \Poi(\lambda p_i)$ will follow from the induction step.

  For $m = 1$, there is nothing to prove. It suffices to prove for $m = 2$, since we may think of the problem as
  \begin{equation*}
    \text{Type 1} \quad \underbrace{\text{Type 2} \quad \text{Type 3} \hdots \text{Type m}}_{\text{Type 2'}}.
  \end{equation*}

  \noindent\hlbnotea{Case $m = 2$} Suppose $N = N_1 + N_2 \sim \Poi(\lambda)$. To show that $N_1$ and $N_2$ are independent, a relation which we denote as $N_1 \bot N_2$, we need to show
  \begin{equation}\label{eq:splitting_poisson_independence}
    P(N_1 = k_1, N_2 = k_2) = P(N_1 = k_1) P(N_2 = k_2),
  \end{equation}
  which is a defining property of independence.

  Firstly, note that if given sets $A \subset B$, we have
  \begin{equation*}
    P(A) = P(A \cap B).
  \end{equation*}
  With that,
  \begin{align}
    P(N_1 = k_1, N_2 = k_2) &= P(\overbrace{N_1 = k_1, N_2 = k_2}^{A}, \overbrace{N_1 + N_2 = k_1 + k_2}^{B}) \nonumber \\
                            &= P(A \mid B) P(B) \nonumber \\
                            &= \binom{k_1 + k_2}{k_1} p_1^{k_1} p_2^{k_2} \cdot \frac{e^{-\lambda} \lambda^{k_1 + k_2}}{(k_1 + k_2)!} \nonumber \\
                            &= \frac{(k_1 + k_2)!}{k_1! k_2!} p_1^{k_1} p_2^{k_2} \cdot \frac{e^{-\lambda (1)} \lambda^{k_1 + k_2}}{(k_1 + k_2)!} \nonumber \\
                            &= e^{-\lambda (p_1 + p_2)} \cdot \frac{(\lambda p_1)^{k_1}}{k_1!} \cdot \frac{(\lambda p_2)^{k_2}}{k_2!} \nonumber \\
                            &= \frac{e^{-\lambda p_1} (\lambda p_1)^{k_1}}{k_1!} \cdot \frac{e^{-\lambda p_2} (\lambda p_2)^{k_2}}{k_2!} \label{eq:splitting_poisson_jointdist}
  \end{align}
  Thus, the marginal distribution of $N_1$
  \begin{align*}
    P(N_1 = k_1) &= \sum_{k_2 = 0}^{\infty} P(N_1 = k_1, N_2 = k_2) \\
                 &= \frac{e^{-\lambda p_1} (\lambda p_1)^{k_1}}{k_1!} e^{-\lambda p_2} \sum_{k_2 = 0}^{\infty} \frac{(\lambda p_2)^{k_2}}{k_2!} \\
                 &= \frac{e^{-\lambda p_1} (\lambda p_1)^{k_1}}{k_1!} e^{-\lambda p_2} e^{\lambda p_2} \\
                 &= \frac{e^{-\lambda p_1} (\lambda p_1)^{k_1}}{k_1!}
  \end{align*}
  which is the pmf of $\Poi(\lambda p_1)$. The marginal distribution of $N_2$ is similar. It is clear from \cref{eq:splitting_poisson_jointdist} that we have \cref{eq:splitting_poisson_independence}. The result then follows from induction.\qed\
\end{proof}

\begin{eg}
  The number of claims of a portfolio follows $\Poi(\lambda)$. The severity of ground-up loss follows $\Unif(0, b)$. The insurer would like to impose an ordinary deductible $d$ and a policy limit $u$ such that
  \begin{equation*}
    0 < d < u < b.
  \end{equation*}
  What is the frequency distribution of \hlnotea{positive payments}?
\end{eg}

\begin{solution}
  Let Type 1 be the case where $X < d$ and Type 2 be $X > d$. Since the severity of the ground-up loss follows $\Unif(0, b)$, the probability of an occurrence of Type 2 is
  \begin{equation*}
    1 - \frac{d}{b} = \frac{b - d}{b}.
  \end{equation*}
  By \cref{propo:splitting_a_poisson_distribution}, we have that the frequency distribution of positive payments, i.e. Type 2, follows $\Poi \left( \lambda \frac{b - d}{b} \right)$.
\end{solution}

% subsubsection poisson_distribution_continued (end)

\subsubsection{Binomial Distribution}%
\label{ssub:binomial_distribution}
% subsubsection binomial_distribution

\begin{defn}[Binomial Distribution]\index{Binomial Distribution}\label{defn:binomial_distribution}
  A counting rv $N$ is said to have a \hlnoteb{binomial distribution} with parameters $q \in (0, 1)$ and $m \in \mathbb{N} \setminus \{ 0 \}$, written as $N \sim \Bin(q, m)$, if it has the pmf
  \begin{equation*}
    p_k = P(N = k) = \binom{m}{k} q^k ( 1 - q )^{m - k}, \enspace k = 0, 1, 2, \ldots .
  \end{equation*}
\end{defn}

\begin{remark}
  It is easy to verify that this is a valid probability distribution, since
  \begin{equation*}
    \sum_{k=0}^{m} \binom{m}{k} q^k (1 - q)^{m - k} = (q + 1 - q)^m = 1^m = 1
  \end{equation*}
  by the \hlnotea{binomial theorem}.
\end{remark}

\begin{note}
  \begin{itemize}
    \item When $m = 1$, the distribution is called a \hldefn{Bernoulli} rv with mean $q$. 
    \item The binomial distribution is a \hlnotea{bounded} rv, since it has a fixed number of trials.
  \end{itemize}
\end{note}

\begin{propo}[PGF of Binomial Distribution]\label{propo:pgf_of_binomial_distribution}
  Let $N \sim \Bin(q, m)$. Its pgf is given by
  \begin{equation*}
    G(t) = ( 1 - q + tq )^m.
  \end{equation*}
  Moreover, its mean and variance are
  \begin{equation*}
    E[N] = mq \text{ and } \Var(N) = mq(1 - q)
  \end{equation*}
  respectively.
\end{propo}

\begin{proof}
  We have
  \begin{equation*}
    G(t) = \sum_{k=0}^{m} \binom{m}{k} (tq)^k (1 - q)^{m - k} = ( 1 - q + tq )^m
  \end{equation*}
  The mean is, therefore,
  \begin{equation*}
    G'(1) = mq (1 - q + (1)q)^{m - 1} = mq,
  \end{equation*}
  and its variance
  \begin{align*}
    \Var(N) &= G''(1) + G'(1) - G'(1)^2 \\
            &= m(m-1)q^2 + mq - m^2 q^2 = mq ( 1 - q ).
  \end{align*}\qed\
\end{proof}

\begin{propo}[Sum of Independent Binomial RVs]\label{propo:sum_of_independent_binomial_rvs}
  If $N_1, \ldots, N_n$ are independent and $N_i \sim \Bin(q, m_i)$ for $i = 1, \ldots, n$, then
  \begin{equation*}
    N = \sum_{i=1}^{n} N_i \sim \Bin \left( q, \sum_{i=1}^{n} m_i \right).
  \end{equation*}
\end{propo}

\begin{proof}
  We shall use the pgf to prove this, instead of using the mgf (which is the common approach).
  \begin{align*}
    G_N(t) &= E \left[ t^N \right] = E \left[ t^{\sum_{i=1}^{n} N_i} \right] \overset{(*)}{=} \prod_{i=1}^{n} E \left[ t^{N_i} \right] \\
           &= \prod_{i=1}^{n} (1 - q + tq)^{m_i} = (1 - q + tq)^{\sum\limits_{i=1}^{n} m_i}
  \end{align*}
  Thus $N = \sum_{i=1}^{n} N_i \sim \Bin \left( q, \sum\limits_{i=1}^{n} m_i \right)$.\qed\
\end{proof}

\begin{note}
  As a result of \cref{propo:sum_of_independent_binomial_rvs}, if we have a sequence of Bernoulli trials, each with the same ``success'' probability $q$, call each of them $I_i$, then
  \begin{equation*}
    N = \sum_{i=1}^{m} I_i \sim \Bin ( q, m )
  \end{equation*}
  Consequently, it becomes rather silly how easy it is we can get the mean and variance of $N$:
  \begin{gather*}
    E[N] = E \left[ \sum_{i=1}^{m} I_i \right] = \sum_{i=1}^{m} E [ I_i ] = mq \\
    \Var(N) = \Var \left( \sum_{i=1}^{m} I_i \right) = \sum_{i=1}^{m} \Var(I_i) = mq(1 - q)
  \end{gather*}
\end{note}

% subsubsection binomial_distribution (end)

% subsection frequency_distributions_continued (end)

% section frequency_distribution_basic_frequency_distributions_continued (end)

% chapter lecture_14_oct_30th (end)

\chapter{Lecture 15 Nov 01st}%
\label{chp:lecture_15_nov_01st}
% chapter lecture_15_nov_01st

\section{Frequency Distribution --- Basic Frequency Distributions (Continued 2)}%
\label{sec:frequency_distribution_basic_frequency_distributions_continued_2}
% section frequency_distribution_basic_frequency_distributions_continued_2

\subsection{Frequency Distributions (Continued 2)}%
\label{sub:frequency_distributions_continued_2}
% subsection frequency_distributions_continued_2

\subsubsection{Negative Binomial Distribution}%
\label{ssub:negative_binomial_distribution}
% subsubsection negative_binomial_distribution

\begin{defn}[Negative Binomial Distribution]\index{Negative Binomial Distribution}\label{defn:negative_binomial_distribution}
  A counting rv $N$ is said to have a \hlnoteb{negatiev binomial distribution} with parameters $\beta > 0$ and $r > 0$, denoted $N \sim \NB(\beta, r)$, if it has the pmf
  \begin{equation*}
    p_k = P(N = k) = \binom{k + r - 1}{k} \left( \frac{1}{1 + \beta} \right)^r \left( \frac{\beta}{1 + \beta} \right)^k, k = 0, 1, 2, \ldots
  \end{equation*}
\end{defn}

\begin{remark}
  Note that
  \begin{equation*}
    \binom{k + r - 1}{k} = \frac{\Gamma(k + r)}{k! \Gamma(r)} = \frac{(k + r - 1)!}{k! (r - 1)!},
  \end{equation*}
  where the later equality follows if $r \in \mathbb{N} \setminus \{ 0 \}$.
\end{remark}

\begin{note}
  \begin{itemize}
    \item When $r = 1$, we can also write the pmf of $\NB(\beta, 1)$ as the pmf of the \hlnotea{geometric distribution}:
      \begin{equation*}
        p_k = \frac{1}{1 + \beta} \left( \frac{\beta}{1 + \beta} \right)^k, k = 0, 1, 2, \ldots.
      \end{equation*}

    \item To verify that the negative binomial distribution is a valid probability distribution, we need the following identity:\marginnote{
      \begin{ex}
        Verify that the negative binomial distribution is a valid probability distribution.
      \end{ex}}
      \begin{equation*}
        (1 - x)^{-r} = \sum_{k=0}^{\infty} \binom{k + r - 1}{k} x^k,
      \end{equation*}
      which is proven as follows:

      \begin{proof}
        We shall use the \hlnotea{Taylor expansion} of $(1 - x)^{-r}$.
        \begin{align*}
          (1 - x)^{-r} &= 1 + (-1)(-r)(1 - x)^{-r-1}\at{x = 0}{} x \\
                       &\quad + \frac{r}{2} (-1) (-r-2) (1 - x)^{-r-2}\at{x = 0}{} x^2 + \hdots \\
                       &= 1 + rx + \frac{r(r + 1)}{2} x^2 + \frac{r(r + 1)(r + 2)}{3!} x^3 + \hdots \\
                       &= \sum_{k=0}^{\infty} \frac{r(r + 1) \hdots (r + k - 1)}{k!} x^K \\
                       &= \sum_{k=0}^{\infty} \binom{k + r - 1}{k} x^k.
        \end{align*}\qed\
      \end{proof}

    \item The negative binomial distribution is an \hlnotea{unbounded} rv, and can take all natural numbers sans $0$.
  \end{itemize}
\end{note}

\paragraph{Interpretation} Consider an experiment with independent trails, of which each has only two possible outcomes: success with probability $\frac{1}{1 + \beta}$, and failure with probability $1 - \frac{1}{1 + \beta} = \frac{\beta}{1 + \beta}$. Let $N$ denote the number of failures until reaching the $r$\textsuperscript{th} success.

\begin{propo}[PGF of the Negative Binomial Distribution]\label{propo:pgf_of_the_negative_binomial_distribution}
  Let $N \sim \NB(\beta, r)$. Its pgf is thus
  \begin{equation*}
    G(t) = [1 - \beta(t - 1)]^{-r}.
  \end{equation*}
  Moreover, its mean and variance are
  \begin{equation*}
    E[N] = r \beta \text{ and } \Var(N) = r\beta(1 + \beta),
  \end{equation*}
  respectively.
\end{propo}

\begin{note}
  Note that the proof for getting the pgf is similar to how we can verify that $N$ is a probability (same case as in earlier counting distributions).
\end{note}

\begin{proof}
  Using the Taylor Expansion $(1 - x)^{-r} = \sum_{k=0}^{\infty} \binom{k + r - 1}{k} x^k$, we have
  \begin{align*}
    G(t) &= \sum_{k=0}^{\infty} t^k p_k = \left( \frac{1}{1 + \beta} \right)^r \sum_{k=0}^{\infty} \binom{k + r - 1}{k} \left( \frac{t \beta}{1 + \beta} \right)^k \\
         &= \left( \frac{1}{1 + \beta} \right)^r \left( 1 - \frac{t \beta}{1 + \beta} \right)^{-r} = [ 1 - \beta (t - 1) ]^{-r}.
  \end{align*}
  Consequently, the mean is
  \begin{equation*}
    E[N] = G'(1) = -r(-\beta) = r \beta
  \end{equation*}
  and variance is
  \begin{align*}
    \Var(N) &= G''(1) + G'(1) - G'(1)^2 \\
            &= -r ( -r - 1 ) \beta^2 + r \beta - r^2 \beta^2 = r \beta ( 1 + \beta )
  \end{align*}\qed\
\end{proof}

\begin{propo}[Negative Binomial from Poisson Conditioned on Gamma]\label{propo:negative_binomial_from_poisson_conditioned_on_gamma}
  Let $N \mid \Lambda = \lambda \sim \Poi(\lambda)$ and $\Lambda \sim \Gam(\alpha, \theta)$. Then
  \begin{equation*}
    N \sim \NB(\theta, \alpha).
  \end{equation*}
\end{propo}

\begin{note}
  We may also write $N \mid \Lambda = \lambda \sim \Poi(\lambda)$ as $N \mid \Lambda \sim \Poi(\Lambda)$.
\end{note}

\begin{proof}
  We shall prove this statement by finding the pgf of $N$, which identifies the distribution. Note that
  \begin{equation*}
    G_N(t) = E\left[ t^N \right] \overset{\text{Proposition }\ref{propo:total_expectation_and_total_variance}}{=} E \left[ E \left[ t^N \mid \Lambda \right] \right] \overset{(*)}{=} E \left[ e^{\Lambda (t - 1)} \right],
  \end{equation*}
  where $(*)$ \hlwarn{requires further clarification}. Now since $\Lambda \sim \Gam(\alpha, \theta)$, and $M_\Lambda(t) = E\left[e^{t \Lambda}\right] = (1 - \theta t)^{-\alpha}$, it follows that
  \begin{equation*}
    G_N(t) = [ 1 - \theta(t - 1) ]^{-\alpha}.
  \end{equation*}
  Thus $N \sim \NB(\theta, \alpha)$.\qed\
\end{proof}

\begin{propo}[Combining Negative Binomial Distributions]\label{propo:combining_negative_binomial_distributions}
  If $\{ N_i \}_{i = 1}^{n}$ is a sequence of independent rvs, and $N_i \sim \NB(\beta, r_i)$. Then
  \begin{equation*}
    N = \sum_{i=1}^{n} N_i \sim \NB \left( \beta, \sum_{i=1}^{n} r_i \right).
  \end{equation*}
\end{propo}

\begin{proof}
  We shall, again, use the pgf. We have
  \begin{align*}
    G_N(t) &= E \left[ t^N \right] \overset{(*)}{=} \prod_{i=1}^{n} E \left[ t^{N_i} \right] = \prod_{i=1}^{n} G_{N_i}(t) \\
           &= \prod_{i=1}^{n} [1 - \beta ( t - 1 )]^{r_i} = [ 1 - \beta ( t - 1 ) ]^{- \sum_{i=1}^{n} r_i},
  \end{align*}
  where $(*)$ is by independence of the rvs, and the last equality is thanks to $\beta$ being fixed for all the rvs. This completes the proof.\qed\
\end{proof}

% subsubsection negative_binomial_distribution (end)

% subsection frequency_distributions_continued_2 (end)

\subsection{$(a, b, n)$ Classes}%
\label{sub:a_b_n_classes}
% subsection a_b_n_classes

\subsubsection{$(a, b, 0)$ Class}%
\label{ssub:a_b_0_class}
% subsubsection a_b_0_class

\begin{defn}[$(a, b, 0)$ Class]\index{$(a, b, 0)$ Class}\label{defn:a_b_0_class}
  The $(a, b, 0)$ class is a set of counting rvs with pmf $p_k$ satisfying the recursive formula
  \begin{equation*}
    \frac{p_k}{p_{k - 1}} = a + \frac{b}{k}, \quad k \in \mathbb{N} \setminus \{ 0 \}.
  \end{equation*}
\end{defn}

\begin{remark}
  An $(a, b, 0)$ distribution is determiend by the parameters $a$ and $b$.
\end{remark}

\begin{note}
  Observe that
  \begin{align*}
    \frac{p_1}{p_0} &= a + \frac{b}{1} \iff p_1 = p_0 \left( a + \frac{b}{1} \right) \\
    \frac{p_2}{p_2} &= a + \frac{b}{2} \iff p_2 = p_1 \left( a + \frac{b}{2} \right) = p_0 \left( a + \frac{b}{1} \right)\left( a + \frac{b}{2} \right) \\
                    &\vdots \\
    \frac{p_k}{p_{k - 1}} &= a + \frac{b}{k} \iff p_k = p_0 \prod_{i=1}^{k} \left( a + \frac{b}{i} \right).
  \end{align*}
  Thus we see that each of the $p_k$ is completely determined by $p_0$. In other words, for the distributions of this class, if we can find $p_0$, then we can get $p_k$, even if we do not know the actual parameters of the distribution.

  In fact, we can solve for $p_0$, if we already know what $a$ and $b$ are: we need to solve for $p_0$ in $\sum_{k=0}^{\infty} p_k = 1$. In particular, we need to solve for
  \begin{equation*}
    p_0 \sum_{k=0}^{\infty} \prod_{i=1}^{k} \left( a + \frac{b}{i} \right) = 1.
  \end{equation*}
\end{note}

\paragraph{Members of the $(a, b, 0)$ class} It can be shown\sidenote{Perhaps this can be shown using \url{https://www.actuaries.org/ASTIN/Colloquia/Helsinki/Papers/S7_13_Fackler.pdf}.} that the Poisson, Binomial, and Negative Binomial distributions are \hlnotea{the only} distributions that belong to this class. We have that

\begin{table}[ht]
  \centering
  \begin{tabular}{l | c | c | c}
    \toprule
    Distribution    & $a$                       & $b$                              & $p_0$ \\
    \midrule
    $\Poi(\lambda)$ & $0$                       & $\lambda$                        & $e^{-\lambda}$ \\
    $\Bin(q, m)$    & $-\frac{q}{1 - q}$        & $( m + 1 ) \frac{q}{1 - q}$      & $(1 - q)^m$ \\
    $\NB(\beta, r)$ & $\frac{\beta}{1 + \beta}$ & $(r - 1)\frac{\beta}{1 + \beta}$ & $(1 + \beta)^{-r}$ \\
    \bottomrule
  \end{tabular}
  \caption{The $(a, b, 0)$ distributions}
  \label{table:the_a_b_0_distributions}
\end{table}

We shall prove for the case of $\Poi(\lambda)$.\marginnote{
\begin{ex}
  Find $a$, $b$ and $p_0$ for $\Bin(q, m)$ and $\NB(\beta, r)$.
\end{ex}}

\begin{proof}
  By the pmf of $\Poi(\lambda)$, it is clear that
  \begin{equation*}
    p_0 = \frac{e^{-\lambda} \lambda^0}{0!} = e^{-\lambda}.
  \end{equation*}
  Now, since
  \begin{equation*}
    p_1 = \lambda e^{-\lambda} \quad p_2 = \frac{1}{2} \lambda^2 e^{-\lambda}
  \end{equation*}
  we have the following system of equations:
  \begin{gather*}
    \lambda = \frac{p_1}{p_0} = a + b \\
    \frac{1}{2}\lambda = \frac{p_2}{p_1} = a + \frac{b}{2}
  \end{gather*}
  Thus $b = \lambda$ and $a = 0$.\qed\
\end{proof}

\begin{eg}
  Assume that the number of claims in a portfolio $N$ follows $(-0.25, 2.75, 0)$ distribution. Calculate the probability that there is at least one claim.
\end{eg}

\begin{solution}
  Using \cref{table:the_a_b_0_distributions}, we know that $N \sim \Bin(q, m)$, where
  \begin{equation*}
    - \frac{q}{1 - q} = - 0.25 \text{ and } (m + 1) \frac{q}{1 - q} = 2.75,
  \end{equation*}
  which gives $q = 0.2$ and $m = 10$. Thus the desired probability is
  \begin{equation*}
    P(N \geq 1) = 1 - P(N = 0) = 1 - (1 - 0.8)^{10} = 0.8926.
  \end{equation*}
\end{solution}

% subsubsection a_b_0_class (end)

% subsection a_b_n_classes (end)

% section frequency_distribution_basic_frequency_distributions_continued_2 (end)

% chapter lecture_15_nov_01st (end)

\appendix

\chapter{Additional Material}%
\label{chp:additional_material}
% chapter additional_material

\section{Individual Risk Model: An Alternate View}%
\label{sec:individual_risk_model_an_alternate_view}
% section individual_risk_model_an_alternate_view

\textit{This appendix serves to explain why our note of $Z_i = I_i X_i$ is wrong with as mush rigour as we can go for now. There may be hand-wavy parts, but those will be indicated.} 

We mentioned, as shown by Klugman, Panjer and Willmot (2012)\cite{KlugmanPanjerWillmot2012}, that for the \hyperref[defn:individual_risk_model]{Individual Risk Model}, the aggregate claim is modeled by
\begin{equation*}
  S = \sum_{i=1}^{n} Z_i
\end{equation*}
where $Z_i$ is a random variable for the potential loss of the $i$\textsuperscript{th} insurance policy, while $n$ is fixed. It is claimed that we can also express each $Z_i$ as
\begin{equation*}
  Z_i = I_i X_i
\end{equation*}
where $I_i$ is an indicator function given by
\begin{equation*}
  I_i(x) = \begin{cases}
    1 & \text{ if a claim occurs } \\
    0 & \text{ if there are no claims }
  \end{cases},
\end{equation*}
while $X_i$ is the size of the claim(s) for the $i$\textsuperscript{th} policy provided that there is a claim.

\newthought{One problem} that arises is: are $X_i$ and $I_i$ independent? They should be if we wish to define $Z_i$ in such a way. In fact, according to \\
\noindent\textcolor{be-magenta}{\underline{Klugman et al.\ in page 177}},

\begin{quotebox}{be-magenta}{light}
  Let $X_j = I_j B_j$, where $I_1, \ldots, I_n, B_1, \ldots, B_n$ are independent.
\end{quotebox}

where $X_j$ is our $Z_i$, $I_j$ is our $I_i$, and $B_j$ is our $X_i$.

\paragraph{$\S \; Z_i$ is not well-defined} Let us be explicit about the definitions of $I_i$ and $X_i$; we have
\begin{gather*}
  I_i = \mathbb{1}_{\{ Z_i > 0 \}} \\
  X_i = Z_i \mid Z_i > 0
\end{gather*}
However, we observe that such a defintion of $X_i$ is undefined on $Z_i = 0$. So the equation
\begin{equation*}
  Z_i = I_i X_i
\end{equation*}
is note well-defined.

\paragraph{$\S$ Independence of $I_i$ and $X_i$} We cannot actually tell if $I_i$ and $X_i$ are independent from each other, as it is equivalent to comparing apples with oranges\sidenote{In fact, I think this analogy fits our case perfectly so.}. Recall from our earlier courses, in particular STAT330, of the following notion:

\begin{defnnonum}[Probability Space]\label{defn:probability_space}
  Let $\Omega$ be a sample space, and $\mathcal{F}$ a $\sigma$-algebra defined on $\Omega$\sidenote{Note that $(\Omega, \mathcal{F})$ is called a \hlnotea{measurable space}.}. A \hlnoteb{probability space} is the measurable space $(\Omega, \mathcal{F})$ with a \textcolor{be-blue}{probability measure}, $f: \mathcal{F} \to [0, 1]$, defined on the space. We denote a probability space as $(\Omega, \mathcal{F}, f)$.
\end{defnnonum}

As mentioned in an earlier $\S$, $X_i$ is not defined on $Z_i = 0$, while $I_i$ is defined on $Z_i = 0$ \sidenote{\faHandPaperO\ \enspace\ This statement is hand-wavy.}. So the sample space for $X_i$ and $I_i$ are not the same, and so their probability measures are not the same as well. Therefore, \hlimpo{it is meaningless to ask if $X_i$ and $I_i$ are independent}.

Our best attempt at fixing this is probably the following: let
\begin{equation*}
  Z_i = \sum_{i=1}^{I_i} X_i,
\end{equation*}
which we can then have $X_i$ to be independent from $I_i$. However, interestingly so, this is a similar approach to a \hyperref[defn:collective_risk_model]{Collective Risk Model}.

% section individual_risk_model_an_alternate_view (end)

\section{Coherent Risk Measure}%
\label{sec:coherent_risk_measure}
% section coherent_risk_measure

An excerpt from Klugman et al.\ (2012)~\cite{KlugmanPanjerWillmot2012}:

\begin{quotebox}{be-magenta}{light}
  The study of risk measures and their properties has been carried out by authors such as Wang. Specific desirable properties of risk measures were proposed as axioms in connection with risk pricing by Wang, Young, and Panjer and more generally in risk measurement by Artzer et al.\ The Artzner paper introduced the concept of \textbf{coherence} and is considered to be the groundbreaking paper in risk measurement.
\end{quotebox}

Often, we use the function $\rho(X)$ to denote risk measures. One may think of $\rho(X)$ as \hlnotec{the amount of assets required to protect against adverse outcomes of the risk $X$}.

\begin{defn}[Coherent Risk Measure]\index{Coherent Risk Measure}\label{defn:coherent_risk_measure}
  A \hlnoteb{coherent risk measure} is a risk measure $\rho(X)$ that has the following four properties for any two loss rvs $X$ and $Y$:
  \begin{enumerate}
    \item (\hlnotea{Subadditivity}) $\rho(X + Y) \leq \rho(X) + \rho(Y)$.
    \item (\hlnotea{Monotonicity}) If $X \leq Y$ for all possible outcomes, then $\rho(X) \leq \rho(Y)$.
    \item (\hlnotea{Positive homogeneity}) $\forall c \in \mathbb{R}_{> 0}$, $\rho(cX) = c\rho(X)$.
    \item (\hlnotea{Translation invariance}) $\forall c \in \mathbb{R}_{> 0}$, $\rho(X + c) = \rho(X) + c$
  \end{enumerate}
\end{defn}

\paragraph{Interpretation of the conditions}

\begin{itemize}
  \item \textbf{Subadditivity}
    \begin{itemize}
      \item the risk measure (and in return, the capital required to cover for it) for two risks combined will not be greater than for the risks to be treated separately;
      \item reflects the fact that there shuld be some diversification benefit from combining risks;
      \item this requirement is disputed: e.g.\ the merger of several small companies into a larger one exposes each of the small companies to the \hlnotea{reputational risks} of the others.
    \end{itemize}

  \item \textbf{Monotonicity}
    \begin{itemize}
      \item if one risk always has greater losses than the other under all circumstances\sidenote{Probabilistically, this means $P(X > Y) = 0$}, then the risk measure of the greater risk should always be greater than the other.
    \end{itemize}

  \item \textbf{Positive homogeneity}
    \begin{itemize}
      \item the risk measure is independent of the currency used to measure it;
      \item doubling the exposure to a particular risk requires double the capital, which is sensible as doubling provides no diversification.
    \end{itemize}

  \item \textbf{Translation invariance}
    \begin{itemize}
      \item there is no additional risk for an additional risk which has no additional uncertainty.
    \end{itemize}
\end{itemize}

% section coherent_risk_measure (end)

% chapter additional_material (end)

\backmatter\

\pagestyle{plain}

\nobibliography*
\bibliography{references}

\input{listofsymbols.tex}

\printindex

\end{document}
