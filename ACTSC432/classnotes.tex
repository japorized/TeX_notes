% !TEX TS-program = pdflatex
\documentclass[notoc,notitlepage]{tufte-book}
% \nonstopmode % uncomment to enable nonstopmode

\usepackage{classnotetitle}

\title{ACTSC432 --- Loss Models II}
\author{Johnson Ng}
\subtitle{Classnotes for Spring 2019}
\credentials{BMath (Hons), Pure Mathematics major, Actuarial Science Minor}
\institution{University of Waterloo}

\input{latex-classnotes-preamble.tex}
\input{probnotation.tex}

\DeclareMathOperator{\VaR}{VaR}

\begin{document}
\input{latex-classnotes-header.tex}

\chapter*{Preface}%
\label{chp:preface}
\addcontentsline{toc}{chapter}{Preface}
% chapter preface

For this set of notes, I shall follow the format of which the course is
presented, by breaking contents into modules instead of lectures. Also, I will
be relying on the standard textbook for this topic, namely
\citealt{klugman2012}.

% chapter preface (end)

\chapter{Introduction and Review of Probability}%
\label{chp:introduction_and_review_of_probability}
% chapter introduction_and_review_of_probability

We shall first take an overview of what this course is about, and we will review
on some of the relevant notions from earlier courses.

\section{Introduction to Credibility Theory}%
\label{sec:introduction_to_credibility_theory}
% section introduction_to_credibility_theory

\hldefn{Credibility Theory} is a form of statistical inference that
\begin{itemize}
  \item uses newly observed past events; to
  \item more accurately re-forecasts uncertain future events.
\end{itemize}
From \citealt{klugman2012},
\begin{quotebox}{magenta}{foreground}
  It is a \hlnotea{set of quantitative tools} that allows an insurer to perform
  prospective \hlnotea{experience rating} (adjust future premiums based
  on past experience) on a risk or group of risks. If the experience of a
  policyholder is consistently better than that assumed in the underlying manual
  rate (also called a \hldefn{pure premium}), then the policyholder may demand
  a rate reduction.
\end{quotebox}

That's all fancy mumbo-jumbo so let's go through an example that will hopefully
enlighten us.

\begin{eg}[Enlightening Example to Credibility Theory]
  Suppose automobile insurance policies are classified according to the
  following factors:
  \begin{itemize}
    \item number of drivers;
    \item gender of each driver;
    \item number of vehicles; and
    \item brand, model, production year, and approximate mileage driver per
      year.
  \end{itemize}
  Policies with identical characteristics are assumed to belong to the same
  \hldefn{rating class}, which represents a group of individuals with similar
  risks.

  Suppose there are 2 policies in the same rating class. Both policies are
  charged with a so-called \hldefn{manual premium} of $\$1,500$ per year. This
  is the premium specified in the insurance manual for a policy with similar
  characteristics.

  Let's say that after 3 years, we obtain the following data:
  \begin{table}[ht]
    \centering
    \caption{Newly acquired past history for finding `credibility'}
    \label{table:newly_acquired_past_history_for_finding_credibility_}
    \begin{tabular}{c | c c}
             & Policy 1 & Policy 2 \\
      \hline
      Year 1 & $0$      & $500$ \\
      Year 2 & $200$    & $4000$ \\
      Year 3 & $0$      & $2500$
    \end{tabular}
  \end{table}
  We want to find out what's a good premium to charge to each policy for Year 4.
\end{eg}

\begin{remark}
  The shall leave the following as remarks.
  \begin{itemize}
    \item \textbf{How is the policyholder's own experience account for?} This is
      a key question that will be addressed in this course.
    \item Risks in a given rating class are \hlimpo{not perfectly identical}
      (i.e., no rating system is perfect)
    \item One may refine the rating system by incorporating more factors but it
      is time-consuming (and no system is perfect).
  \end{itemize}
\end{remark}

Thus, credibility theory is designed such that it
\begin{itemize}
  \item accounts for heterogeneity within a given rating lass; and
  \item provides a theoretical justification to charge a premium that reflects
    to the policyholder's own experience.
\end{itemize}

% section introduction_to_credibility_theory (end)

\section{Review of Probability}%
\label{sec:review_of_probability}
% section review_of_probability

You are expected to be familiar with the following concepts:
\marginnote{Some examples or more detailed review will be added for each topic
if I come to work through them in detail.}

\begin{itemize}
  \item Joint and Marginal Distribution
  \item Conditional Distribution
  \item Mixture Distributions (see also
    \href{https://tex.japorized.ink/ACTSC431/classnotes.pdf}{ACTSC431})
    \begin{itemize}
      \item $n$-point Mixture
    \end{itemize}
  \item Conditional Expectation
\end{itemize}

% section review_of_probability (end)

% chapter introduction_and_review_of_probability (end)

\chapter{Review of Statistics}%
\label{chp:review_of_statistics}
% chapter review_of_statistics

In this chapter, we will review the following notions:
\begin{itemize}
  \item Unbiased estimation
  \item Maximum likelihood estimation
  \item Bayesian estimation \faStar
\end{itemize}

\section{Unbiased Estimation}%
\label{sec:unbiased_estimation}
% section unbiased_estimation

Suppose we are given a \hlnotea{parametric model} \sidenote{See
\href{https://tex.japorized.ink/ACTSC431/classnotes.pdf\#defn.24}{ACTSC431}.} of
$X$, i.e. the distribution of $X \mid \Theta = \theta$ is known but $\theta$ is
unknown. Furthermore, we have a \hlnotea{random sample} of $X$, i.e. we have $\{
X_i \}_{i=1}^{n}$ is an independent and identically distributed (iid) sequence
of random variables (rv) such that $X_i \sim X$.

\begin{defn}[Estimate]\index{Estimate}\label{defn:estimate}
  An \hlnoteb{estimate} is a specific value that is obtained when applying an
  estimation procedure to a set of numbers, and in our case, rvs. We usually
  denote an estimate by a hat $\hat{}$.
\end{defn}

\begin{defn}[Estimator]\index{Estimator}\label{defn:estimator}
  An \hlnoteb{estimator} is a rule or formula that produces an
  \hlnotea{estimate}. We usually denote an estimator by $\tilde{}$.
\end{defn}

\begin{note}
  An estimate is a number or a function, while an estimator is an rv or a random
  function.
\end{note}

\begin{remark}
  In this course, we will not make a difference between the estimator and the
  estimate, and will use only $\hat{}$.
\end{remark}

\begin{defn}[Biased and Unbiased Estimator]\index{Bias}\index{Biased Estimator}\index{Unbiased Estimator}\label{defn:biased_and_unbiased_estimator}
  We say that an estimator, $\hat{\theta}$, is \hlnoteb{unbiased} if
  \begin{equation*}
    E[\hat{\theta} \mid \theta] = \theta
  \end{equation*}
  for all $\theta$. We say that an estimator is \hlnoteb{biased} if it is not
  unbiased, and we define the \hlnoteb{bias} as
  \begin{equation*}
    \bias_{\hat{\theta}}(\theta) = E[\hat{\theta} \mid \theta] - \theta.
  \end{equation*}
\end{defn}

Let's have ourselves a silly example.

\begin{eg}
  Let $(X_1, \ldots, X_n)$ be a random sample of $\Exp(\beta)$. The
  \hlnotea{sample mean}
  \begin{equation*}
    \overline{X} = \frac{1}{n} \sum_{i=1}^{n} X_i,
  \end{equation*}
  is an unbiased estimator for the mean $\beta$; observe that by the
  \hlnotea{linearity of the expectation}, we have
  \begin{equation*}
    E[\overline{X}] = E \left[ \frac{1}{n} \sum_{i=1}^{n} X_i \right] =
    \frac{1}{n} \sum_{i=1}^{n} E[X_i] = \frac{1}{n} (n\beta) = \beta.
  \end{equation*}
\end{eg}

\begin{eg}
  Let $\{ X_i \}_{i=1}^{n}$ be a random sample of $X \sim \Unif(0, \theta)$. Let
  us construct two unbiased estimators for $\theta$ using
  \begin{enumerate}
    \item the sample mean $\overline{X}$; and
    \item order statistics $X_{(n)} \coloneqq \max_{1 \leq i \leq n} \{ X_i \}$.
  \end{enumerate}
\end{eg}

\begin{solution}
  \begin{enumerate}
    \item Observe that
      \begin{equation*}
        E[\overline{X}] = E \left[ \frac{1}{n} \sum_{i=1}^{n} X_i \right] =
        \frac{1}{n} \sum_{i=1}^{n} E[X_i] = \frac{1}{n} \cdot n \left(
        \frac{\theta}{2} \right) = \frac{\theta}{2}.
      \end{equation*}
      This tells us that if we picked $\hat{\theta} = 2\overline{X}$, then we
      would end up with
      \begin{equation*}
        E[2\overline{X}] = \theta.
      \end{equation*}
      Thus $2\overline{X}$ is an unbiased estimator of $\theta$.

    \item Using the \hlnotea{Darth Vader rule} \sidenote{The \hldefn{Darth Vader
      rule} is given as: if $X$ is a \hlimpo{non-negative} rv, then
      \begin{equation*}
        E[X] = \int_{0}^{\infty} \overline{F}_X(x) \dif{x},
      \end{equation*}
      where $\overline{F}_X$ is the survival function of $X$.
      }, since the $X_i$'s form a random sample of $X$, and the bounds for each
      $X_i$ is $0$ and $\theta$, we have that
      \begin{align*}
        E[X_{(n)}]
        &= \int_{0}^{\infty} \overline{F}_{X_{(n)}}(x) \dif{x} \\
        &= \int_{0}^{\infty} \left( 1 - P(\max\{X_1, X_2, \ldots, X_n\}) \leq x
          \right) \dif{x} \\
        &= \int_{0}^{\infty} \left( 1 - P(X_1 \leq x)P(X_2 \leq x)\hdots P(X_n
          \leq x) \right) \dif{x} \\
        &= \int_{0}^{\theta} \left( 1 - (\frac{x}{\theta})^n \right) \dif{x} \\
        &= \theta - \frac{1}{n+1} \left( \frac{x^{n+1}}{\theta^n}
        \right)\at{x=0}{x=\theta} = \frac{n}{n+1} \theta,
      \end{align*}
      where we note that we can change the bounds as such since $X \sim \Unif(0,
      \theta)$ implies that
      \begin{equation*}
        P(X \leq \theta) = \begin{cases}
          \frac{x}{\theta} & 0 \leq x \leq \theta \\
          1                & x > \theta
        \end{cases}.
      \end{equation*}

      Thus, to get an unbiased estimator for $\theta$, we simply need to
      consider
      \begin{equation*}
        \hat{\theta} = \frac{n+1}{n} X_{(n)},
      \end{equation*}
      which then
      \begin{equation*}
        E \left[ \frac{n+1}{n} X_{(n)} \right] = \theta.
      \end{equation*}
  \end{enumerate}
\end{solution}

\begin{propo}[Sample Mean as the Unbiased Estimator of the Mean]\label{propo:sample_mean_as_the_unbiased_estimator_of_the_mean}
  Let $\{ X_i \}_{i=1}^n$ be a random sample of $X$ which has mean $\mu$. Then
  $\overline{X}$ is an unbiased estimator of $\mu$.
\end{propo}

\begin{proof}
  We have that
  \begin{equation*}
    E[\overline{X}] = \frac{1}{n} \sum_{i=1}^{n} E[X_i] = \frac{1}{n} (n\mu) =
    \mu.
  \end{equation*}
\end{proof}

\begin{defn}[Sample Variance]\index{Sample Variance}\label{defn:sample_variance}
  Let $\{ X_i \}_{i=1}^n$ be a random sample of $X$ which has mean $\mu$ and
  variance $\sigma^2$. We define the \hlnoteb{sample variance} as
  \begin{equation*}
    \hat{\sigma}^2 \coloneqq \frac{1}{n-1} \sum_{i=1}^{n} (X_i -
    \overline{X})^2.
  \end{equation*}
\end{defn}

\begin{propo}[Sample Variance as the Unbiased Estimator of the Variance]\label{propo:sample_variance_as_the_unbiased_estimator_of_the_variance}
  Let $\{ X_i \}_{i=1}^n$ be a random sample of $X$ which has mean $\mu$ and
  variance $\sigma^2$. Then the sample variance $\hat{\sigma}^2$ is an unbiased
  estimator of $\sigma^2$.
\end{propo}

\begin{proof}
  First, note that
  \begin{align*}
    \Var(\overline{X}) &= \Var \left( \frac{1}{n} \sum_{i=1}^{n} X_i \right) \\
                       &= \frac{1}{n^2} n \Var(X_i) \\
                       &= \frac{1}{n} \sigma^2.
  \end{align*}
  Thus
  \begin{align*}
    E\left[\sum_{i=1}^{n} (X_i - \overline{X})^2\right]
    &= E \left[ \sum_{i=1}^{n} (X_i - \mu + \mu - \overline{X})^2 \right] \\
    &= \sum_{i=1}^{n} E \left[ (X_i - \mu)^2 \right] + \sum_{i=1}^{n} E \left[
    (\mu - \overline{X})^2 \right] \\
    &\quad + 2E \left[ \sum_{i=1}^{n} (X_i - \mu)(\mu - \overline{X}) \right] \\
    &= n\sigma^2 + n\Var(\overline{X}) \enspace\textcolor{green}{\footnotemark}
      + 2nE[(\overline{X}-\mu)(\mu-\overline{X})]
      \enspace\textcolor{green}{\footnotemark} \\
    &= n\sigma^2 - n\Var(\overline{X}) \\
    &= n\sigma^2 - n \left( \frac{1}{n} \sigma^2 \right) \\
    &= (n-1)\sigma^2.
  \end{align*}
  \footnotetext{This relies on the fact that $\overline{X}$ is the unbiased
  estimator for $\mu$ (cf.
  \cref{propo:sample_mean_as_the_unbiased_estimator_of_the_mean}). We then use the
  definition of the variance to achieve this.}
  \footnotetext{We used the fact that
  \begin{equation*}
    \sum_{i=1}^{n} (X_i - \mu) = \sum_{i=1}^{n} X_i - n\mu = n \overline{X} - n
    \mu.
  \end{equation*}
  Also, note that
  \begin{equation*}
    \Var(\overline{X}) = E[(\overline{X} - \mu)^2].
  \end{equation*}
  }

  It follows that
  \begin{equation*}
    E \left[ \frac{1}{n-1} \sum_{i=1}^{n} (X_i - \overline{X})^2 \right] =
    \sigma^2.
  \end{equation*}
\end{proof}

\begin{remark}
  In general, unbiasedness is \hlimpo{not preserved} under parameter
  transformations. E.g., $\frac{1}{\overline{X}}$ is generally not unbiased for
  $\mu$, where $\mu$ is the mean of $\overline{X}$.
\end{remark}

Some unbiased estimators can also be unreasonable.

\begin{eg}
  Consider $X \sim \Poi(\lambda)$, where $\lambda > 0$. Note that
  \begin{equation*}
    E[(-1)^X] = e^{\lambda(-1-1)} = e^{-2\lambda}
  \end{equation*}
  by the \hlnotea{probability generating function} method, and we see that
  $(-1)^X$ is an unbiased estimator of $e^{-2\lambda}$. However, we see that
  $(-1)^x$ only takes on values $\pm 1$, which is nowhere close to
  $e^{-2\lambda}$.

  Intuitively, $e^{-2 \overline{X}}$ would be a ``better'' estimator despite the
  fact that it is biased.
\end{eg}

Despite shortcomings like the above, unbiasedness is generally a good property
for an estimator to have.

% section unbiased_estimation (end)

\section{Mean Squared Error}%
\label{sec:mean_squared_error}
% section mean_squared_error

\begin{defn}[Mean Squared Error]\index{Mean Squared Error}\label{defn:mean_squared_error}
  Suppose $\hat{\theta}$ is an estimator for the parameter $\theta$. The
  \hlnoteb{mean squared error (MSE)} of $\hat{\theta}$ is defined as
  \begin{equation*}
    \MSE_{\hat{\theta}}(\theta) \coloneqq E \left[ (\hat{\theta} - \theta)^2
    \right] = \Var(\hat{\theta}) + \bias_{\hat{\theta}}(\theta)^2.
  \end{equation*}
\end{defn}

\begin{proof}
  It is not immediately clear how the two expressions are the same. We shall
  prove it here. First, note that $\bias_{\hat{\theta}}(\theta) =
  E[\hat{\theta}] - \theta$ is a real value. Using a similar idea as in
  \cref{propo:sample_variance_as_the_unbiased_estimator_of_the_variance}, we see
  that
  \begin{align*}
    E \left[ \left(\hat{\theta} - \theta\right)^2 \right]
    &= E \left[ \left( \hat{\theta} - E[\hat{\theta}] + E[\hat{\theta}] - \theta
    \right)^2 \right] \\
    &= E\left[(\hat{\theta} - E[\hat{\theta}])^2\right] + E\left[\left(
      E[\hat{\theta}] - \theta \right)^2\right] \\
    &\quad + 2E[(\hat{\theta} - E[\hat{\theta}])(E[\hat{\theta}]-\theta)] \\
    &= \Var(\hat{\theta}) + \bias_{\hat{\theta}}(\theta)^2 \\
    &\quad + 2\bias_{\hat{\theta}}(\theta)\cancelto{0}{E[\hat{\theta} -
      E[\hat{\theta}]]} \\
    &= \Var(\hat{\theta}) + \bias_{\hat{\theta}}(\theta)^2.
  \end{align*}
\end{proof}

\begin{note}
  The MSE is a measure to evaluate the \hlnotea{quality of estimators}. The
  smaller the MSE, the better the estimator.
\end{note}

% section mean_squared_error (end)

\section{Maximum Likelihood Estimation}%
\label{sec:maximum_likelihood_estimation}
% section maximum_likelihood_estimation

\begin{defn}[Likelihood Function]\index{Likelihood Function}\label{defn:likelihood_function}
  Let $\{X_i\}_{i=1}^n$ be a random sample of $X$ with density $f(x;
  \underline{\theta})$, where $\underline{\theta}$ is possibly a vector of
  parameters. The \hlnoteb{likelihood function} for $\underline{\theta}$ is
  defined as
  \begin{equation*}
    L(\underline{\theta}) = \prod_{i=1}^{n} f(X_i; \underline{\theta}).
  \end{equation*}
\end{defn}

\begin{defn}[Maximum Likelihood Estimation]\index{Maximum Likelihood Estimation}\label{defn:maximum_likelihood_estimation}
  The \hlnoteb{maximum likelihood estimation (MLE)} of $\hat{\underline{\theta}}$ of
  $\underline{\theta}$ is an approach that maximizes $L(\hat{\underline{\theta}})$.
\end{defn}

\begin{note}
  Heuristically, under the MLE, $\hat{\underline{\theta}}$ is the \hlnotea{most
  likely parameter} for the sample $(X_1, \ldots, X_n)$ to be realized.
\end{note}

Sometimes, the likelihood function is difficult to work with. Fortunately, since
$\ln x$ is a increasing bijective function that preserves monotonicity, we can
make us of this property to ensure maximality.

\begin{defn}[Log-likelihood Function]\index{Log-likelihood Function}\label{defn:log_likelihood_function}
  The \hlnoteb{log-likelihood function} is defined as
  \begin{equation*}
    l(\underline{\theta}) = \sum_{i=1}^{n} \ln (f(X_i; \underline{\theta})).
  \end{equation*}
\end{defn}

\begin{eg}
  Let $\{ X_i \}_{i=1}^n$ be a random sample for $\Nor(\mu, v)$. Find the MLE
  for $\mu,\, v$.
\end{eg}

\begin{solution}
  First, we shall work on getting an MLE for $\mu$. The likelihood function here
  is
  \begin{align*}
    L(\mu) &= \prod_{i=1}^{n} f(X_i; \mu) \\
           &= \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{(X_i -
           \mu)^2}{2\sigma^2}} \\
           &\propto \exp \left\{ - \frac{1}{2\sigma^2} \sum_{i=1}^{n} (X_i -
           \mu)^2 \right\}.
  \end{align*}
  Evaluating the derivative and equating it to $0$ would be fruitless, since
  this is an exponentiation. Thus we appeal to the log-likelihood, which is
  \begin{align*}
    l(\mu) \propto \sum_{i=1}^{n} (X_i - \mu)^2.
  \end{align*}
  The derivative log-likelihood is thus
  \begin{equation*}
    \frac{\dif{l}}{\dif{\mu}} \propto -2 \sum_{i=1}^{n} (X_i - \mu).
  \end{equation*}
  Equating the above to $0$, we get
  \begin{equation*}
    \hat{\mu} = \overline{X}.
  \end{equation*}

  Now for an MLE of $\sigma^2$. For sanity, let us denote $\tau = \sigma^2$.
  Then the likelihood function, focusing on $\tau$, is
  \begin{align*}
    L(\tau) &= \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\tau}} e^{-\frac{(X_i -
              \mu)^2}{2\tau}} \\
            &\propto \tau^{-\frac{n}{2}} e^{-\frac{1}{2\tau} \sum_{i=1}^{n} (X_i
            - \mu)^2}.
  \end{align*}
  Again, the likelihood involves an exponentiation, so we appeal to the
  log-likelihood, which is
  \begin{equation*}
    l(\tau) \propto -\frac{n}{2} \ln \tau - \frac{1}{2\tau} \sum_{i=1}^{n} (X_i
    - \mu)^2.
  \end{equation*}
  The derivative of the log-likelihood is
  \begin{equation*}
    \frac{\dif{l}}{\dif{\tau}} = -\frac{n}{2\tau} + \frac{1}{2\tau^2}
    \sum_{i=1}^{n} (X_i - \mu)^2.
  \end{equation*}
  Equating the above to $0$, we get
  \begin{equation*}
    n = \frac{1}{\hat{\tau}} \sum_{i=1}^{n} (X_i - \hat{\mu})^2,
  \end{equation*}
  and so
  \begin{equation*}
    \hat{\sigma}^2 = \hat{\tau} = \frac{1}{n} \sum_{i=1}^{n} (X_i -
    \overline{X})^2
  \end{equation*}
\end{solution}

% section maximum_likelihood_estimation (end)

\section{Bayesian Estimation}%
\label{sec:bayesian_estimation}
% section bayesian_estimation

From \citealt{klugman2012},
\begin{quotebox}{magenta}{foreground}
  The Bayesian approach assumes that only the data actually observed are
  relevant and it is the population distribution that is variable.
\end{quotebox}

\begin{defn}[Prior Distribution]\index{Prior Distribution}\label{defn:prior_distribution}
  The \hlnoteb{prior distribution} is a probability distribution over the space
  of possible parameter values. It is denoted $\pi(\theta)$ and represents our
  opinion concerning the relative chances that various values of $\theta$ are
  the true value of the parameter.
\end{defn}

\begin{note}
  \begin{itemize}
    \item The parameter $\theta$ may be scalar or vector valued.
    \item Determining the prior distribution has always been one of the barriers
      to the widespread acceptance of the Bayesian methods, since it is almost
      certainly the case that your experience has provided you with some
      insight about possible parameter values before the first data point has
      been observed.
  \end{itemize}
\end{note}

We shall use the following concepts from multivariate statistics to obtain the
following definitions.

\begin{defn}[Joint Distribution]\index{Joint Distribution}\label{defn:joint_distribution}
  Let $\{ X_i \}_{i=1}^{n}$ be a random sample of the rv $X$, and $\Theta$ 
  another rv that is independent of the $X_i$'s \sidenote{Note that $\Theta$ 
  does not necessarily have a similar distribution to $X$.}, with pdf $\pi$. Let
  $\vec{X} = (X_1, X_2, \ldots, X_n)$. Then the \hlnoteb{joint distribution} of
  $\vec{X}$ and $\Theta$ is defined as
  \begin{equation*}
    f_{\vec{X}, \Theta}(\vec{x}, \theta) = f_{\vec{X} \mid \Theta}(\vec{x} \mid
    \theta) \pi(\theta).
  \end{equation*}
\end{defn}

\begin{defn}[Marginal Distribution]\index{Marginal Distribution}\label{defn:marginal_distribution}
  Let $\{ X_i \}_{i=1}^{n}$ be a random sample of the rv $X$, and $\Theta$ 
  another rv that is independent of the $X_i$'s \sidenote{Note that $\Theta$ 
  does not necessarily have a similar distribution to $X$.}, with pdf $\pi$. Let
  $\vec{X} = (X_1, X_2, \ldots, X_n)$. Then the \hlnoteb{marginal distribution} of
  $\vec{X}$ is defined as
  \begin{equation*}
    f_{\vec{X}}(\vec{x}) = \int f_{\vec{X} \mid \Theta}(\vec{x} \mid
    \theta)\pi(\theta) \dif{\theta}.
  \end{equation*}
\end{defn}

Once we have obtained data, we can look back at our prior distribution and
``update'' it to...

\begin{defn}[Posterior Distribution]\index{Posterior Distribution}\label{defn:posterior_distribution}
  Let $\{ X_i \}_{i=1}^{n}$ be a random sample of the rv $X$, and $\Theta$ 
  another rv that is independent of the $X_i$'s \sidenote{Note that $\Theta$ 
  does not necessarily have a similar distribution to $X$.}, with pdf $\pi$.
  The \hlnoteb{posterior distribution}, denoted by $\pi_{\Theta \mid
  \vec{X}}(\theta \mid \vec{x})$, is the conditional probability distribution of
  the parameters given the observed data.
\end{defn}

It is easy to find out what the general formula of the posterior distribution
is. One simply needs to make use of \cref{defn:joint_distribution} and
\cref{defn:marginal_distribution}. The proof of the following proposition is
left as an easy brain exercise for the reader. \marginnote{
\begin{ex}
  Prove \cref{propo:formula_for_the_posterior_distribution}.
\end{ex}
}

\begin{propo}[Formula for the Posterior Distribution]\label{propo:formula_for_the_posterior_distribution}
  With the assumptions in \cref{defn:posterior_distribution}, we have that the
  posterior distribution can be computed as
  \begin{align*}
    \pi_{\Theta \mid \vec{X}}(\theta \mid \vec{x})
    &= \frac{f_{\vec{X}, \Theta}(\vec{x}, \theta)}{f_{\vec{X}}(\vec{x})} \\
    &= \frac{\left( \prod_{i=1}^{n} f_{X_i \mid \Theta}(x_i \mid \theta) \right)
      \pi(\theta)}{\int_{\forall \theta} \left( \prod_{i=1}^{n} f_{X_i \mid
      \Theta}(x_i \mid \theta) \right) \pi(\theta) \dif{\theta}}.
  \end{align*}
\end{propo}

\begin{defn}[Posterior Mean]\index{Posterior Mean}\label{defn:posterior_mean}
  The \hlnoteb{posterior mean} is defined as the expected value of the posterior
  distribution.
\end{defn}

\begin{defn}[Bayes Estimator]\index{Bayes Estimator}\label{defn:bayes_estimator}
  The \hlnoteb{Bayes estimator} of $\Theta$ is the posterior mean of $\Theta$,
  defined as
  \begin{equation*}
    \hat{\theta}_B \coloneqq E[\Theta \mid \vec{X} = \vec{x}]
    = \int_{\forall \theta} \theta \cdot \pi_{\Theta \mid \vec{X}}(\theta \mid
    \vec{x}).
  \end{equation*}
\end{defn}

\begin{note}
  It can be shown that $\hat{\theta}_B$ minimizes the mean square error
  \begin{equation*}
    \min_{\hat{\theta}} E \left[ \left( \hat{\theta} - \Theta \right)^2 \mid
    \vec{X} = \vec{x} \right].
  \end{equation*}
\end{note}

\subsection{Conjugate Prior Distributions and the Linear Exponential Family}%
\label{sub:conjugate_prior_distributions_and_the_linear_exponential_family}
% subsection conjugate_prior_distributions_and_the_linear_exponential_family

\begin{defn}[Conjugate Prior Distribution]\index{Conjugate Prior Distribution}\label{defn:conjugate_prior_distribution}
  A prior distribution is said to be a \hlnoteb{conjugate prior distribution}
  for a given model if the resulting posterior distribution is from the same
  family as the prior, although possibly with different parameters.
\end{defn}

\sidenote{More examples should be added here.}
\begin{eg}\label{eg:conjugate_prior_distributions_egs}
  The following are some important/prominent examples of conjugate prior
  distributions:
  \begin{table}[ht]
    \centering
    \caption{Important/Prominent Conjugate Prior Distributions}
    \label{table:important_prominent_conjugate_prior_distributions}
    \begin{tabular}{c c c}
      $\pi(\theta)$ & $f(x \mid \theta)$ & $\pi(\theta \mid \vec{x})$ \\
      \hline
      Gamma         & Poisson            & Gamma \\
      Normal        & Normal             & Normal \\
      Beta          & Binomial           & Beta \\
      Beta          & Geometric          & Beta
    \end{tabular}
  \end{table}
\end{eg}

\begin{defn}[Linear Exponential Family]\index{Linear Exponential Family}\label{defn:linear_exponential_family}
  An rv $X$ is said to belong to the \hlnoteb{linear exponential family} if its
  pdf is of the form
  \begin{equation*}
    f(x,\theta) = \frac{p(x)e^{xr(\theta)}}{q(\theta)},
  \end{equation*}
  where $p(x)$ is some function of $x$, and $r(\theta), q(\theta)$ are some
  functions of $\theta$, and the support of $f$ does not depend on $\theta$.
\end{defn}

\marginnote{
\begin{mnote}
  Basically, functions the belong to a linear exponential family is a
  linear-like function with an exponent.
\end{mnote}
}

\begin{eg}
  Some members of the linear exponential family include
  \begin{itemize}
    \item $\Exp(\theta): f(x, \theta) = \frac{1}{\theta}
      e^{-\frac{x}{\theta}}$, where $p(x) = 1$, $r(\theta) = -\frac{1}{\theta}$ 
      and $q(\theta) = \theta$.
    \item $\Gam(\alpha, \theta): f(x, \alpha, \theta) =
      \frac{1}{\Gamma(\alpha)\theta^\alpha} x^{\alpha - 1}
      e^{-\frac{x}{\theta}}$.
    \item $\Poi(\theta): f(x, \theta) = \frac{\theta^x e^{-\theta}}{x!} =
      \frac{\frac{1}{x!} e^{x \ln \theta}}{e^\theta}$
    \item $\Nor(\theta, v) : f(x, \theta, v) = \frac{1}{\sqrt{2\pi v}}
      e^{-\frac{(x-\theta)^2}{2v}} = \frac{(2\pi v)^{-\frac{1}{2}}
      e^{-\frac{x^2}{2v}} e^{x \frac{\theta}{v}}}{e^{\theta^2 / 2v}}$
  \end{itemize}
\end{eg}

\begin{thm}[Conjugate Prior Distributions of Linear Exponential Distributions]\label{thm:conjugate_prior_distributions_of_linear_exponential_distributions}
  Suppose that given $\Theta = \theta$ the rvs $\vec{X}$ are iid with pf
  \begin{equation*}
    f_{X_j \mid \Theta} (x_j \mid \theta) = \frac{p(x_j)e^{r(\theta)
    x_j}}{q(\theta)},
  \end{equation*}
  where $\Theta$ has the pdf
  \begin{equation*}
    \pi(\theta) = \frac{[q(\theta)]^{-k} e^{\mu kr(\theta)} r'(\theta)}{c(\mu,
    k)},
  \end{equation*}
  where $\mu$ and $k$ are parameters of the distribution and $c(\mu, k)$ is the
  \hldefn{normalizing constant} \sidenote{The normalizing constant is used to
  reduce any probability function to a probability density function with a total
  probability of $1$. (Source:
  \href{https://en.wikipedia.org/wiki/Normalizing_constant}{Wikipedia})}. Then
  the posterior pf $\pi_{\Theta \mid \vec{X}}(\theta \mid \vec{x})$ is of the
  same form as $\pi(\theta)$, i.e. $\pi(\theta)$ is a conjugate prior
  distribution function.
\end{thm}

\begin{proof}
  Notice that the posterior distribution is
  \begin{align*}
    \pi(\theta \mid \vec{x})
    &= \frac{\left( \prod_{i=1}^{n} f_{X_i \mid \Theta}(x_i \mid \theta) \right)
      \pi(\theta)}{\int_{\forall \theta} \left( \prod_{i=1}^{n} f_{X_i \mid
      \Theta}(x_i \mid \theta) \right) \pi(\theta) \dif{\theta}} \\
    &\propto \left( \prod_{i=1}^{n} f_{X_i \mid \Theta}(x_i \mid \theta)
      \pi(\theta) \right) \\
    &= \left( \prod_{i=1}^{n} \frac{p(x_j)e^{r(\theta) x_j}}{q(\theta)} \right)
      \left( \frac{[q(\theta)]^{-k} e^{\mu kr(\theta)} r'(\theta)}{c(\mu, k)}
      \right) \\
    &\propto q(\theta)^{-(n+k)} e^{\mu k + n \overline{x} r(\theta)} r'(\theta)
    \\
    &= q(\theta)^{-k^*} e^{\mu^* k^* r(\theta)} r'(\theta),
  \end{align*}
  where
  \begin{equation*}
    k^* = k + n, \text{ and } \mu^* = \frac{\mu k + \sum x_j}{k + n} =
    \frac{k}{k + n} \mu + \frac{n}{k + n} \overline{x},
  \end{equation*}
  and we see that the posterior distribution has the same form as
  $\pi(\theta)$.
\end{proof}

\begin{eg}
  One non-example is mentioned in \cref{eg:conjugate_prior_distributions_egs}:
  the distribution of $X_i$ is not from the linear exponential family, but we
  still obtain that the posterior distribution has a similar distribution to the
  posterior distribution.
\end{eg}

% subsection conjugate_prior_distributions_and_the_linear_exponential_family (end)

% section bayesian_estimation (end)

% chapter review_of_statistics (end)

\chapter{Limited Fluctuation Credibility Theory}%
\label{chp:limited_fluctuation_credibility_theory}
% chapter limited_fluctuation_credibility_theory

The Limited Fluctuation Credibility Theory provides a mechanism for assigning
\hlnotea{full} or \hlnotea{partial credibility} to a policyholder's experience.
The difficulty with this approach is its lack of a sound underlying mathematical
theory that justifies the use of these methods. Despite that fact, it is still
widely used today, especially in the United States.

\section{Limited Fluctuation Credibility}%
\label{sec:limited_fluctuation_credibility}
% section limited_fluctuation_credibility

From \citealt{klugman2012},
\begin{quotebox}{magenta}{foreground}
  This branch of credibility theory represents the first attempt to quantify the
  credibility problem.
\end{quotebox}
This approach is also known as the ``\hldefn{American credibility}''. It was
first proposed by Mowbray in 1914 \cite{mowbray1914}.

The problem can be formulated as follows. Suppose that $\{ X_i \}_{i=1}^n$
represents a policyholder's claim amounts in the past $n$ years. Furthermore, we
assume that the $X_i$'s have
\begin{itemize}
  \item the same expected value, i.e. $E[X_i] = \mu$ for some $\mu$; and
  \item variance, i.e. $\Var(X_i) = \sigma^2$ for some $\sigma$.
\end{itemize}
From our revision in the last section, we know that $\overline{X}$ is an
unbiased estimator for $\mu$, and if the $X_i$'s are independent, then
$\Var(\overline{X}) = \frac{\sigma^2}{n}$.

The goal here is to figure our how much to charge for the next premium, i.e.
determining $E[X_{n+1}]$. We have at least the following 3 possibilities:
\begin{itemize}
  \item ignore past data (no credibility) and charge $M$, a value, called the
    \hldefn{manual premium} \sidenote{This name is obtained from the fact that
    it usually comes from a book (manual) of premiums.}, obtained from
    experience on other similar but non-identical policyholders;
  \item ignore $M$ and charge $\overline{X}$ (full credibility); and a third
    possibility is to
  \item choose some combination of $M$ and $\overline{X}$ (partial
    credibility).
\end{itemize}

From the POV of an insurer, it seems sensible to favor $\overline{X}$ if the
experience is ``stable'', i.e. there is little fluctuation, represented by a
small $\sigma^2$. Stable values imply that $\overline{X}$ is more reliable as a
predictor. Conversely, if $\overline{X}$ is volatile, then $M$ would be a safer
choice.

% section limited_fluctuation_credibility (end)

\section{Full Credibility}%
\label{sec:full_credibility}
% section full_credibility

In \hldefn{full credibility} theory, there are only 2 outcomes: either we
\begin{itemize}
  \item assign full credibility, that is to charge $\overline{X}$; or
  \item no credibility, where we charge $M$.
\end{itemize}
One method to `quantify the stability' of $\overline{X}$ \sidenote{This has become the
standard method for `quantifying stability' for $\overline{X}$.} is to infer
that $\overline{X}$ is stable if the difference between $\overline{X}$ and $\mu$
is small relative to $\mu$ with high probability, i.e.
\begin{equation}\label{eq:full_cred_cond}
  P(\abs{\overline{X} - \mu} \leq \epsilon \mu) \geq p
\end{equation}
for some $\epsilon > 0$ and $0 < p < 1$. We may rewrite
\cref{eq:full_cred_cond} as
\begin{equation*}
  P \left( \frac{\abs{\overline{X} - \mu}}{\sigma / \sqrt{n}} \leq
  \frac{\epsilon\mu}{\sigma / \sqrt{n}} \right) \geq p.
\end{equation*}

Now let $y_p$ be defined as by
\begin{equation*}
  y_p = \VaR_p \left( \frac{\abs{\overline{X} - \mu}}{\sigma / \sqrt{n}} \right)
  = \inf \left\{ y \in \mathbb{R} : P \left( \frac{\abs{\overline{X} -
  \mu}}{\sigma / \sqrt{n}} \leq y \right) \geq p \right\}.
\end{equation*}
If $\overline{X}$ is continuous, then the $\geq$ sign above can be replaced with
an ``$=$'' sign \sidenote{See
\href{https://tex.japorized.ink/ACTSC431/classnotes.pdf}{ACTSC431}.}, and $y_p$
satisfies
\begin{equation}\label{eq:set_stage_for_clt_for_y_p}
  P \left( \frac{\abs{\overline{X} - \mu}}{\sigma / \sqrt{n}} \leq y_p \right) = p.
\end{equation}
Then the condition for full credibility is
\begin{equation*}
  y_p \leq \frac{\epsilon\mu}{\sigma / \sqrt{n}}.
\end{equation*}
\marginnote{
\begin{procedure}[Condition for Full Credibility]\label{procedure:condition_for_full_credibility}
  \begin{enumerate}
    \item Use the central limit theorem argument for $y_p$.
    \item Calculate RHS of \cref{eq:num_of_exposure_for_full_cred}.
  \end{enumerate}
\end{procedure}
}
Making $n$ the subject, we have that the number of exposure required for full
credibility is thus
\begin{equation}\label{eq:num_of_exposure_for_full_cred}
  n \geq \left( \frac{y_p}{\epsilon} \right)^2 \frac{\sigma^2}{\mu^2} =
  \lambda_0 \frac{\sigma^2}{\mu^2},
\end{equation}
where we let $\lambda_0 = \left(\frac{y_p}{\epsilon}\right)^2$ for notational
succinctness since it is a constant that depends only $p$ and $\epsilon$.

It is often difficult to identify a distribution for $\overline{X}$, of which
$y_p$ depends on. Recall the \hlnotea{normal approximation}, which is applicable
if $n$ is large \sidenote{\hlwarn{Is this not circular!?}}:
\begin{equation*}
  \frac{\overline{X} - \mu}{\sigma / \sqrt{n}} \approx Z_{0, 1} \sim \Nor(0, 1)
\end{equation*}
Then \cref{eq:set_stage_for_clt_for_y_p} becomes
\begin{align*}
  p &= P(\abs{Z} \leq y_p) = \Phi(y_p) - \Phi(-y_p) \\
    &= \Phi(y_p) - 1 + \Phi(y_p) = 2 \Phi(y_p) - 1.
\end{align*}
Thus
\begin{equation*}
  y_p \approx \Phi^{-1} \left( \frac{1 + p}{2} \right).
\end{equation*}

\begin{eg}
  Suppose that one has data $\{ X_i \}_{i=1}^{10}$ on the claim amounts in the
  last 10 periods, where
  \begin{equation*}
    X_i = 0 \text{ for } i = 1, \ldots, 6,
  \end{equation*}
  and
  \begin{equation*}
    X_7 = 253,\, X_8 = 398,\, X_9 = 439,\, X_{10} = 756.
  \end{equation*}
  Determine the condition for full credibility with $\epsilon = 0.05$ and $p =
  0.9$.
\end{eg}

\begin{solution}
  We need to first determine the sample mean and sample variance, and we shall
  use the unbiased estimators of $\mu$ and $\sigma^2$ respectively: they are
  \begin{equation*}
    \overline{X} = \frac{1}{10} \sum_{i=1}^{10} X_i = \frac{0 + 253 + 398 + 439 +
    756}{10} = 184.6,
  \end{equation*}
  and
  \begin{equation*}
    \hat{\sigma}^2 = \frac{1}{10-1} \sum_{i=1}^{10} (X_i - \overline{X})^2 =
    267.89^2.
  \end{equation*}
  We also need
  \begin{equation*}
    y_p = \Phi^{-1} \left( \frac{1 + p}{2} \right) = \Phi^{-1} (.95) = 1.645.
  \end{equation*}
  Then we require that
  \begin{equation*}
    n \geq \left( \frac{1.645}{0.05} \right)^2 \left( \frac{267.89^2}{184.6^2}
    \right) = 2279.5.
  \end{equation*}
  We see that the $10$ observations definitely do not deserve full credibility.
\end{solution}

Full credibility is sometimes given on a number of claims basis (instead of on
the claims amount).

\begin{eg}\label{eq:simple_example_for_full_cred_with_poisson}
  Suppose that one has iid data $\{ N_i \}_{i=1}^n$ on the number of claims in
  the past $n$ periods, with $N_i \sim \Poi(\lambda)$. Determine the condition
  for full credibility in terms of the \textbf{expected total number of claims}
  given that $p = 0.9$ and $\epsilon = 0.05$.
\end{eg}

\begin{solution}
  Since $N_i \sim \Poi(\lambda)$, we have $E[N_i] = \lambda = \Var(N_i)$.
  Furthermore,
  \begin{equation*}
    y_p = \Phi^{-1} \left( 0.95 \right) = 1.645.
  \end{equation*}
  Now since the condition is
  \begin{equation*}
    n \geq \lambda_0 \frac{\sigma^2}{\mu^2} = \frac{\lambda_0}{\lambda},
  \end{equation*}
  and we want the expected total number of claims, we focus on looking at
  \begin{equation*}
    n \mu = n \lambda \geq \lambda_0.
  \end{equation*}
  Observe that
  \begin{equation*}
    \lambda_0 = \left( \frac{1.645}{0.05} \right)^2 = 1082.41,
  \end{equation*}
  we have that the required expected total number of claims should fulfill
  \begin{equation*}
    n\lambda \geq 1082.41.
  \end{equation*}
\end{solution}

\begin{eg}[Compound Poisson for Full Credibility]\label{eg:compound_poisson_for_full_credibility}
  Let $\{ X_i \}_{i=1}^n$ be a sequence of iid compound Poisson rvs, given by
  \begin{equation*}
    X_i = \sum_{j=1}^{N_i} Y_{i, j} = \begin{cases}
      \sum_{j=1}^{N_i} Y_{i, j}, & N_i \geq 0 \\
      0                          & N_i = 0
    \end{cases},
  \end{equation*}
  where
  \begin{itemize}
    \item $\{ N_i \}_{i=1}^{n}$ are iid with $N_i \sim \Poi(\lambda)$ for each
      $i$; and
    \item $\{ Y_{i, j} \}$ are also iid with mean $\mu_Y$ and variance
      $\sigma^2_Y$.
  \end{itemize}
  Determine the condition for full credibility.
\end{eg}

\begin{solution}
  We require the unconditional sample mean and sample variance of $X_i$; they
  are
  \begin{equation*}
    E[X_i] = E[E[X_i \mid N_i]] = E[N_i]E[Y_{i, j}] = \lambda \mu_Y,
  \end{equation*}
  and
  \begin{align*}
    \Var(X_i) &= \Var(E[X_i \mid N_i]) + E[\Var(X_i \mid N_i)] \\
              &= \Var(N_i \mu_Y) + E[N_i \sigma^2_Y] \\
              &= \mu_Y^2 \lambda + \sigma^2_Y \lambda \\
              &= \lambda (\mu^2_Y + \sigma^2_Y).
  \end{align*}
  Thus, the condition for full credibility is
  \begin{equation*}
    n \geq \lambda_0 \frac{\lambda(\mu^2_Y + \sigma^2_Y)}{\lambda^2 \mu^2_Y} =
    \frac{\lambda_0}{\lambda} \left( 1 + \frac{\sigma^2_Y}{\mu^2_Y} \right).
  \end{equation*}
\end{solution}

To further illustrate that we can use the concept of full credibility for
different things, the following example is provided.

\begin{eg}\label{eg:full_cred_on_different_basis}
  Suppose that the average claim size for a group of insureds is $1500$ with a
  standard deviation of $7500$. Furthermore, assume that claim counts have a
  Poisson distribution. For $\epsilon = 0.06$ and $p = 0.9$, determine the
  standard for full credibility based on the
  \begin{enumerate}
    \item total claim amount; and
    \item total number of claims,
  \end{enumerate}
  in terms of the expected total number of claims.
\end{eg}

\begin{solution}
  \begin{enumerate}
    \item Using the last example and letting
      \begin{equation*}
        E[X_i] = \mu   \text{ and } \Var(X_i) = \Var(X_i) = \sigma^2,
      \end{equation*}
      the standard for full credibility is
      \begin{equation*}
        n \geq \frac{\lambda_0}{\lambda} \left( 1 +
        \frac{\sigma^2_Y}{\mu^2_Y} \right).
      \end{equation*}
      We are given that
      \begin{equation*}
        \mu_Y = 1500 \text{ and } \sigma^2_Y = 7500^2.
      \end{equation*}
      Thus
      \begin{equation*}
        n \geq \frac{1.645^2}{0.06^2 \lambda} \left( 1 + \frac{7500^2}{1500^2}
        \right) = \frac{19543.51}{\lambda}.
      \end{equation*}
      In terms of the expected total number of claims, we have
      \begin{equation*}
        n\lambda \geq 19543.51.
      \end{equation*}
      Thus the observed total number of claims of past claims must be at least
      $19544$ to assign full credibility.

    \item Using \cref{eq:simple_example_for_full_cred_with_poisson}, we have
      \begin{equation*}
        n \geq \frac{\lambda_0}{\lambda} = \frac{751.67}{\lambda}.
      \end{equation*}
      Thus, in terms of the expected total number of claims, we have
      \begin{equation*}
        n\lambda \geq 751.67.
      \end{equation*}
      Therefore, the observed total number of past claims must be at least $752$ 
      to assign full credibility.
  \end{enumerate}
\end{solution}

% section full_credibility (end)

\section{Partial Credibility}%
\label{sec:partial_credibility}
% section partial_credibility

If full credibility is inappropriate, then we may want to assign \hldefn{partial
credibility} to the past experience $\overline{X}$ in the net premium. Without
much mathematical support, it was suggested that we let the net premium be
defined as a weighted average of $\overline{X}$ and the manual premium $M$,
i.e.
\begin{equation*}
  P = Z \overline{X} + (1 - Z) M,
\end{equation*}
where $Z \in [0, 1]$ is known as the \hldefn{credibility factor} \sidenote{It is
important to note there that $Z$ is not an rv. It is simply a pretentious choice
of notation for what is to come.} \sidenote{It is interesting to remark that
\citealt{mowbray1914} considered full but not partial credibility.}, which is a
value that needs to be chosen.

In the actuarial literature \cite{klugman2012}, there are various suggestions
for determining $Z$. However, they are usually justified on intuition rather
than theoretically sound grounds. We shall discuss one of the choices here,
which is flawed, but is at least simple.

Recall that the goal of the full-credibility standard is to ensure that the
difference between $\overline{X}$ and $\mu$ is small with high probability (cf.
beginning of \cref{sec:full_credibility}). Since $\overline{X}$ is unbiased, to
achieve this standard is basically \sidenote{This is exactly the case if
$\overline{X}$ is normal.} equivalent to controlling the variance of
$\overline{X}$. Note that full credibility fails when
\begin{equation}\label{eq:failure_of_full_cred}
  n < \lambda_0 \left( \frac{\sigma^2}{\mu^2} \right),
\end{equation}
and since the sample variance (which is unbiased for the variance) is
\begin{equation*}
  \Var(\overline{X}) = \frac{\sigma^2}{n},
\end{equation*}
rearranging \cref{eq:failure_of_full_cred}, we have that
\begin{equation*}
  \Var(\overline{X}) = \frac{\sigma^2}{n} > \frac{\mu^2}{\lambda_0}.
\end{equation*}
Thus, we choose $Z$ such that it controls the variance of the credibility
premium as such:
\begin{align*}
  \frac{\mu^2}{\lambda_0} &= \Var(P) = \Var(Z \overline{X} + (1 - Z)M) \\
                          &= Z^2 \Var(\overline{X}) = Z^2 \cdot
                          \frac{\sigma^2}{n}.
\end{align*}
Thus, since we want $Z$ as a weighted average, we let
\begin{equation*}
  Z = \min \left\{ \frac{\mu}{\sigma} \sqrt{\frac{n}{\lambda_0}}, 1 \right\}.
\end{equation*}
\sidenote{Note that this choice of $Z$ has some consistency with full
credibility, since $Z = 1$ iff $n \geq \lambda_0 \frac{\sigma^2}{\mu^2}$.} Note
that
\begin{equation*}
  \frac{\mu}{\sigma} \sqrt{\frac{n}{\lambda_0}} = \sqrt{\frac{n}{\lambda_0
  (\frac{\sigma^2}{\mu^2})}},
\end{equation*}
which is the square root of the \hlnotea{actual number of exposures} divided by
the \hlnotea{number of exposures needed for full credibility}. This is also
referred to as the \hldefn{Square-root rule for partial credibility}.

\begin{eg}
  Suppose that past observations of the number of claims $\{ N_i \}_{i=1}^{n}$ 
  are iid and $N_i \sim \Poi(\lambda)$. Determine the credibility factor $Z$ 
  based on the number of claims.
\end{eg}

\begin{solution}
  Note that
  \begin{equation*}
    \mu = E[N_i] = \lambda \text{ and } \sigma^2 = \Var(N_i) = \lambda.
  \end{equation*}
  We have that
  \begin{equation*}
    Z = \min \left\{ \frac{\mu}{\sigma} \sqrt{\frac{n}{\lambda_0}}, 1 \right\}
    = \min \left\{ \sqrt{\frac{n\lambda}{\lambda_0}}, 1 \right\}.
  \end{equation*}
\end{solution}

\begin{eg}
  Consider the setup in \cref{eg:compound_poisson_for_full_credibility}.
  Determine the credibility factor $Z$ based on the amount of claims.
\end{eg}

\begin{solution}
  We have that
  \begin{equation*}
    \mu = E[X_i] = \lambda \mu_Y \text{ and } \sigma^2 = \Var(X_i) = \lambda
    (\mu^2_Y + \sigma^2_Y).
  \end{equation*}
  Then since
  \begin{equation*}
    \frac{\mu}{\sigma} \sqrt{\frac{n}{\lambda_0}} =
    \sqrt{\frac{n\lambda}{\lambda_0} \cdot \frac{\mu^2_Y}{\mu^2_Y +
    \sigma^2_Y}},
  \end{equation*}
  we have that
  \begin{equation*}
    Z = \min \left\{ \sqrt{\frac{n\lambda}{\lambda_0} \cdot \frac{\mu^2_Y}{\mu^2_Y +
    \sigma^2_Y}}, 1 \right\}
  \end{equation*}
\end{solution}

\newthought{Different credibility factors} may arise depending on the basis of
which the credibility is founded upon.

\begin{eg}
  Consider the setup in \cref{eg:full_cred_on_different_basis}. Further suppose
  that
  \begin{itemize}
    \item in thelast year, this group of insureds had $600$ claims and a total
      loss of $15600$ ; and
    \item the prior estimate of the total loss was $16500$ (this is $M$).
  \end{itemize}
  Estimate the credibility premium for the group based on the
  \begin{enumerate}
    \item total claim amount; and
    \item total number of claims.
  \end{enumerate}
\end{eg}

\begin{solution}
  \begin{enumerate}
    \item We are given that $\mu_Y = 1500$, $\sigma_Y = 7500$ and $n \lambda =
      600$. Thus
      \begin{align*}
        Z &= \min \left\{ \sqrt{\frac{n\lambda}{\lambda_0} \cdot
          \frac{\mu^2_Y}{\mu^2_Y + \sigma^2_Y}}, 1 \right\} \\
          &= \min \left\{ \sqrt{\frac{600}{\left(\frac{1.645}{0.06}\right)^2}
          \cdot \frac{1500^2}{1500^2 + 7500^2}}, 1 \right\} \\
          &= 0.17522
      \end{align*}
      Thus the credibility premium for the group is
      \begin{align*}
        P &= 0.17522 \overline{X} + (1-0.17522)M \\
          &= 0.17522 (15600) + (1-0.17522)(16500) \\
          &= 16342.302
      \end{align*}
      \sidenote{It is important to note here that $\overline{X} = 15600$ in this
      case, since this is the total loss over `$1$' period of time, in particular
      it is the total amount up to the latest time.}

    \item Based on the total number of claims, the credibility factor is
      \begin{equation*}
        Z = \min \left\{ \sqrt{\frac{n\lambda}{\lambda_0}}, 1 \right\}
        = \min \left\{ \sqrt{\frac{600}{\left( \frac{1.645}{0.06} \right)^2}}, 1
        \right\}
        = 0.89343.
      \end{equation*}
      Thus the credibility premium for the group is
      \begin{equation*}
        P = 0.89343 \overline{X} + (1-0.89343) M = 15696.
      \end{equation*}
  \end{enumerate}
\end{solution}

% section partial_credibility (end)

\section{Problems with Limited Fluctuation Credibility}%
\label{sec:problems_with_limited_fluctuation_credibility}
% section problems_with_limited_fluctuation_credibility

\begin{itemize}
  \item There is no theoretical model for the distribution of $X_i$'s, and so
    there is no reason why
    \begin{equation*}
      P = Z \overline{X} + (1 - Z) M
    \end{equation*}
    is a reasonable and more preferable to $M$.
  \item The choice of $Z$ is rather arbitrary.
  \item There is no guidance to the choices of $\epsilon$ and $p$.
  \item The limited fluctuation approach does not examine the difference between
    $\mu$ and $M$. Furthermore, it is usually the case that $M$ is also an
    estimate, and hence unreliable in itself.
\end{itemize}

% section problems_with_limited_fluctuation_credibility (end)

% chapter limited_fluctuation_credibility_theory (end)

\chapter{Greatest Accuracy Credibility}%
\label{chp:greatest_accuracy_credibility}
% chapter greatest_accuracy_credibility

The \hldefn{Greatest Accuary Credibility} approach is a model-based approach to
the solution of the credibility problem, which is an outgrowth of B\"{u}hlmann's
classic paper in 1967 \cite{buhlmann1967}. The greater accuracy credibility is
also called the \hldefn{European credibility}.

In greatest accuracy credibility, we assume that all risk units in a given
rating class have an \hlnotea{unknown risk parameter} $\theta$ that is
associated with their risk level. Since different insureds have different
$\theta$ values, risk units within a rating class are \hlnotea{not completely
homogeneous}. This assumption allows us to quantify the differences between
policyholders wrt to the risk characteristics.

\begin{note}[Assumptions]
  We shall also always assume that $\theta$ exists, but we shall assume that it
  is not observable, and that we can never know its true value.
  
  Since $\theta$ varies by policyholder, there is a probability distribution
  $\Theta$ across the rating class. We denote
  \begin{itemize}
    \item $\pi_{\Theta}(\theta)$ as the probability distribution of $\Theta$; and
    \item $\Pi_{\Theta}(\theta)$ as the cdf of $\Theta$.
  \end{itemize}
  If $\theta$ is a \hlnotea{scalar parameter} \sidenote{Refer to
  \href{https://tex.japorized.ink/STAT330S18/classnotes.pdf\#defn.20}{STAT330}.},
  then we may interpret
  \begin{equation*}
    \Pi(\theta) = P(\Theta \leq \theta)
  \end{equation*}
  as the percentage of policyholders in the rating class with risk parameter
  $\Theta$ less than or equal to $\theta$.

  Furthermore, if we let $\{ X_i \}_{i=1}^n$ be the past exposure units
  \sidenote{which is not necessarily iid}, we will suppose that
  \begin{equation*}
    \{ X_i \mid \Theta = \theta \}_{i=1}^n
  \end{equation*}
  are iid, with common density function $f_{X \mid \Theta}(x \mid \theta)$.
\end{note}

We want to use these assumptions to derive a rate to cover for $X_{n+1}$.

\section{The Bayesian Methodology}%
\label{sec:the_bayesian_methodology}
% section the_bayesian_methodology

\begin{defn}[Predictive Distribution]\index{Predictive Distribution}\label{defn:predictive_distribution}
  The \hlnoteb{predictive distribution} is the conditional probability
  distribution of a new observation $y$ given the data $\vec{x}$. It is denoted
  as $f_{Y \mid \vec{X}}(y \mid \vec{x})$.
\end{defn}

\begin{propo}[Formula for Predictive Distribution]\label{propo:formula_for_predictive_distribution}
  Given exposure units $\{ X_i \}_{i=1}^n$, the predictive distribution of a new
  observation, $Y$, can be computed as
  \begin{equation*}
    f_{Y \mid \vec{X}}(y \mid \vec{x}) = \int_{\forall \theta} f_{Y \mid
    \Theta}(y \mid \theta) \pi_{\Theta \mid \vec{X}}(\theta \mid \vec{x}).
  \end{equation*}
\end{propo}

\begin{proof}
  By the \hyperref[propo:formula_for_the_posterior_distribution]{formula for the
  posterior distribution}, we have that
  \begin{align*}
    \pi_{\Theta \mid \vec{X}}(\theta \mid \vec{x})
    &= \frac{f_{\Theta, \vec{X}}(\theta, \vec{x})}{f_{\vec{X}}(\vec{x})} \\
    &= \frac{f_{\vec{X} \mid \Theta}(\vec{x} \mid
      \theta)\pi(\theta)}{\int_{\forall \theta} f_{\vec{X} \mid \Theta}(\vec{x}
      \mid \theta) \pi(\theta) \dif{\theta}}.
  \end{align*}
  Also, observe that
  \begin{align*}
    f_{Y, \vec{X}}(y, \vec{x})
    &= \int_{\forall \theta} f_{(Y, \vec{X}) \mid \Theta}(y, \vec{x} \mid
      \theta) \pi(\theta) \dif{\theta} \\
    &= \int_{\forall \theta} f_{Y \mid \Theta}(y \mid \theta) f_{\vec{X} \mid
    \Theta}(\vec{x} \mid \theta) \pi(\theta) \dif{\theta},
  \end{align*}
  where the second equality follows from our assumption that the conditional
  observations are independent. Then
  \begin{align*}
    f_{Y \mid \vec{X}}(y \mid \vec{x})
    &= \frac{f_{Y, \vec{X}}(y, \vec{x})}{f_{\vec{X}}(\vec{x})} \\
    &= \frac{\int_{\forall \theta} f_{Y \mid \Theta}(y \mid \theta) f_{\vec{X}
      \mid \Theta}(\vec{x} \mid \theta) \pi(\theta) \dif{\theta}}{\int_{\forall
      \theta} f_{\vec{X} \mid \Theta}(\vec{x} \mid \theta) \pi(\theta)
      \dif{\theta}} \\
    &= \int_{\forall \theta} f_{Y \mid
      \Theta}(y \mid \theta) \pi_{\Theta \mid \vec{X}}(\theta \mid \vec{x}).
  \end{align*}
\end{proof}

\begin{defn}[Individual Premium]\index{Individual Premium}\label{defn:individual_premium}
  Given the $X_{n+1}$ exposure unit and risk $\Theta$, we define the
  \hlnoteb{individual premium} (or \hldefn{hypothetical mean}) of $X_{n+1}$ as
  \begin{equation*}
    \mu_{n + 1}(\theta) = E[X_{n+1} \mid \Theta = \theta].
  \end{equation*}
\end{defn}

\begin{defn}[Pure Premium]\index{Pure Premium}\label{defn:pure_premium}
  We define the \hlnoteb{pure premium} (or \hldefn{collective premium}) of
  $X_{n+1}$ as
  \begin{equation*}
    \mu_{n + 1} = E[X_{n+1}].
  \end{equation*}
\end{defn}

\begin{defn}[Bayesian Premium]\index{Bayesian Premium}\label{defn:bayesian_premium}
  The \hlnoteb{Bayesian premium} of $X_{n+1}$ is defined as
  \begin{equation*}
    E[X_{n+1} \mid \vec{X}] = \int_{\forall \theta} \mu_{n+1}(\theta)
    \pi_{\Theta \mid \vec{X}}(\theta \mid \vec{x}) \dif{\theta}.
  \end{equation*}
\end{defn}

\begin{eg}
  The number of claims for a policyholder in year $i$ is $X_i$ for $i = 1, 2$.
  Suppose that $X_1 \mid \Theta = \theta$ and $X_2 \mid \Theta = \theta$ are iid
  with pmf
  \begin{equation*}
    P(X = 1 \mid \Theta = \theta) = 1 - \theta,
  \end{equation*}
  and
  \begin{equation*}
    P(X = 2 \mid \Theta = \theta) = \theta.
  \end{equation*}
  The prior distribution is given as $\Theta \sim \BetaDist(2, 3)$. Determine
  the Bayesian premium $E[X_2 \mid X_1 = 2]$.
\end{eg}

\begin{solution}
  \hlbnoted{Method 1: Using predictive distribution} Observe that
  \begin{align*}
    P(X_2 = 2 \mid X_1 = 2)
    &= \int_{\forall \theta} P(X_2 = 2 \mid \Theta = \theta) \pi_{\Theta \mid
      X_1}(\theta \mid x_1) \dif{\theta} \\
    &= \int_{\forall \theta} \theta \cdot \frac{f_{X_1 \mid \Theta}(2 \mid
      \theta) \pi(\theta)}{\int_{\forall \theta} f_{X_1 \mid \Theta}(x_1 \mid
      \theta) \pi(\theta) \dif{\theta}} \dif{\theta} \\
    &= \int_{\forall \theta} \frac{\theta^2 \pi(\theta)}{E[\Theta]} \dif{\theta}
    \\
    &= \frac{E[\Theta^2]}{E[\Theta]} = \frac{\frac{1}{5}}{\frac{2}{5}} =
    \frac{1}{2}.
  \end{align*}
  Thus
  \begin{equation*}
    P(X_2 = 1 \mid X_1 = 2) = 1 - \frac{1}{2} = \frac{1}{2}.
  \end{equation*}
  Hence
  \begin{equation*}
    E[X_2 \mid X_1 = 2] = 1 \cdot \frac{1}{2} + 2 \cdot \frac{1}{2} =
    \frac{3}{2}.
  \end{equation*}

  \noindent
  \hlbnoted{Method 2: Using Bayesian premium formula} We have that
  \begin{align*}
    E[X_2 \mid X_1 = 2]
    &= \int_{\forall \theta} E[X_2 \mid \Theta = \theta] \pi_{\Theta \mid
      X_1}(\theta \mid 2) \dif{\theta} \\
    &= \int_{\forall \theta} [1(1 - \theta) + 2\theta] \cdot
    \frac{P(X_1 = 2 \mid \Theta = \theta)\pi(\theta)}{\int_{\forall \theta} P(X1
      = 2 \mid \Theta = \theta)\pi(\theta) \dif{\theta}} \dif{\theta} \\
    &= \int_{\forall \theta} \frac{(1 + \theta)\theta\pi(\theta)}{E[\Theta]}
      \dif{\theta} \\
    &= \frac{E[\Theta] + E[\Theta^2]}{E[\Theta]} \\
    &= \frac{\frac{2}{5} + \frac{1}{5}}{\frac{2}{5}} = \frac{3}{2}.
  \end{align*}
\end{solution}

% section the_bayesian_methodology (end)

\section{The Credibility Premium}%
\label{sec:the_credibility_premium}
% section the_credibility_premium

The Bayesian premium strongly depends on the assumed distribution of $X_i \mid
\Theta = \theta$ and $\Theta$. Furthermore, the Bayesian premium may be
difficult to evaluate.

Another method to estimate $X_{n+1}$ which we shall study is to make use of
linear combinations of past observations, in particular
\begin{equation*}
  \alpha_0 + \sum_{i=1}^{n} \alpha_i X_i.
\end{equation*}
The estimates $\hat{\alpha}_0, \ldots \hat{\alpha}_n$ are chosen to
\hlimpo{minimize} the mean square error
\begin{equation*}
  \mathcal{Q}(\alpha_0, \ldots, \alpha_n) = E \left[ \left( X_{n+1} - \left[
  \alpha_0 + \sum_{i=1}^{n} \alpha_i X_i \right] \right)^2 \right].
\end{equation*}

Let us now develop the general model in calculating the credibility premium.

\begin{thm}[General Model for Credibility Premium]\label{thm:general_model_for_credibility_premium}
  Let $\{ X_i \}_{i=1}^n$ be a sequence of past observations (rvs), and
  $X_{n+1}$ the predictive rv. Then, the solution $(\hat{\alpha}_0, \ldots,
  \hat{\alpha}_n)$ to the system of linear equations, called the \hldefn{normal
  equations},
  \begin{gather*}
    E[X_{n+1}] = \hat{\alpha}_0  + \sum_{i=1}^{n} \hat{\alpha}_i E[X_i] \\
    \Cov(X_j, X_{n+1}) = \sum_{i=1}^{n} \hat{\alpha}_i \Cov(X_i, X_j), \quad
    \forall j \in \{ 1, \ldots, n \},
  \end{gather*}
  minimizes the mean square error
  \begin{equation*}
    \mathcal{Q}(\alpha_0, \ldots, \alpha_n) = E \left[ \left( X_{n+1} - \left[
    \alpha_0 + \sum_{i=1}^{n} \alpha_i X_i \right] \right)^2 \right].
  \end{equation*}
\end{thm}

\begin{proof}
  First, we take partial derivative wrt $\alpha_0$, and set the derivative to
  $0$, i.e.
  \begin{equation*}
    \frac{\partial \mathcal{Q}}{\partial \alpha_0} = E \left[ -2 \left( X_{n+1}
    - \hat{\alpha}_0 - \sum_{i=1}^{n} \hat{\alpha}_i X_i \right) \right] = 0.
  \end{equation*}
  This gives us
  \begin{equation}\label{eq:genmod_cred_prem_eq1}
    E[X_{n+1}] = \hat{\alpha}_0 + \sum_{i=1}^{n} \hat{\alpha}_i E[X_i].
  \end{equation}

  Now, we take partial derivatives wrt each $\alpha_j$, $j \in \{ 1, \ldots,
  n\}$, and equate the derivatives to $0$, i.e.
  \begin{equation*}
    \frac{\partial \mathcal{Q}}{\partial \alpha_j} = E \left[ -2X_j \left(
    X_{n+1} - \hat{\alpha}_0 - \sum_{i=1}^{n} \hat{\alpha}_i X_i \right) \right]
    = 0.
  \end{equation*}
  Then we have
  \begin{equation}\label{eq:genmod_cred_prem_eq2}
    E[X_j X_{n+1}] = \hat{\alpha}_0 E[X_j] + \sum_{i=1}^{n} \hat{\alpha}_i E[X_i
    X_j].
  \end{equation}

  Multiplying \cref{eq:genmod_cred_prem_eq1} by $E[X_j]$, for each $j \in \{ 1,
  \ldots, n \}$, we get that
  \begin{equation*}
    E[X_{n+1}]E[X_j] = \hat{\alpha}_0 E[X_j] + \sum_{i=1}^{n} \hat{\alpha}_i
    E[X_i]E[X_j].
  \end{equation*}
  Subtracting the above from \cref{eq:genmod_cred_prem_eq2}, we get
  \begin{equation*}
    \Cov(X_i, X_{n+1}) = \hat{\alpha}_0 E[X_j] + \sum_{i=1}^{n} \hat{\alpha}_i
    \Cov(X_i, X_j),
  \end{equation*}
  for $j \in \{1, \ldots, n\}$.

  It is then clear that $\hat{\alpha}_0, \ldots, \hat{\alpha}_n$ satisfies the
  normal equations
  \begin{gather*}
    E[X_{n+1}] = \hat{\alpha}_0  + \sum_{i=1}^{n} \hat{\alpha}_i E[X_i] \\
    \Cov(X_j, X_{n+1}) = \sum_{i=1}^{n} \hat{\alpha}_i \Cov(X_i, X_j), \quad
    \forall j \in \{ 1, \ldots, n \}.
  \end{gather*}
\end{proof}

\begin{defn}[Estimator for the Credibility Premium]\label{defn:estimator_for_the_credibility_premium}
  We define the \hlnoteb{estimator for the credibility premium} as
  \begin{equation*}
    \hat{P} \coloneqq \hat{\alpha}_0 + \sum_{i=1}^{n} \hat{\alpha}_i X_i.
  \end{equation*}
\end{defn}

\begin{crly}[$\hat{P}$ as Best Linear Estimator]\label{crly:p_hat_as_best_linear_estimator}
  The $\alpha_j$'s, for $j \in \{0, \ldots, n\}$, also minimizes
  \begin{enumerate}
    \item 
      \begin{equation*}
        \mathcal{Q}_1(\alpha_0, \ldots, \alpha_n) = E \left[ \left( E[X_{n+1}
          \mid \vec{X}] - \left[\alpha_0 + \sum_{i=1}^{n} \alpha_i X_i\right]
          \right)^2 \right];
      \end{equation*}
      and
    \item 
      \begin{equation*}
        \mathcal{Q}_2(\alpha_0, \ldots, \alpha_n) = E \left[ \left( E[X_{n+1}
          \mid \Theta] - \left[ \alpha_0 + \sum_{i=1}^{n} \alpha_i X_i \right]
          \right)^2 \right].
      \end{equation*}
  \end{enumerate}

  We say that $\hat{P}$ is the \hldefn{Best Linear Estimator} for
  \begin{itemize}
    \item $X_{n+1}$;
    \item the Bayesian premium $E[X_{n+1} \mid \vec{X}]$; and
    \item the hypothetical mean $E[X_{n+1} \mid \Theta] = \mu_{n+1}(\Theta)$.
  \end{itemize}
\end{crly}

\marginnote{The name for \cref{thm:theorem_1} is unfortunate, but I can't think
of a good name for it, and it is what is used in lectures.}

\begin{thm}[Theorem 1]\index{Theorem 1}\label{thm:theorem_1}
  Suppose $\{ X_i \}_{i=1}^n$ is a sequence of past observations, $X_{n+1}$ is
  the predictive rv, with
  \begin{itemize}
    \item $E[X_i] = \mu$ ;
    \item $\Var(X_i) = \sigma^2$ ; and
    \item $\Cov(X_i, X_j) = \rho \sigma^2$, for $i \neq j$, $i, j \in \{ 1,
      \ldots, n+1 \}$, and $\rho \in (-1, 1)$.
  \end{itemize}
  Then the credibility premium for $X_{n+1}$ is
  \begin{equation*}
    P = Z \overline{X} + (1 - Z) \mu,
  \end{equation*}
  where
  \begin{equation*}
    Z = \frac{n\rho}{1 - \rho + n\rho},
  \end{equation*}
  and
  \begin{equation*}
    \overline{X} = \frac{1}{n} \sum_{i=1}^{n} X_i.
  \end{equation*}
\end{thm}

\begin{proof}
  \hlwarn{Proof to be added.} 
\end{proof}

% section the_credibility_premium (end)

\section{The B\"{u}lmann Model}%
\label{sec:the_buhlmann_model}
% section the_buhlmann_model



% section the_buhlmann_model (end)

% chapter greatest_accuracy_credibility (end)

\appendix

\backmatter

\fancyhead[LE]{\thepage \enspace \textsl{\leftmark}}

% \nobibliography*
\bibliography{references}

\printindex

\end{document}
% vim:tw=80:fdm=syntax

